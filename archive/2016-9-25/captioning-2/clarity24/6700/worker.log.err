SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm102/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/work/run/storm102/data/supervisor/stormdist/captioning-1-1474850075/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/peifeng/work/run/storm102/data/workers/3a68788c-0d20-4e95-b143-d444098dccf9/tmp/cvld758222126954948375/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0925 20:35:46.980703 31660 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /home/peifeng/work/run/storm102/data/workers/3a68788c-0d20-4e95-b143-d444098dccf9/tmp/cvld758222126954948375/s2vt.words_to_preds.prototxt
I0925 20:35:46.980857 31660 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0925 20:35:46.980867 31660 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0925 20:35:46.981009 31666 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0925 20:35:46.981149 31666 layer_factory.hpp:77] Creating layer data
I0925 20:35:46.981156 31660 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0925 20:35:46.981178 31666 net.cpp:91] Creating Layer data
I0925 20:35:46.981189 31666 net.cpp:399] data -> data
I0925 20:35:46.981297 31660 layer_factory.hpp:77] Creating layer input
I0925 20:35:46.981314 31660 net.cpp:91] Creating Layer input
I0925 20:35:46.981323 31660 net.cpp:399] input -> frames_fc7
I0925 20:35:46.981341 31660 net.cpp:399] input -> cont_sentence
I0925 20:35:46.981355 31660 net.cpp:399] input -> input_sentence
I0925 20:35:46.981369 31660 net.cpp:399] input -> stage_indicator
I0925 20:35:47.580010 31666 net.cpp:141] Setting up data
I0925 20:35:47.580109 31666 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0925 20:35:47.580118 31666 net.cpp:156] Memory required for data: 6183480
I0925 20:35:47.580139 31666 layer_factory.hpp:77] Creating layer conv1
I0925 20:35:47.580174 31666 net.cpp:91] Creating Layer conv1
I0925 20:35:47.580185 31666 net.cpp:425] conv1 <- data
I0925 20:35:47.580200 31666 net.cpp:399] conv1 -> conv1
I0925 20:35:47.580190 31660 net.cpp:141] Setting up input
I0925 20:35:47.580240 31660 net.cpp:148] Top shape: 1 4096 (4096)
I0925 20:35:47.580252 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.580261 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.580270 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.580276 31660 net.cpp:156] Memory required for data: 16396
I0925 20:35:47.580288 31660 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0925 20:35:47.580324 31660 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0925 20:35:47.580334 31660 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0925 20:35:47.580381 31660 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0925 20:35:47.580412 31660 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0925 20:35:47.581614 31660 net.cpp:141] Setting up cont_sentence_input_1_split
I0925 20:35:47.581657 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.581667 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.581674 31660 net.cpp:156] Memory required for data: 16404
I0925 20:35:47.581682 31660 layer_factory.hpp:77] Creating layer embed_encoder
I0925 20:35:47.581717 31660 net.cpp:91] Creating Layer embed_encoder
I0925 20:35:47.581725 31660 net.cpp:425] embed_encoder <- frames_fc7
I0925 20:35:47.581740 31660 net.cpp:399] embed_encoder -> embedded_in_frames
I0925 20:35:47.624722 31660 net.cpp:141] Setting up embed_encoder
I0925 20:35:47.624766 31660 net.cpp:148] Top shape: 1 500 (500)
I0925 20:35:47.624775 31660 net.cpp:156] Memory required for data: 18404
I0925 20:35:47.624809 31660 layer_factory.hpp:77] Creating layer reshape_frames
I0925 20:35:47.624881 31660 net.cpp:91] Creating Layer reshape_frames
I0925 20:35:47.624891 31660 net.cpp:425] reshape_frames <- embedded_in_frames
I0925 20:35:47.624904 31660 net.cpp:399] reshape_frames -> embedded_input_frames
I0925 20:35:47.632588 31660 net.cpp:141] Setting up reshape_frames
I0925 20:35:47.632616 31660 net.cpp:148] Top shape: 1 1 500 (500)
I0925 20:35:47.632638 31660 net.cpp:156] Memory required for data: 20404
I0925 20:35:47.632647 31660 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0925 20:35:47.632663 31660 net.cpp:91] Creating Layer reshape_stage_indicator
I0925 20:35:47.632671 31660 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0925 20:35:47.632689 31660 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0925 20:35:47.636759 31660 net.cpp:141] Setting up reshape_stage_indicator
I0925 20:35:47.636786 31660 net.cpp:148] Top shape: 1 1 1 (1)
I0925 20:35:47.636795 31660 net.cpp:156] Memory required for data: 20408
I0925 20:35:47.636802 31660 layer_factory.hpp:77] Creating layer embedding
I0925 20:35:47.636822 31660 net.cpp:91] Creating Layer embedding
I0925 20:35:47.636831 31660 net.cpp:425] embedding <- input_sentence
I0925 20:35:47.636849 31660 net.cpp:399] embedding -> embedded_input_sentence
I0925 20:35:47.845479 31666 net.cpp:141] Setting up conv1
I0925 20:35:47.845530 31666 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0925 20:35:47.845536 31666 net.cpp:156] Memory required for data: 17799480
I0925 20:35:47.845562 31666 layer_factory.hpp:77] Creating layer relu1
I0925 20:35:47.845582 31666 net.cpp:91] Creating Layer relu1
I0925 20:35:47.845588 31666 net.cpp:425] relu1 <- conv1
I0925 20:35:47.845597 31666 net.cpp:386] relu1 -> conv1 (in-place)
I0925 20:35:47.846050 31666 net.cpp:141] Setting up relu1
I0925 20:35:47.846068 31666 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0925 20:35:47.846074 31666 net.cpp:156] Memory required for data: 29415480
I0925 20:35:47.846081 31666 layer_factory.hpp:77] Creating layer pool1
I0925 20:35:47.846093 31666 net.cpp:91] Creating Layer pool1
I0925 20:35:47.846099 31666 net.cpp:425] pool1 <- conv1
I0925 20:35:47.846107 31666 net.cpp:399] pool1 -> pool1
I0925 20:35:47.846191 31666 net.cpp:141] Setting up pool1
I0925 20:35:47.846204 31666 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0925 20:35:47.846209 31666 net.cpp:156] Memory required for data: 32214840
I0925 20:35:47.846213 31666 layer_factory.hpp:77] Creating layer norm1
I0925 20:35:47.846235 31666 net.cpp:91] Creating Layer norm1
I0925 20:35:47.846241 31666 net.cpp:425] norm1 <- pool1
I0925 20:35:47.846249 31666 net.cpp:399] norm1 -> norm1
I0925 20:35:47.846570 31666 net.cpp:141] Setting up norm1
I0925 20:35:47.846583 31666 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0925 20:35:47.846588 31666 net.cpp:156] Memory required for data: 35014200
I0925 20:35:47.846604 31666 layer_factory.hpp:77] Creating layer conv2
I0925 20:35:47.846624 31666 net.cpp:91] Creating Layer conv2
I0925 20:35:47.846632 31666 net.cpp:425] conv2 <- norm1
I0925 20:35:47.846639 31666 net.cpp:399] conv2 -> conv2
I0925 20:35:47.850265 31666 net.cpp:141] Setting up conv2
I0925 20:35:47.850283 31666 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0925 20:35:47.850289 31666 net.cpp:156] Memory required for data: 42479160
I0925 20:35:47.850302 31666 layer_factory.hpp:77] Creating layer relu2
I0925 20:35:47.850312 31666 net.cpp:91] Creating Layer relu2
I0925 20:35:47.850318 31666 net.cpp:425] relu2 <- conv2
I0925 20:35:47.850330 31666 net.cpp:386] relu2 -> conv2 (in-place)
I0925 20:35:47.850788 31666 net.cpp:141] Setting up relu2
I0925 20:35:47.850803 31666 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0925 20:35:47.850808 31666 net.cpp:156] Memory required for data: 49944120
I0925 20:35:47.850814 31666 layer_factory.hpp:77] Creating layer pool2
I0925 20:35:47.850828 31666 net.cpp:91] Creating Layer pool2
I0925 20:35:47.850834 31666 net.cpp:425] pool2 <- conv2
I0925 20:35:47.850842 31666 net.cpp:399] pool2 -> pool2
I0925 20:35:47.850908 31666 net.cpp:141] Setting up pool2
I0925 20:35:47.850917 31666 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0925 20:35:47.850922 31666 net.cpp:156] Memory required for data: 51674680
I0925 20:35:47.850929 31666 layer_factory.hpp:77] Creating layer norm2
I0925 20:35:47.850941 31666 net.cpp:91] Creating Layer norm2
I0925 20:35:47.850946 31666 net.cpp:425] norm2 <- pool2
I0925 20:35:47.850955 31666 net.cpp:399] norm2 -> norm2
I0925 20:35:47.851246 31666 net.cpp:141] Setting up norm2
I0925 20:35:47.851259 31666 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0925 20:35:47.851264 31666 net.cpp:156] Memory required for data: 53405240
I0925 20:35:47.851270 31666 layer_factory.hpp:77] Creating layer conv3
I0925 20:35:47.851287 31666 net.cpp:91] Creating Layer conv3
I0925 20:35:47.851294 31666 net.cpp:425] conv3 <- norm2
I0925 20:35:47.851301 31666 net.cpp:399] conv3 -> conv3
I0925 20:35:47.855298 31666 net.cpp:141] Setting up conv3
I0925 20:35:47.855316 31666 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0925 20:35:47.855321 31666 net.cpp:156] Memory required for data: 56001080
I0925 20:35:47.855335 31666 layer_factory.hpp:77] Creating layer relu3
I0925 20:35:47.855350 31666 net.cpp:91] Creating Layer relu3
I0925 20:35:47.855355 31666 net.cpp:425] relu3 <- conv3
I0925 20:35:47.855363 31666 net.cpp:386] relu3 -> conv3 (in-place)
I0925 20:35:47.855618 31666 net.cpp:141] Setting up relu3
I0925 20:35:47.855630 31666 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0925 20:35:47.855635 31666 net.cpp:156] Memory required for data: 58596920
I0925 20:35:47.855640 31666 layer_factory.hpp:77] Creating layer conv4
I0925 20:35:47.855655 31666 net.cpp:91] Creating Layer conv4
I0925 20:35:47.855661 31666 net.cpp:425] conv4 <- conv3
I0925 20:35:47.855671 31666 net.cpp:399] conv4 -> conv4
I0925 20:35:47.860152 31666 net.cpp:141] Setting up conv4
I0925 20:35:47.860172 31666 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0925 20:35:47.860178 31666 net.cpp:156] Memory required for data: 61192760
I0925 20:35:47.860189 31666 layer_factory.hpp:77] Creating layer relu4
I0925 20:35:47.860198 31666 net.cpp:91] Creating Layer relu4
I0925 20:35:47.860204 31666 net.cpp:425] relu4 <- conv4
I0925 20:35:47.860213 31666 net.cpp:386] relu4 -> conv4 (in-place)
I0925 20:35:47.860651 31666 net.cpp:141] Setting up relu4
I0925 20:35:47.860668 31666 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0925 20:35:47.860674 31666 net.cpp:156] Memory required for data: 63788600
I0925 20:35:47.860679 31666 layer_factory.hpp:77] Creating layer conv5
I0925 20:35:47.860692 31666 net.cpp:91] Creating Layer conv5
I0925 20:35:47.860697 31666 net.cpp:425] conv5 <- conv4
I0925 20:35:47.860708 31666 net.cpp:399] conv5 -> conv5
I0925 20:35:47.864761 31666 net.cpp:141] Setting up conv5
I0925 20:35:47.864779 31666 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0925 20:35:47.864784 31666 net.cpp:156] Memory required for data: 65519160
I0925 20:35:47.864799 31666 layer_factory.hpp:77] Creating layer relu5
I0925 20:35:47.864809 31666 net.cpp:91] Creating Layer relu5
I0925 20:35:47.864815 31666 net.cpp:425] relu5 <- conv5
I0925 20:35:47.864830 31666 net.cpp:386] relu5 -> conv5 (in-place)
I0925 20:35:47.865262 31666 net.cpp:141] Setting up relu5
I0925 20:35:47.865277 31666 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0925 20:35:47.865281 31666 net.cpp:156] Memory required for data: 67249720
I0925 20:35:47.865288 31666 layer_factory.hpp:77] Creating layer pool5
I0925 20:35:47.865298 31666 net.cpp:91] Creating Layer pool5
I0925 20:35:47.865304 31666 net.cpp:425] pool5 <- conv5
I0925 20:35:47.865315 31666 net.cpp:399] pool5 -> pool5
I0925 20:35:47.865383 31666 net.cpp:141] Setting up pool5
I0925 20:35:47.865394 31666 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0925 20:35:47.865399 31666 net.cpp:156] Memory required for data: 67618360
I0925 20:35:47.865404 31666 layer_factory.hpp:77] Creating layer fc6
I0925 20:35:47.865417 31666 net.cpp:91] Creating Layer fc6
I0925 20:35:47.865425 31666 net.cpp:425] fc6 <- pool5
I0925 20:35:47.865433 31666 net.cpp:399] fc6 -> fc6
I0925 20:35:47.939925 31660 net.cpp:141] Setting up embedding
I0925 20:35:47.939980 31660 net.cpp:148] Top shape: 1 1 500 (500)
I0925 20:35:47.939986 31660 net.cpp:156] Memory required for data: 22408
I0925 20:35:47.940006 31660 layer_factory.hpp:77] Creating layer lstm1
I0925 20:35:47.940042 31660 net.cpp:91] Creating Layer lstm1
I0925 20:35:47.940052 31660 net.cpp:425] lstm1 <- embedded_input_frames
I0925 20:35:47.940062 31660 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0925 20:35:47.940078 31660 net.cpp:399] lstm1 -> lstm1
I0925 20:35:47.940116 31660 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0925 20:35:47.940549 31660 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0925 20:35:47.940659 31660 layer_factory.hpp:77] Creating layer lstm1_
I0925 20:35:47.940673 31660 net.cpp:91] Creating Layer lstm1_
I0925 20:35:47.940680 31660 net.cpp:399] lstm1_ -> x
I0925 20:35:47.940693 31660 net.cpp:399] lstm1_ -> cont
I0925 20:35:47.940764 31660 net.cpp:141] Setting up lstm1_
I0925 20:35:47.940776 31660 net.cpp:148] Top shape: 1 1 500 (500)
I0925 20:35:47.940783 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.940788 31660 net.cpp:156] Memory required for data: 2004
I0925 20:35:47.940793 31660 layer_factory.hpp:77] Creating layer lstm1_
I0925 20:35:47.940804 31660 net.cpp:91] Creating Layer lstm1_
I0925 20:35:47.940814 31660 net.cpp:399] lstm1_ -> c_0
I0925 20:35:47.940824 31660 net.cpp:399] lstm1_ -> h_0
I0925 20:35:47.940879 31660 net.cpp:141] Setting up lstm1_
I0925 20:35:47.940889 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:47.940896 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:47.940901 31660 net.cpp:156] Memory required for data: 10004
I0925 20:35:47.940906 31660 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0925 20:35:47.940915 31660 net.cpp:91] Creating Layer lstm1_cont_slice
I0925 20:35:47.940920 31660 net.cpp:425] lstm1_cont_slice <- cont
I0925 20:35:47.940933 31660 net.cpp:399] lstm1_cont_slice -> cont_1
I0925 20:35:47.940970 31660 net.cpp:141] Setting up lstm1_cont_slice
I0925 20:35:47.940980 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.940985 31660 net.cpp:156] Memory required for data: 10008
I0925 20:35:47.940990 31660 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0925 20:35:47.941005 31660 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0925 20:35:47.941011 31660 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0925 20:35:47.941018 31660 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0925 20:35:47.941030 31660 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0925 20:35:47.941079 31660 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0925 20:35:47.941089 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.941095 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:47.941100 31660 net.cpp:156] Memory required for data: 10016
I0925 20:35:47.941105 31660 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0925 20:35:47.941117 31660 net.cpp:91] Creating Layer lstm1_x_transform
I0925 20:35:47.941121 31660 net.cpp:425] lstm1_x_transform <- x
I0925 20:35:47.941130 31660 net.cpp:399] lstm1_x_transform -> W_xc_x
I0925 20:35:47.962710 31660 net.cpp:141] Setting up lstm1_x_transform
I0925 20:35:47.962729 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:47.962735 31660 net.cpp:156] Memory required for data: 26016
I0925 20:35:47.962750 31660 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0925 20:35:47.962759 31660 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0925 20:35:47.962765 31660 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0925 20:35:47.962774 31660 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0925 20:35:47.962811 31660 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0925 20:35:47.962822 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:47.962826 31660 net.cpp:156] Memory required for data: 42016
I0925 20:35:47.962831 31660 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0925 20:35:47.962846 31660 net.cpp:91] Creating Layer lstm1_h_conted_0
I0925 20:35:47.962851 31660 net.cpp:425] lstm1_h_conted_0 <- h_0
I0925 20:35:47.962857 31660 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0925 20:35:47.962864 31660 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0925 20:35:47.962955 31660 net.cpp:141] Setting up lstm1_h_conted_0
I0925 20:35:47.962965 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:47.962970 31660 net.cpp:156] Memory required for data: 46016
I0925 20:35:47.962975 31660 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0925 20:35:47.962987 31660 net.cpp:91] Creating Layer lstm1_transform_1
I0925 20:35:47.962993 31660 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0925 20:35:47.963001 31660 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0925 20:35:47.980933 31666 net.cpp:141] Setting up fc6
I0925 20:35:47.980985 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:47.980991 31666 net.cpp:156] Memory required for data: 67782200
I0925 20:35:47.981007 31666 layer_factory.hpp:77] Creating layer relu6
I0925 20:35:47.981027 31666 net.cpp:91] Creating Layer relu6
I0925 20:35:47.981035 31666 net.cpp:425] relu6 <- fc6
I0925 20:35:47.981045 31666 net.cpp:386] relu6 -> fc6 (in-place)
I0925 20:35:47.981408 31666 net.cpp:141] Setting up relu6
I0925 20:35:47.981421 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:47.981427 31666 net.cpp:156] Memory required for data: 67946040
I0925 20:35:47.981432 31666 layer_factory.hpp:77] Creating layer drop6
I0925 20:35:47.981456 31666 net.cpp:91] Creating Layer drop6
I0925 20:35:47.981462 31666 net.cpp:425] drop6 <- fc6
I0925 20:35:47.981474 31666 net.cpp:386] drop6 -> fc6 (in-place)
I0925 20:35:47.981526 31666 net.cpp:141] Setting up drop6
I0925 20:35:47.981536 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:47.981541 31666 net.cpp:156] Memory required for data: 68109880
I0925 20:35:47.981546 31666 layer_factory.hpp:77] Creating layer fc7
I0925 20:35:47.981560 31666 net.cpp:91] Creating Layer fc7
I0925 20:35:47.981566 31666 net.cpp:425] fc7 <- fc6
I0925 20:35:47.981573 31666 net.cpp:399] fc7 -> fc7
I0925 20:35:48.014812 31660 net.cpp:141] Setting up lstm1_transform_1
I0925 20:35:48.014866 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.014873 31660 net.cpp:156] Memory required for data: 62016
I0925 20:35:48.014897 31660 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0925 20:35:48.014925 31660 net.cpp:91] Creating Layer lstm1_gate_input_1
I0925 20:35:48.014935 31660 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0925 20:35:48.014943 31660 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0925 20:35:48.014952 31660 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0925 20:35:48.015015 31660 net.cpp:141] Setting up lstm1_gate_input_1
I0925 20:35:48.015027 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.015031 31660 net.cpp:156] Memory required for data: 78016
I0925 20:35:48.015036 31660 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0925 20:35:48.015050 31660 net.cpp:91] Creating Layer lstm1_unit_1
I0925 20:35:48.015056 31660 net.cpp:425] lstm1_unit_1 <- c_0
I0925 20:35:48.015063 31660 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0925 20:35:48.015069 31660 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0925 20:35:48.015076 31660 net.cpp:399] lstm1_unit_1 -> c_1
I0925 20:35:48.015086 31660 net.cpp:399] lstm1_unit_1 -> h_1
I0925 20:35:48.015157 31660 net.cpp:141] Setting up lstm1_unit_1
I0925 20:35:48.015167 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.015174 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.015178 31660 net.cpp:156] Memory required for data: 86016
I0925 20:35:48.015184 31660 layer_factory.hpp:77] Creating layer lstm1_
I0925 20:35:48.015194 31660 net.cpp:91] Creating Layer lstm1_
I0925 20:35:48.015199 31660 net.cpp:425] lstm1_ <- c_1
I0925 20:35:48.015209 31660 net.cpp:399] lstm1_ -> c_T
I0925 20:35:48.015242 31660 net.cpp:141] Setting up lstm1_
I0925 20:35:48.015251 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.015256 31660 net.cpp:156] Memory required for data: 90016
I0925 20:35:48.015261 31660 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0925 20:35:48.015272 31660 net.cpp:91] Creating Layer lstm1_h_concat
I0925 20:35:48.015277 31660 net.cpp:425] lstm1_h_concat <- h_1
I0925 20:35:48.015288 31660 net.cpp:399] lstm1_h_concat -> h
I0925 20:35:48.015338 31660 net.cpp:141] Setting up lstm1_h_concat
I0925 20:35:48.015348 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.015353 31660 net.cpp:156] Memory required for data: 94016
I0925 20:35:48.015358 31660 layer_factory.hpp:77] Creating layer h_pseudoloss
I0925 20:35:48.015374 31660 net.cpp:91] Creating Layer h_pseudoloss
I0925 20:35:48.015380 31660 net.cpp:425] h_pseudoloss <- h
I0925 20:35:48.015388 31660 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0925 20:35:48.015491 31660 net.cpp:141] Setting up h_pseudoloss
I0925 20:35:48.015502 31660 net.cpp:148] Top shape: (1)
I0925 20:35:48.015508 31660 net.cpp:151]     with loss weight 1
I0925 20:35:48.015550 31660 net.cpp:156] Memory required for data: 94020
I0925 20:35:48.015558 31660 net.cpp:217] h_pseudoloss needs backward computation.
I0925 20:35:48.015563 31660 net.cpp:217] lstm1_h_concat needs backward computation.
I0925 20:35:48.015568 31660 net.cpp:219] lstm1_ does not need backward computation.
I0925 20:35:48.015573 31660 net.cpp:217] lstm1_unit_1 needs backward computation.
I0925 20:35:48.015579 31660 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0925 20:35:48.015584 31660 net.cpp:217] lstm1_transform_1 needs backward computation.
I0925 20:35:48.015590 31660 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0925 20:35:48.015596 31660 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0925 20:35:48.015602 31660 net.cpp:217] lstm1_x_transform needs backward computation.
I0925 20:35:48.015607 31660 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0925 20:35:48.015614 31660 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0925 20:35:48.015619 31660 net.cpp:219] lstm1_ does not need backward computation.
I0925 20:35:48.015625 31660 net.cpp:219] lstm1_ does not need backward computation.
I0925 20:35:48.015628 31660 net.cpp:261] This network produces output c_T
I0925 20:35:48.015633 31660 net.cpp:261] This network produces output h_pseudoloss
I0925 20:35:48.015651 31660 net.cpp:274] Network initialization done.
I0925 20:35:48.015717 31660 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0925 20:35:48.015724 31660 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0925 20:35:48.015729 31660 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0925 20:35:48.015847 31660 net.cpp:141] Setting up lstm1
I0925 20:35:48.015859 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.015866 31660 net.cpp:156] Memory required for data: 26408
I0925 20:35:48.015880 31660 layer_factory.hpp:77] Creating layer concat
I0925 20:35:48.015890 31660 net.cpp:91] Creating Layer concat
I0925 20:35:48.015897 31660 net.cpp:425] concat <- lstm1
I0925 20:35:48.015904 31660 net.cpp:425] concat <- embedded_input_sentence
I0925 20:35:48.015910 31660 net.cpp:425] concat <- reshaped_stage_indicator
I0925 20:35:48.015918 31660 net.cpp:399] concat -> lstm1_video_sequence
I0925 20:35:48.015954 31660 net.cpp:141] Setting up concat
I0925 20:35:48.015964 31660 net.cpp:148] Top shape: 1 1 1501 (1501)
I0925 20:35:48.015969 31660 net.cpp:156] Memory required for data: 32412
I0925 20:35:48.015974 31660 layer_factory.hpp:77] Creating layer lstm2
I0925 20:35:48.015988 31660 net.cpp:91] Creating Layer lstm2
I0925 20:35:48.015995 31660 net.cpp:425] lstm2 <- lstm1_video_sequence
I0925 20:35:48.016001 31660 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0925 20:35:48.016010 31660 net.cpp:399] lstm2 -> lstm2
I0925 20:35:48.016022 31660 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0925 20:35:48.016317 31660 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0925 20:35:48.016415 31660 layer_factory.hpp:77] Creating layer lstm2_
I0925 20:35:48.016429 31660 net.cpp:91] Creating Layer lstm2_
I0925 20:35:48.016436 31660 net.cpp:399] lstm2_ -> x
I0925 20:35:48.016448 31660 net.cpp:399] lstm2_ -> cont
I0925 20:35:48.016506 31660 net.cpp:141] Setting up lstm2_
I0925 20:35:48.016516 31660 net.cpp:148] Top shape: 1 1 1501 (1501)
I0925 20:35:48.016523 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:48.016528 31660 net.cpp:156] Memory required for data: 6008
I0925 20:35:48.016533 31660 layer_factory.hpp:77] Creating layer lstm2_
I0925 20:35:48.016546 31660 net.cpp:91] Creating Layer lstm2_
I0925 20:35:48.016553 31660 net.cpp:399] lstm2_ -> c_0
I0925 20:35:48.016563 31660 net.cpp:399] lstm2_ -> h_0
I0925 20:35:48.016618 31660 net.cpp:141] Setting up lstm2_
I0925 20:35:48.016628 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.016634 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.016639 31660 net.cpp:156] Memory required for data: 14008
I0925 20:35:48.016644 31660 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0925 20:35:48.016654 31660 net.cpp:91] Creating Layer lstm2_cont_slice
I0925 20:35:48.016659 31660 net.cpp:425] lstm2_cont_slice <- cont
I0925 20:35:48.016666 31660 net.cpp:399] lstm2_cont_slice -> cont_1
I0925 20:35:48.016705 31660 net.cpp:141] Setting up lstm2_cont_slice
I0925 20:35:48.016715 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:48.016718 31660 net.cpp:156] Memory required for data: 14012
I0925 20:35:48.016723 31660 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0925 20:35:48.016731 31660 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0925 20:35:48.016736 31660 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0925 20:35:48.016746 31660 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0925 20:35:48.016755 31660 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0925 20:35:48.016805 31660 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0925 20:35:48.016818 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:48.016824 31660 net.cpp:148] Top shape: 1 1 (1)
I0925 20:35:48.016829 31660 net.cpp:156] Memory required for data: 14020
I0925 20:35:48.016834 31660 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0925 20:35:48.016844 31660 net.cpp:91] Creating Layer lstm2_x_transform
I0925 20:35:48.016849 31660 net.cpp:425] lstm2_x_transform <- x
I0925 20:35:48.016860 31660 net.cpp:399] lstm2_x_transform -> W_xc_x
I0925 20:35:48.033669 31666 net.cpp:141] Setting up fc7
I0925 20:35:48.033723 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:48.033730 31666 net.cpp:156] Memory required for data: 68273720
I0925 20:35:48.033743 31666 layer_factory.hpp:77] Creating layer relu7
I0925 20:35:48.033766 31666 net.cpp:91] Creating Layer relu7
I0925 20:35:48.033772 31666 net.cpp:425] relu7 <- fc7
I0925 20:35:48.033782 31666 net.cpp:386] relu7 -> fc7 (in-place)
I0925 20:35:48.034461 31666 net.cpp:141] Setting up relu7
I0925 20:35:48.034476 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:48.034481 31666 net.cpp:156] Memory required for data: 68437560
I0925 20:35:48.034487 31666 layer_factory.hpp:77] Creating layer drop7
I0925 20:35:48.034502 31666 net.cpp:91] Creating Layer drop7
I0925 20:35:48.034508 31666 net.cpp:425] drop7 <- fc7
I0925 20:35:48.034515 31666 net.cpp:386] drop7 -> fc7 (in-place)
I0925 20:35:48.034562 31666 net.cpp:141] Setting up drop7
I0925 20:35:48.034572 31666 net.cpp:148] Top shape: 10 4096 (40960)
I0925 20:35:48.034577 31666 net.cpp:156] Memory required for data: 68601400
I0925 20:35:48.034582 31666 layer_factory.hpp:77] Creating layer fc8
I0925 20:35:48.034593 31666 net.cpp:91] Creating Layer fc8
I0925 20:35:48.034615 31666 net.cpp:425] fc8 <- fc7
I0925 20:35:48.034627 31666 net.cpp:399] fc8 -> fc8
I0925 20:35:48.046911 31666 net.cpp:141] Setting up fc8
I0925 20:35:48.046958 31666 net.cpp:148] Top shape: 10 1000 (10000)
I0925 20:35:48.046965 31666 net.cpp:156] Memory required for data: 68641400
I0925 20:35:48.046978 31666 layer_factory.hpp:77] Creating layer prob
I0925 20:35:48.046995 31666 net.cpp:91] Creating Layer prob
I0925 20:35:48.047003 31666 net.cpp:425] prob <- fc8
I0925 20:35:48.047011 31666 net.cpp:399] prob -> prob
I0925 20:35:48.047508 31666 net.cpp:141] Setting up prob
I0925 20:35:48.047523 31666 net.cpp:148] Top shape: 10 1000 (10000)
I0925 20:35:48.047528 31666 net.cpp:156] Memory required for data: 68681400
I0925 20:35:48.047534 31666 net.cpp:219] prob does not need backward computation.
I0925 20:35:48.047540 31666 net.cpp:219] fc8 does not need backward computation.
I0925 20:35:48.047545 31666 net.cpp:219] drop7 does not need backward computation.
I0925 20:35:48.047550 31666 net.cpp:219] relu7 does not need backward computation.
I0925 20:35:48.047554 31666 net.cpp:219] fc7 does not need backward computation.
I0925 20:35:48.047560 31666 net.cpp:219] drop6 does not need backward computation.
I0925 20:35:48.047565 31666 net.cpp:219] relu6 does not need backward computation.
I0925 20:35:48.047570 31666 net.cpp:219] fc6 does not need backward computation.
I0925 20:35:48.047575 31666 net.cpp:219] pool5 does not need backward computation.
I0925 20:35:48.047580 31666 net.cpp:219] relu5 does not need backward computation.
I0925 20:35:48.047585 31666 net.cpp:219] conv5 does not need backward computation.
I0925 20:35:48.047590 31666 net.cpp:219] relu4 does not need backward computation.
I0925 20:35:48.047595 31666 net.cpp:219] conv4 does not need backward computation.
I0925 20:35:48.047600 31666 net.cpp:219] relu3 does not need backward computation.
I0925 20:35:48.047605 31666 net.cpp:219] conv3 does not need backward computation.
I0925 20:35:48.047610 31666 net.cpp:219] norm2 does not need backward computation.
I0925 20:35:48.047621 31666 net.cpp:219] pool2 does not need backward computation.
I0925 20:35:48.047626 31666 net.cpp:219] relu2 does not need backward computation.
I0925 20:35:48.047632 31666 net.cpp:219] conv2 does not need backward computation.
I0925 20:35:48.047637 31666 net.cpp:219] norm1 does not need backward computation.
I0925 20:35:48.047643 31666 net.cpp:219] pool1 does not need backward computation.
I0925 20:35:48.047648 31666 net.cpp:219] relu1 does not need backward computation.
I0925 20:35:48.047653 31666 net.cpp:219] conv1 does not need backward computation.
I0925 20:35:48.047658 31666 net.cpp:219] data does not need backward computation.
I0925 20:35:48.047662 31666 net.cpp:261] This network produces output prob
I0925 20:35:48.047683 31666 net.cpp:274] Network initialization done.
I0925 20:35:48.080978 31660 net.cpp:141] Setting up lstm2_x_transform
I0925 20:35:48.081022 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.081028 31660 net.cpp:156] Memory required for data: 30020
I0925 20:35:48.081049 31660 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0925 20:35:48.081065 31660 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0925 20:35:48.081073 31660 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0925 20:35:48.081082 31660 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0925 20:35:48.081136 31660 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0925 20:35:48.081147 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.081153 31660 net.cpp:156] Memory required for data: 46020
I0925 20:35:48.081158 31660 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0925 20:35:48.081171 31660 net.cpp:91] Creating Layer lstm2_h_conted_0
I0925 20:35:48.081176 31660 net.cpp:425] lstm2_h_conted_0 <- h_0
I0925 20:35:48.081183 31660 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0925 20:35:48.081190 31660 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0925 20:35:48.081295 31660 net.cpp:141] Setting up lstm2_h_conted_0
I0925 20:35:48.081305 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.081310 31660 net.cpp:156] Memory required for data: 50020
I0925 20:35:48.081315 31660 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0925 20:35:48.081331 31660 net.cpp:91] Creating Layer lstm2_transform_1
I0925 20:35:48.081336 31660 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0925 20:35:48.081346 31660 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0925 20:35:48.123703 31660 net.cpp:141] Setting up lstm2_transform_1
I0925 20:35:48.123739 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.123744 31660 net.cpp:156] Memory required for data: 66020
I0925 20:35:48.123762 31660 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0925 20:35:48.123786 31660 net.cpp:91] Creating Layer lstm2_gate_input_1
I0925 20:35:48.123795 31660 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0925 20:35:48.123802 31660 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0925 20:35:48.123811 31660 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0925 20:35:48.123862 31660 net.cpp:141] Setting up lstm2_gate_input_1
I0925 20:35:48.123872 31660 net.cpp:148] Top shape: 1 1 4000 (4000)
I0925 20:35:48.123877 31660 net.cpp:156] Memory required for data: 82020
I0925 20:35:48.123881 31660 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0925 20:35:48.123893 31660 net.cpp:91] Creating Layer lstm2_unit_1
I0925 20:35:48.123898 31660 net.cpp:425] lstm2_unit_1 <- c_0
I0925 20:35:48.123904 31660 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0925 20:35:48.123910 31660 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0925 20:35:48.123920 31660 net.cpp:399] lstm2_unit_1 -> c_1
I0925 20:35:48.123929 31660 net.cpp:399] lstm2_unit_1 -> h_1
I0925 20:35:48.123998 31660 net.cpp:141] Setting up lstm2_unit_1
I0925 20:35:48.124008 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.124016 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.124019 31660 net.cpp:156] Memory required for data: 90020
I0925 20:35:48.124025 31660 layer_factory.hpp:77] Creating layer lstm2_
I0925 20:35:48.124037 31660 net.cpp:91] Creating Layer lstm2_
I0925 20:35:48.124042 31660 net.cpp:425] lstm2_ <- c_1
I0925 20:35:48.124052 31660 net.cpp:399] lstm2_ -> c_T
I0925 20:35:48.124084 31660 net.cpp:141] Setting up lstm2_
I0925 20:35:48.124094 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.124099 31660 net.cpp:156] Memory required for data: 94020
I0925 20:35:48.124104 31660 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0925 20:35:48.124114 31660 net.cpp:91] Creating Layer lstm2_h_concat
I0925 20:35:48.124119 31660 net.cpp:425] lstm2_h_concat <- h_1
I0925 20:35:48.124130 31660 net.cpp:399] lstm2_h_concat -> h
I0925 20:35:48.124173 31660 net.cpp:141] Setting up lstm2_h_concat
I0925 20:35:48.124182 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.124187 31660 net.cpp:156] Memory required for data: 98020
I0925 20:35:48.124192 31660 layer_factory.hpp:77] Creating layer h_pseudoloss
I0925 20:35:48.124202 31660 net.cpp:91] Creating Layer h_pseudoloss
I0925 20:35:48.124207 31660 net.cpp:425] h_pseudoloss <- h
I0925 20:35:48.124214 31660 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0925 20:35:48.124310 31660 net.cpp:141] Setting up h_pseudoloss
I0925 20:35:48.124320 31660 net.cpp:148] Top shape: (1)
I0925 20:35:48.124325 31660 net.cpp:151]     with loss weight 1
I0925 20:35:48.124347 31660 net.cpp:156] Memory required for data: 98024
I0925 20:35:48.124353 31660 net.cpp:217] h_pseudoloss needs backward computation.
I0925 20:35:48.124359 31660 net.cpp:217] lstm2_h_concat needs backward computation.
I0925 20:35:48.124363 31660 net.cpp:219] lstm2_ does not need backward computation.
I0925 20:35:48.124368 31660 net.cpp:217] lstm2_unit_1 needs backward computation.
I0925 20:35:48.124375 31660 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0925 20:35:48.124380 31660 net.cpp:217] lstm2_transform_1 needs backward computation.
I0925 20:35:48.124385 31660 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0925 20:35:48.124392 31660 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0925 20:35:48.124397 31660 net.cpp:217] lstm2_x_transform needs backward computation.
I0925 20:35:48.124402 31660 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0925 20:35:48.124408 31660 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0925 20:35:48.124416 31660 net.cpp:219] lstm2_ does not need backward computation.
I0925 20:35:48.124421 31660 net.cpp:219] lstm2_ does not need backward computation.
I0925 20:35:48.124425 31660 net.cpp:261] This network produces output c_T
I0925 20:35:48.124430 31660 net.cpp:261] This network produces output h_pseudoloss
I0925 20:35:48.124446 31660 net.cpp:274] Network initialization done.
I0925 20:35:48.124500 31660 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0925 20:35:48.124506 31660 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0925 20:35:48.124511 31660 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0925 20:35:48.124621 31660 net.cpp:141] Setting up lstm2
I0925 20:35:48.124634 31660 net.cpp:148] Top shape: 1 1 1000 (1000)
I0925 20:35:48.124639 31660 net.cpp:156] Memory required for data: 36412
I0925 20:35:48.124653 31660 layer_factory.hpp:77] Creating layer predict
I0925 20:35:48.124667 31660 net.cpp:91] Creating Layer predict
I0925 20:35:48.124675 31660 net.cpp:425] predict <- lstm2
I0925 20:35:48.124682 31660 net.cpp:399] predict -> predict
I0925 20:35:48.633941 31660 net.cpp:141] Setting up predict
I0925 20:35:48.633997 31660 net.cpp:148] Top shape: 1 1 46168 (46168)
I0925 20:35:48.634004 31660 net.cpp:156] Memory required for data: 221084
I0925 20:35:48.634021 31660 layer_factory.hpp:77] Creating layer probs
I0925 20:35:48.634039 31660 net.cpp:91] Creating Layer probs
I0925 20:35:48.634048 31660 net.cpp:425] probs <- predict
I0925 20:35:48.634059 31660 net.cpp:399] probs -> probs
I0925 20:35:48.634912 31660 net.cpp:141] Setting up probs
I0925 20:35:48.634927 31660 net.cpp:148] Top shape: 1 1 46168 (46168)
I0925 20:35:48.634932 31660 net.cpp:156] Memory required for data: 405756
I0925 20:35:48.634939 31660 net.cpp:219] probs does not need backward computation.
I0925 20:35:48.634946 31660 net.cpp:219] predict does not need backward computation.
I0925 20:35:48.634953 31660 net.cpp:219] lstm2 does not need backward computation.
I0925 20:35:48.634959 31660 net.cpp:219] concat does not need backward computation.
I0925 20:35:48.634966 31660 net.cpp:219] lstm1 does not need backward computation.
I0925 20:35:48.634974 31660 net.cpp:219] embedding does not need backward computation.
I0925 20:35:48.634979 31660 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0925 20:35:48.634985 31660 net.cpp:219] reshape_frames does not need backward computation.
I0925 20:35:48.634991 31660 net.cpp:219] embed_encoder does not need backward computation.
I0925 20:35:48.634997 31660 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0925 20:35:48.635004 31660 net.cpp:219] input does not need backward computation.
I0925 20:35:48.635007 31660 net.cpp:261] This network produces output probs
I0925 20:35:48.635027 31660 net.cpp:274] Network initialization done.
I0925 20:35:52.080545 31666 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/peifeng/work/run/storm102/data/workers/3a68788c-0d20-4e95-b143-d444098dccf9/tmp/cvld758222126954948375/bvlc_reference_caffenet.caffemodel
I0925 20:35:52.080597 31666 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0925 20:35:52.080605 31666 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0925 20:35:52.080610 31666 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/peifeng/work/run/storm102/data/workers/3a68788c-0d20-4e95-b143-d444098dccf9/tmp/cvld758222126954948375/bvlc_reference_caffenet.caffemodel
I0925 20:35:52.198850 31660 net.cpp:752] Ignoring source layer data
I0925 20:35:52.198894 31660 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0925 20:35:52.198918 31660 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0925 20:35:52.284996 31660 net.cpp:752] Ignoring source layer cross_entropy_loss
I0925 20:35:52.478206 31666 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0925 20:35:52.529700 31666 net.cpp:752] Ignoring source layer loss
Loading the model + trained: 5701.26ms
Using cv::Size and some other stuff: 0.104ms
Loading the mean file: 64083.9ms
TIMERTIMER 300959372
TIMERTIMER 250003525
TIMERTIMER 245226267
TIMERTIMER 224090011
TIMERTIMER 214380736
TIMERTIMER 227971892
TIMERTIMER 243486202
TIMERTIMER 243124041
TIMERTIMER 231522708
TIMERTIMER 231757616
TIMERTIMER 247257401
TIMERTIMER 219004358
TIMERTIMER 236630330
TIMERTIMER 214630071
TIMERTIMER 211290976
TIMERTIMER 225421989
TIMERTIMER 225051468
TIMERTIMER 226072986
TIMERTIMER 236308444
TIMERTIMER 236336114
TIMERTIMER 247898752
TIMERTIMER 223516947
TIMERTIMER 219738209
TIMERTIMER 238554564
TIMERTIMER 239015208
TIMERTIMER 226291573
TIMERTIMER 228974155
TIMERTIMER 227198392
TIMERTIMER 233308483
TIMERTIMER 188120946
TIMERTIMER 194720965
TIMERTIMER 189693139
