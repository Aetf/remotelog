SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1470136239/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-08-02 07:11:10,076 ERROR Logger contains an invalid element or attribute "appender"
2016-08-02 07:11:13,146 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld7396311930794007874/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0802 07:11:24.603966  2592 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld7396311930794007874/s2vt.words_to_preds.prototxt
I0802 07:11:24.604451  2602 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0802 07:11:24.604883  2592 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0802 07:11:24.604898  2592 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0802 07:11:24.605000  2602 layer_factory.hpp:77] Creating layer data
I0802 07:11:24.605037  2602 net.cpp:91] Creating Layer data
I0802 07:11:24.605054  2602 net.cpp:399] data -> data
I0802 07:11:24.605234  2592 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0802 07:11:24.605396  2592 layer_factory.hpp:77] Creating layer input
I0802 07:11:24.605414  2592 net.cpp:91] Creating Layer input
I0802 07:11:24.605427  2592 net.cpp:399] input -> frames_fc7
I0802 07:11:24.605444  2592 net.cpp:399] input -> cont_sentence
I0802 07:11:24.605465  2592 net.cpp:399] input -> input_sentence
I0802 07:11:24.605484  2592 net.cpp:399] input -> stage_indicator
I0802 07:11:25.066303  2602 net.cpp:141] Setting up data
I0802 07:11:25.066373  2602 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0802 07:11:25.066376  2592 net.cpp:141] Setting up input
I0802 07:11:25.066380  2602 net.cpp:156] Memory required for data: 6183480
I0802 07:11:25.066402  2592 net.cpp:148] Top shape: 1 4096 (4096)
I0802 07:11:25.066409  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.066412  2602 layer_factory.hpp:77] Creating layer conv1
I0802 07:11:25.066414  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.066427  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.066431  2592 net.cpp:156] Memory required for data: 16396
I0802 07:11:25.066437  2592 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0802 07:11:25.066444  2602 net.cpp:91] Creating Layer conv1
I0802 07:11:25.066453  2602 net.cpp:425] conv1 <- data
I0802 07:11:25.066457  2592 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0802 07:11:25.066463  2592 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0802 07:11:25.066465  2602 net.cpp:399] conv1 -> conv1
I0802 07:11:25.066485  2592 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0802 07:11:25.066496  2592 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0802 07:11:25.066604  2592 net.cpp:141] Setting up cont_sentence_input_1_split
I0802 07:11:25.066615  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.066620  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.066624  2592 net.cpp:156] Memory required for data: 16404
I0802 07:11:25.066629  2592 layer_factory.hpp:77] Creating layer embed_encoder
I0802 07:11:25.066655  2592 net.cpp:91] Creating Layer embed_encoder
I0802 07:11:25.066661  2592 net.cpp:425] embed_encoder <- frames_fc7
I0802 07:11:25.066671  2592 net.cpp:399] embed_encoder -> embedded_in_frames
I0802 07:11:25.097049  2592 net.cpp:141] Setting up embed_encoder
I0802 07:11:25.097095  2592 net.cpp:148] Top shape: 1 500 (500)
I0802 07:11:25.097101  2592 net.cpp:156] Memory required for data: 18404
I0802 07:11:25.097126  2592 layer_factory.hpp:77] Creating layer reshape_frames
I0802 07:11:25.097156  2592 net.cpp:91] Creating Layer reshape_frames
I0802 07:11:25.097163  2592 net.cpp:425] reshape_frames <- embedded_in_frames
I0802 07:11:25.097175  2592 net.cpp:399] reshape_frames -> embedded_input_frames
I0802 07:11:25.097223  2592 net.cpp:141] Setting up reshape_frames
I0802 07:11:25.097232  2592 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:25.097236  2592 net.cpp:156] Memory required for data: 20404
I0802 07:11:25.097241  2592 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0802 07:11:25.097259  2592 net.cpp:91] Creating Layer reshape_stage_indicator
I0802 07:11:25.097265  2592 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0802 07:11:25.097272  2592 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0802 07:11:25.097306  2592 net.cpp:141] Setting up reshape_stage_indicator
I0802 07:11:25.097314  2592 net.cpp:148] Top shape: 1 1 1 (1)
I0802 07:11:25.097318  2592 net.cpp:156] Memory required for data: 20408
I0802 07:11:25.097322  2592 layer_factory.hpp:77] Creating layer embedding
I0802 07:11:25.097333  2592 net.cpp:91] Creating Layer embedding
I0802 07:11:25.097337  2592 net.cpp:425] embedding <- input_sentence
I0802 07:11:25.097352  2592 net.cpp:399] embedding -> embedded_input_sentence
I0802 07:11:25.308961  2592 net.cpp:141] Setting up embedding
I0802 07:11:25.309021  2592 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:25.309026  2592 net.cpp:156] Memory required for data: 22408
I0802 07:11:25.309043  2592 layer_factory.hpp:77] Creating layer lstm1
I0802 07:11:25.309063  2592 net.cpp:91] Creating Layer lstm1
I0802 07:11:25.309072  2592 net.cpp:425] lstm1 <- embedded_input_frames
I0802 07:11:25.309079  2592 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0802 07:11:25.309088  2592 net.cpp:399] lstm1 -> lstm1
I0802 07:11:25.309118  2592 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0802 07:11:25.309444  2592 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0802 07:11:25.309535  2592 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:25.309548  2592 net.cpp:91] Creating Layer lstm1_
I0802 07:11:25.309554  2592 net.cpp:399] lstm1_ -> x
I0802 07:11:25.309566  2592 net.cpp:399] lstm1_ -> cont
I0802 07:11:25.309921  2592 net.cpp:141] Setting up lstm1_
I0802 07:11:25.309932  2592 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:25.309938  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.309942  2592 net.cpp:156] Memory required for data: 2004
I0802 07:11:25.309947  2592 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:25.309962  2592 net.cpp:91] Creating Layer lstm1_
I0802 07:11:25.309967  2592 net.cpp:399] lstm1_ -> c_0
I0802 07:11:25.309979  2592 net.cpp:399] lstm1_ -> h_0
I0802 07:11:25.310183  2592 net.cpp:141] Setting up lstm1_
I0802 07:11:25.310192  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.310199  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.310201  2592 net.cpp:156] Memory required for data: 10004
I0802 07:11:25.310206  2592 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0802 07:11:25.310220  2592 net.cpp:91] Creating Layer lstm1_cont_slice
I0802 07:11:25.310225  2592 net.cpp:425] lstm1_cont_slice <- cont
I0802 07:11:25.310231  2592 net.cpp:399] lstm1_cont_slice -> cont_1
I0802 07:11:25.310271  2592 net.cpp:141] Setting up lstm1_cont_slice
I0802 07:11:25.310279  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.310283  2592 net.cpp:156] Memory required for data: 10008
I0802 07:11:25.310288  2592 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0802 07:11:25.310295  2592 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0802 07:11:25.310299  2592 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0802 07:11:25.310309  2592 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0802 07:11:25.310318  2592 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0802 07:11:25.310374  2592 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0802 07:11:25.310384  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.310389  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.310392  2592 net.cpp:156] Memory required for data: 10016
I0802 07:11:25.310396  2592 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0802 07:11:25.310408  2592 net.cpp:91] Creating Layer lstm1_x_transform
I0802 07:11:25.310413  2592 net.cpp:425] lstm1_x_transform <- x
I0802 07:11:25.310420  2592 net.cpp:399] lstm1_x_transform -> W_xc_x
I0802 07:11:25.315248  2602 net.cpp:141] Setting up conv1
I0802 07:11:25.315275  2602 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0802 07:11:25.315281  2602 net.cpp:156] Memory required for data: 17799480
I0802 07:11:25.315297  2602 layer_factory.hpp:77] Creating layer relu1
I0802 07:11:25.315310  2602 net.cpp:91] Creating Layer relu1
I0802 07:11:25.315315  2602 net.cpp:425] relu1 <- conv1
I0802 07:11:25.315321  2602 net.cpp:386] relu1 -> conv1 (in-place)
I0802 07:11:25.315771  2602 net.cpp:141] Setting up relu1
I0802 07:11:25.315784  2602 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0802 07:11:25.315789  2602 net.cpp:156] Memory required for data: 29415480
I0802 07:11:25.315794  2602 layer_factory.hpp:77] Creating layer pool1
I0802 07:11:25.315805  2602 net.cpp:91] Creating Layer pool1
I0802 07:11:25.315810  2602 net.cpp:425] pool1 <- conv1
I0802 07:11:25.315819  2602 net.cpp:399] pool1 -> pool1
I0802 07:11:25.315884  2602 net.cpp:141] Setting up pool1
I0802 07:11:25.315894  2602 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0802 07:11:25.315898  2602 net.cpp:156] Memory required for data: 32214840
I0802 07:11:25.315903  2602 layer_factory.hpp:77] Creating layer norm1
I0802 07:11:25.315917  2602 net.cpp:91] Creating Layer norm1
I0802 07:11:25.315922  2602 net.cpp:425] norm1 <- pool1
I0802 07:11:25.315929  2602 net.cpp:399] norm1 -> norm1
I0802 07:11:25.316404  2602 net.cpp:141] Setting up norm1
I0802 07:11:25.316418  2602 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0802 07:11:25.316422  2602 net.cpp:156] Memory required for data: 35014200
I0802 07:11:25.316428  2602 layer_factory.hpp:77] Creating layer conv2
I0802 07:11:25.316442  2602 net.cpp:91] Creating Layer conv2
I0802 07:11:25.316447  2602 net.cpp:425] conv2 <- norm1
I0802 07:11:25.316455  2602 net.cpp:399] conv2 -> conv2
I0802 07:11:25.319504  2602 net.cpp:141] Setting up conv2
I0802 07:11:25.319519  2602 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0802 07:11:25.319525  2602 net.cpp:156] Memory required for data: 42479160
I0802 07:11:25.319536  2602 layer_factory.hpp:77] Creating layer relu2
I0802 07:11:25.319545  2602 net.cpp:91] Creating Layer relu2
I0802 07:11:25.319551  2602 net.cpp:425] relu2 <- conv2
I0802 07:11:25.319557  2602 net.cpp:386] relu2 -> conv2 (in-place)
I0802 07:11:25.319983  2602 net.cpp:141] Setting up relu2
I0802 07:11:25.320000  2602 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0802 07:11:25.320013  2602 net.cpp:156] Memory required for data: 49944120
I0802 07:11:25.320019  2602 layer_factory.hpp:77] Creating layer pool2
I0802 07:11:25.320029  2602 net.cpp:91] Creating Layer pool2
I0802 07:11:25.320034  2602 net.cpp:425] pool2 <- conv2
I0802 07:11:25.320041  2602 net.cpp:399] pool2 -> pool2
I0802 07:11:25.320094  2602 net.cpp:141] Setting up pool2
I0802 07:11:25.320103  2602 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:25.320108  2602 net.cpp:156] Memory required for data: 51674680
I0802 07:11:25.320112  2602 layer_factory.hpp:77] Creating layer norm2
I0802 07:11:25.320122  2602 net.cpp:91] Creating Layer norm2
I0802 07:11:25.320127  2602 net.cpp:425] norm2 <- pool2
I0802 07:11:25.320134  2602 net.cpp:399] norm2 -> norm2
I0802 07:11:25.320370  2602 net.cpp:141] Setting up norm2
I0802 07:11:25.320382  2602 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:25.320387  2602 net.cpp:156] Memory required for data: 53405240
I0802 07:11:25.320392  2602 layer_factory.hpp:77] Creating layer conv3
I0802 07:11:25.320403  2602 net.cpp:91] Creating Layer conv3
I0802 07:11:25.320408  2602 net.cpp:425] conv3 <- norm2
I0802 07:11:25.320415  2602 net.cpp:399] conv3 -> conv3
I0802 07:11:25.324077  2602 net.cpp:141] Setting up conv3
I0802 07:11:25.324092  2602 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:25.324097  2602 net.cpp:156] Memory required for data: 56001080
I0802 07:11:25.324110  2602 layer_factory.hpp:77] Creating layer relu3
I0802 07:11:25.324123  2602 net.cpp:91] Creating Layer relu3
I0802 07:11:25.324128  2602 net.cpp:425] relu3 <- conv3
I0802 07:11:25.324136  2602 net.cpp:386] relu3 -> conv3 (in-place)
I0802 07:11:25.324573  2602 net.cpp:141] Setting up relu3
I0802 07:11:25.324586  2602 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:25.324590  2602 net.cpp:156] Memory required for data: 58596920
I0802 07:11:25.324595  2602 layer_factory.hpp:77] Creating layer conv4
I0802 07:11:25.324609  2602 net.cpp:91] Creating Layer conv4
I0802 07:11:25.324615  2602 net.cpp:425] conv4 <- conv3
I0802 07:11:25.324625  2602 net.cpp:399] conv4 -> conv4
I0802 07:11:25.328605  2602 net.cpp:141] Setting up conv4
I0802 07:11:25.328624  2602 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:25.328629  2602 net.cpp:156] Memory required for data: 61192760
I0802 07:11:25.328637  2602 layer_factory.hpp:77] Creating layer relu4
I0802 07:11:25.328646  2602 net.cpp:91] Creating Layer relu4
I0802 07:11:25.328651  2602 net.cpp:425] relu4 <- conv4
I0802 07:11:25.328657  2602 net.cpp:386] relu4 -> conv4 (in-place)
I0802 07:11:25.329097  2602 net.cpp:141] Setting up relu4
I0802 07:11:25.329110  2602 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:25.329114  2602 net.cpp:156] Memory required for data: 63788600
I0802 07:11:25.329119  2602 layer_factory.hpp:77] Creating layer conv5
I0802 07:11:25.329130  2602 net.cpp:91] Creating Layer conv5
I0802 07:11:25.329135  2602 net.cpp:425] conv5 <- conv4
I0802 07:11:25.329145  2602 net.cpp:399] conv5 -> conv5
I0802 07:11:25.330478  2592 net.cpp:141] Setting up lstm1_x_transform
I0802 07:11:25.330493  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.330498  2592 net.cpp:156] Memory required for data: 26016
I0802 07:11:25.330510  2592 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0802 07:11:25.330520  2592 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0802 07:11:25.330525  2592 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0802 07:11:25.330533  2592 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0802 07:11:25.330576  2592 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0802 07:11:25.330586  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.330590  2592 net.cpp:156] Memory required for data: 42016
I0802 07:11:25.330595  2592 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0802 07:11:25.330610  2592 net.cpp:91] Creating Layer lstm1_h_conted_0
I0802 07:11:25.330615  2592 net.cpp:425] lstm1_h_conted_0 <- h_0
I0802 07:11:25.330621  2592 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0802 07:11:25.330627  2592 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0802 07:11:25.330936  2592 net.cpp:141] Setting up lstm1_h_conted_0
I0802 07:11:25.330947  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.330951  2592 net.cpp:156] Memory required for data: 46016
I0802 07:11:25.330955  2592 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0802 07:11:25.330976  2592 net.cpp:91] Creating Layer lstm1_transform_1
I0802 07:11:25.330982  2592 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0802 07:11:25.330991  2592 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0802 07:11:25.340512  2602 net.cpp:141] Setting up conv5
I0802 07:11:25.340574  2602 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:25.340579  2602 net.cpp:156] Memory required for data: 65519160
I0802 07:11:25.340600  2602 layer_factory.hpp:77] Creating layer relu5
I0802 07:11:25.340615  2602 net.cpp:91] Creating Layer relu5
I0802 07:11:25.340620  2602 net.cpp:425] relu5 <- conv5
I0802 07:11:25.340633  2602 net.cpp:386] relu5 -> conv5 (in-place)
I0802 07:11:25.341086  2602 net.cpp:141] Setting up relu5
I0802 07:11:25.341099  2602 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:25.341104  2602 net.cpp:156] Memory required for data: 67249720
I0802 07:11:25.341109  2602 layer_factory.hpp:77] Creating layer pool5
I0802 07:11:25.341119  2602 net.cpp:91] Creating Layer pool5
I0802 07:11:25.341123  2602 net.cpp:425] pool5 <- conv5
I0802 07:11:25.341135  2602 net.cpp:399] pool5 -> pool5
I0802 07:11:25.341197  2602 net.cpp:141] Setting up pool5
I0802 07:11:25.341207  2602 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0802 07:11:25.341212  2602 net.cpp:156] Memory required for data: 67618360
I0802 07:11:25.341217  2602 layer_factory.hpp:77] Creating layer fc6
I0802 07:11:25.341234  2602 net.cpp:91] Creating Layer fc6
I0802 07:11:25.341239  2602 net.cpp:425] fc6 <- pool5
I0802 07:11:25.341248  2602 net.cpp:399] fc6 -> fc6
I0802 07:11:25.402395  2592 net.cpp:141] Setting up lstm1_transform_1
I0802 07:11:25.402447  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.402453  2592 net.cpp:156] Memory required for data: 62016
I0802 07:11:25.402474  2592 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0802 07:11:25.402493  2592 net.cpp:91] Creating Layer lstm1_gate_input_1
I0802 07:11:25.402499  2592 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0802 07:11:25.402508  2592 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0802 07:11:25.402518  2592 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0802 07:11:25.402582  2592 net.cpp:141] Setting up lstm1_gate_input_1
I0802 07:11:25.402591  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.402595  2592 net.cpp:156] Memory required for data: 78016
I0802 07:11:25.402601  2592 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0802 07:11:25.402613  2592 net.cpp:91] Creating Layer lstm1_unit_1
I0802 07:11:25.402618  2592 net.cpp:425] lstm1_unit_1 <- c_0
I0802 07:11:25.402624  2592 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0802 07:11:25.402629  2592 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0802 07:11:25.402636  2592 net.cpp:399] lstm1_unit_1 -> c_1
I0802 07:11:25.402644  2592 net.cpp:399] lstm1_unit_1 -> h_1
I0802 07:11:25.402709  2592 net.cpp:141] Setting up lstm1_unit_1
I0802 07:11:25.402717  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.402724  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.402727  2592 net.cpp:156] Memory required for data: 86016
I0802 07:11:25.402732  2592 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:25.402740  2592 net.cpp:91] Creating Layer lstm1_
I0802 07:11:25.402745  2592 net.cpp:425] lstm1_ <- c_1
I0802 07:11:25.402755  2592 net.cpp:399] lstm1_ -> c_T
I0802 07:11:25.402786  2592 net.cpp:141] Setting up lstm1_
I0802 07:11:25.402794  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.402798  2592 net.cpp:156] Memory required for data: 90016
I0802 07:11:25.402803  2592 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0802 07:11:25.402820  2592 net.cpp:91] Creating Layer lstm1_h_concat
I0802 07:11:25.402825  2592 net.cpp:425] lstm1_h_concat <- h_1
I0802 07:11:25.402832  2592 net.cpp:399] lstm1_h_concat -> h
I0802 07:11:25.402870  2592 net.cpp:141] Setting up lstm1_h_concat
I0802 07:11:25.402879  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.402884  2592 net.cpp:156] Memory required for data: 94016
I0802 07:11:25.402887  2592 layer_factory.hpp:77] Creating layer h_pseudoloss
I0802 07:11:25.402900  2592 net.cpp:91] Creating Layer h_pseudoloss
I0802 07:11:25.402905  2592 net.cpp:425] h_pseudoloss <- h
I0802 07:11:25.402912  2592 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0802 07:11:25.403003  2592 net.cpp:141] Setting up h_pseudoloss
I0802 07:11:25.403014  2592 net.cpp:148] Top shape: (1)
I0802 07:11:25.403018  2592 net.cpp:151]     with loss weight 1
I0802 07:11:25.403054  2592 net.cpp:156] Memory required for data: 94020
I0802 07:11:25.403059  2592 net.cpp:217] h_pseudoloss needs backward computation.
I0802 07:11:25.403064  2592 net.cpp:217] lstm1_h_concat needs backward computation.
I0802 07:11:25.403069  2592 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:25.403074  2592 net.cpp:217] lstm1_unit_1 needs backward computation.
I0802 07:11:25.403079  2592 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0802 07:11:25.403084  2592 net.cpp:217] lstm1_transform_1 needs backward computation.
I0802 07:11:25.403089  2592 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0802 07:11:25.403093  2592 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0802 07:11:25.403097  2592 net.cpp:217] lstm1_x_transform needs backward computation.
I0802 07:11:25.403102  2592 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0802 07:11:25.403107  2592 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0802 07:11:25.403112  2592 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:25.403115  2592 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:25.403120  2592 net.cpp:261] This network produces output c_T
I0802 07:11:25.403123  2592 net.cpp:261] This network produces output h_pseudoloss
I0802 07:11:25.403138  2592 net.cpp:274] Network initialization done.
I0802 07:11:25.403195  2592 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0802 07:11:25.403201  2592 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0802 07:11:25.403206  2592 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0802 07:11:25.403314  2592 net.cpp:141] Setting up lstm1
I0802 07:11:25.403331  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.403334  2592 net.cpp:156] Memory required for data: 26408
I0802 07:11:25.403347  2592 layer_factory.hpp:77] Creating layer concat
I0802 07:11:25.403357  2592 net.cpp:91] Creating Layer concat
I0802 07:11:25.403362  2592 net.cpp:425] concat <- lstm1
I0802 07:11:25.403368  2592 net.cpp:425] concat <- embedded_input_sentence
I0802 07:11:25.403373  2592 net.cpp:425] concat <- reshaped_stage_indicator
I0802 07:11:25.403380  2592 net.cpp:399] concat -> lstm1_video_sequence
I0802 07:11:25.403412  2592 net.cpp:141] Setting up concat
I0802 07:11:25.403421  2592 net.cpp:148] Top shape: 1 1 1501 (1501)
I0802 07:11:25.403425  2592 net.cpp:156] Memory required for data: 32412
I0802 07:11:25.403429  2592 layer_factory.hpp:77] Creating layer lstm2
I0802 07:11:25.403441  2592 net.cpp:91] Creating Layer lstm2
I0802 07:11:25.403445  2592 net.cpp:425] lstm2 <- lstm1_video_sequence
I0802 07:11:25.403451  2592 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0802 07:11:25.403458  2592 net.cpp:399] lstm2 -> lstm2
I0802 07:11:25.403467  2592 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0802 07:11:25.403702  2592 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0802 07:11:25.403785  2592 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:25.403797  2592 net.cpp:91] Creating Layer lstm2_
I0802 07:11:25.403803  2592 net.cpp:399] lstm2_ -> x
I0802 07:11:25.403815  2592 net.cpp:399] lstm2_ -> cont
I0802 07:11:25.403867  2592 net.cpp:141] Setting up lstm2_
I0802 07:11:25.403877  2592 net.cpp:148] Top shape: 1 1 1501 (1501)
I0802 07:11:25.403882  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.403887  2592 net.cpp:156] Memory required for data: 6008
I0802 07:11:25.403892  2592 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:25.403903  2592 net.cpp:91] Creating Layer lstm2_
I0802 07:11:25.403910  2592 net.cpp:399] lstm2_ -> c_0
I0802 07:11:25.403919  2592 net.cpp:399] lstm2_ -> h_0
I0802 07:11:25.403972  2592 net.cpp:141] Setting up lstm2_
I0802 07:11:25.403982  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.403987  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.403991  2592 net.cpp:156] Memory required for data: 14008
I0802 07:11:25.403995  2592 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0802 07:11:25.404005  2592 net.cpp:91] Creating Layer lstm2_cont_slice
I0802 07:11:25.404021  2592 net.cpp:425] lstm2_cont_slice <- cont
I0802 07:11:25.404027  2592 net.cpp:399] lstm2_cont_slice -> cont_1
I0802 07:11:25.404067  2592 net.cpp:141] Setting up lstm2_cont_slice
I0802 07:11:25.404075  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.404079  2592 net.cpp:156] Memory required for data: 14012
I0802 07:11:25.404084  2592 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0802 07:11:25.404090  2592 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0802 07:11:25.404095  2592 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0802 07:11:25.404103  2592 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0802 07:11:25.404111  2592 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0802 07:11:25.404157  2592 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0802 07:11:25.404168  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.404173  2592 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:25.404177  2592 net.cpp:156] Memory required for data: 14020
I0802 07:11:25.404182  2592 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0802 07:11:25.404191  2592 net.cpp:91] Creating Layer lstm2_x_transform
I0802 07:11:25.404196  2592 net.cpp:425] lstm2_x_transform <- x
I0802 07:11:25.404206  2592 net.cpp:399] lstm2_x_transform -> W_xc_x
I0802 07:11:25.442095  2602 net.cpp:141] Setting up fc6
I0802 07:11:25.442160  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.442167  2602 net.cpp:156] Memory required for data: 67782200
I0802 07:11:25.442181  2602 layer_factory.hpp:77] Creating layer relu6
I0802 07:11:25.442199  2602 net.cpp:91] Creating Layer relu6
I0802 07:11:25.442206  2602 net.cpp:425] relu6 <- fc6
I0802 07:11:25.442214  2602 net.cpp:386] relu6 -> fc6 (in-place)
I0802 07:11:25.442534  2602 net.cpp:141] Setting up relu6
I0802 07:11:25.442546  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.442550  2602 net.cpp:156] Memory required for data: 67946040
I0802 07:11:25.442555  2602 layer_factory.hpp:77] Creating layer drop6
I0802 07:11:25.442564  2602 net.cpp:91] Creating Layer drop6
I0802 07:11:25.442569  2602 net.cpp:425] drop6 <- fc6
I0802 07:11:25.442579  2602 net.cpp:386] drop6 -> fc6 (in-place)
I0802 07:11:25.442627  2602 net.cpp:141] Setting up drop6
I0802 07:11:25.442638  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.442643  2602 net.cpp:156] Memory required for data: 68109880
I0802 07:11:25.442648  2602 layer_factory.hpp:77] Creating layer fc7
I0802 07:11:25.442657  2602 net.cpp:91] Creating Layer fc7
I0802 07:11:25.442662  2602 net.cpp:425] fc7 <- fc6
I0802 07:11:25.442668  2602 net.cpp:399] fc7 -> fc7
I0802 07:11:25.470541  2592 net.cpp:141] Setting up lstm2_x_transform
I0802 07:11:25.470608  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.470615  2592 net.cpp:156] Memory required for data: 30020
I0802 07:11:25.470636  2592 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0802 07:11:25.470651  2592 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0802 07:11:25.470659  2592 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0802 07:11:25.470669  2592 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0802 07:11:25.470719  2592 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0802 07:11:25.470731  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.470734  2592 net.cpp:156] Memory required for data: 46020
I0802 07:11:25.470739  2592 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0802 07:11:25.470749  2592 net.cpp:91] Creating Layer lstm2_h_conted_0
I0802 07:11:25.470753  2592 net.cpp:425] lstm2_h_conted_0 <- h_0
I0802 07:11:25.470759  2592 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0802 07:11:25.470767  2592 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0802 07:11:25.470863  2592 net.cpp:141] Setting up lstm2_h_conted_0
I0802 07:11:25.470873  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.470877  2592 net.cpp:156] Memory required for data: 50020
I0802 07:11:25.470881  2592 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0802 07:11:25.470893  2592 net.cpp:91] Creating Layer lstm2_transform_1
I0802 07:11:25.470898  2592 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0802 07:11:25.470906  2592 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0802 07:11:25.487182  2602 net.cpp:141] Setting up fc7
I0802 07:11:25.487251  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.487257  2602 net.cpp:156] Memory required for data: 68273720
I0802 07:11:25.487272  2602 layer_factory.hpp:77] Creating layer relu7
I0802 07:11:25.487285  2602 net.cpp:91] Creating Layer relu7
I0802 07:11:25.487290  2602 net.cpp:425] relu7 <- fc7
I0802 07:11:25.487303  2602 net.cpp:386] relu7 -> fc7 (in-place)
I0802 07:11:25.488100  2602 net.cpp:141] Setting up relu7
I0802 07:11:25.488112  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.488116  2602 net.cpp:156] Memory required for data: 68437560
I0802 07:11:25.488121  2602 layer_factory.hpp:77] Creating layer drop7
I0802 07:11:25.488134  2602 net.cpp:91] Creating Layer drop7
I0802 07:11:25.488139  2602 net.cpp:425] drop7 <- fc7
I0802 07:11:25.488145  2602 net.cpp:386] drop7 -> fc7 (in-place)
I0802 07:11:25.488183  2602 net.cpp:141] Setting up drop7
I0802 07:11:25.488190  2602 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:25.488195  2602 net.cpp:156] Memory required for data: 68601400
I0802 07:11:25.488199  2602 layer_factory.hpp:77] Creating layer fc8
I0802 07:11:25.488214  2602 net.cpp:91] Creating Layer fc8
I0802 07:11:25.488219  2602 net.cpp:425] fc8 <- fc7
I0802 07:11:25.488227  2602 net.cpp:399] fc8 -> fc8
I0802 07:11:25.499487  2602 net.cpp:141] Setting up fc8
I0802 07:11:25.499548  2602 net.cpp:148] Top shape: 10 1000 (10000)
I0802 07:11:25.499554  2602 net.cpp:156] Memory required for data: 68641400
I0802 07:11:25.499568  2602 layer_factory.hpp:77] Creating layer prob
I0802 07:11:25.499589  2602 net.cpp:91] Creating Layer prob
I0802 07:11:25.499595  2602 net.cpp:425] prob <- fc8
I0802 07:11:25.499604  2602 net.cpp:399] prob -> prob
I0802 07:11:25.500016  2602 net.cpp:141] Setting up prob
I0802 07:11:25.500035  2602 net.cpp:148] Top shape: 10 1000 (10000)
I0802 07:11:25.500039  2602 net.cpp:156] Memory required for data: 68681400
I0802 07:11:25.500044  2602 net.cpp:219] prob does not need backward computation.
I0802 07:11:25.500049  2602 net.cpp:219] fc8 does not need backward computation.
I0802 07:11:25.500053  2602 net.cpp:219] drop7 does not need backward computation.
I0802 07:11:25.500058  2602 net.cpp:219] relu7 does not need backward computation.
I0802 07:11:25.500062  2602 net.cpp:219] fc7 does not need backward computation.
I0802 07:11:25.500066  2602 net.cpp:219] drop6 does not need backward computation.
I0802 07:11:25.500071  2602 net.cpp:219] relu6 does not need backward computation.
I0802 07:11:25.500075  2602 net.cpp:219] fc6 does not need backward computation.
I0802 07:11:25.500079  2602 net.cpp:219] pool5 does not need backward computation.
I0802 07:11:25.500083  2602 net.cpp:219] relu5 does not need backward computation.
I0802 07:11:25.500088  2602 net.cpp:219] conv5 does not need backward computation.
I0802 07:11:25.500092  2602 net.cpp:219] relu4 does not need backward computation.
I0802 07:11:25.500097  2602 net.cpp:219] conv4 does not need backward computation.
I0802 07:11:25.500100  2602 net.cpp:219] relu3 does not need backward computation.
I0802 07:11:25.500104  2602 net.cpp:219] conv3 does not need backward computation.
I0802 07:11:25.500109  2602 net.cpp:219] norm2 does not need backward computation.
I0802 07:11:25.500114  2602 net.cpp:219] pool2 does not need backward computation.
I0802 07:11:25.500118  2602 net.cpp:219] relu2 does not need backward computation.
I0802 07:11:25.500123  2602 net.cpp:219] conv2 does not need backward computation.
I0802 07:11:25.500126  2602 net.cpp:219] norm1 does not need backward computation.
I0802 07:11:25.500130  2602 net.cpp:219] pool1 does not need backward computation.
I0802 07:11:25.500134  2602 net.cpp:219] relu1 does not need backward computation.
I0802 07:11:25.500138  2602 net.cpp:219] conv1 does not need backward computation.
I0802 07:11:25.500143  2602 net.cpp:219] data does not need backward computation.
I0802 07:11:25.500147  2602 net.cpp:261] This network produces output prob
I0802 07:11:25.500165  2602 net.cpp:274] Network initialization done.
I0802 07:11:25.509264  2592 net.cpp:141] Setting up lstm2_transform_1
I0802 07:11:25.509320  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.509325  2592 net.cpp:156] Memory required for data: 66020
I0802 07:11:25.509342  2592 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0802 07:11:25.509361  2592 net.cpp:91] Creating Layer lstm2_gate_input_1
I0802 07:11:25.509366  2592 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0802 07:11:25.509374  2592 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0802 07:11:25.509382  2592 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0802 07:11:25.509434  2592 net.cpp:141] Setting up lstm2_gate_input_1
I0802 07:11:25.509444  2592 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:25.509449  2592 net.cpp:156] Memory required for data: 82020
I0802 07:11:25.509452  2592 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0802 07:11:25.509461  2592 net.cpp:91] Creating Layer lstm2_unit_1
I0802 07:11:25.509469  2592 net.cpp:425] lstm2_unit_1 <- c_0
I0802 07:11:25.509474  2592 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0802 07:11:25.509479  2592 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0802 07:11:25.509485  2592 net.cpp:399] lstm2_unit_1 -> c_1
I0802 07:11:25.509493  2592 net.cpp:399] lstm2_unit_1 -> h_1
I0802 07:11:25.509554  2592 net.cpp:141] Setting up lstm2_unit_1
I0802 07:11:25.509563  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.509569  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.509573  2592 net.cpp:156] Memory required for data: 90020
I0802 07:11:25.509577  2592 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:25.509588  2592 net.cpp:91] Creating Layer lstm2_
I0802 07:11:25.509593  2592 net.cpp:425] lstm2_ <- c_1
I0802 07:11:25.509600  2592 net.cpp:399] lstm2_ -> c_T
I0802 07:11:25.509630  2592 net.cpp:141] Setting up lstm2_
I0802 07:11:25.509639  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.509644  2592 net.cpp:156] Memory required for data: 94020
I0802 07:11:25.509649  2592 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0802 07:11:25.509656  2592 net.cpp:91] Creating Layer lstm2_h_concat
I0802 07:11:25.509661  2592 net.cpp:425] lstm2_h_concat <- h_1
I0802 07:11:25.509671  2592 net.cpp:399] lstm2_h_concat -> h
I0802 07:11:25.509708  2592 net.cpp:141] Setting up lstm2_h_concat
I0802 07:11:25.509716  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.509721  2592 net.cpp:156] Memory required for data: 98020
I0802 07:11:25.509726  2592 layer_factory.hpp:77] Creating layer h_pseudoloss
I0802 07:11:25.509733  2592 net.cpp:91] Creating Layer h_pseudoloss
I0802 07:11:25.509737  2592 net.cpp:425] h_pseudoloss <- h
I0802 07:11:25.509743  2592 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0802 07:11:25.510210  2592 net.cpp:141] Setting up h_pseudoloss
I0802 07:11:25.510228  2592 net.cpp:148] Top shape: (1)
I0802 07:11:25.510233  2592 net.cpp:151]     with loss weight 1
I0802 07:11:25.510251  2592 net.cpp:156] Memory required for data: 98024
I0802 07:11:25.510257  2592 net.cpp:217] h_pseudoloss needs backward computation.
I0802 07:11:25.510262  2592 net.cpp:217] lstm2_h_concat needs backward computation.
I0802 07:11:25.510267  2592 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:25.510272  2592 net.cpp:217] lstm2_unit_1 needs backward computation.
I0802 07:11:25.510277  2592 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0802 07:11:25.510282  2592 net.cpp:217] lstm2_transform_1 needs backward computation.
I0802 07:11:25.510287  2592 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0802 07:11:25.510294  2592 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0802 07:11:25.510299  2592 net.cpp:217] lstm2_x_transform needs backward computation.
I0802 07:11:25.510304  2592 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0802 07:11:25.510309  2592 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0802 07:11:25.510314  2592 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:25.510318  2592 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:25.510323  2592 net.cpp:261] This network produces output c_T
I0802 07:11:25.510326  2592 net.cpp:261] This network produces output h_pseudoloss
I0802 07:11:25.510340  2592 net.cpp:274] Network initialization done.
I0802 07:11:25.510385  2592 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0802 07:11:25.510391  2592 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0802 07:11:25.510396  2592 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0802 07:11:25.510512  2592 net.cpp:141] Setting up lstm2
I0802 07:11:25.510524  2592 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:25.510527  2592 net.cpp:156] Memory required for data: 36412
I0802 07:11:25.510541  2592 layer_factory.hpp:77] Creating layer predict
I0802 07:11:25.510553  2592 net.cpp:91] Creating Layer predict
I0802 07:11:25.510560  2592 net.cpp:425] predict <- lstm2
I0802 07:11:25.510566  2592 net.cpp:399] predict -> predict
I0802 07:11:25.721993  2602 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld7396311930794007874/bvlc_reference_caffenet.caffemodel
I0802 07:11:25.722044  2602 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0802 07:11:25.722049  2602 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0802 07:11:25.722054  2602 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld7396311930794007874/bvlc_reference_caffenet.caffemodel
I0802 07:11:25.972331  2592 net.cpp:141] Setting up predict
I0802 07:11:25.972405  2592 net.cpp:148] Top shape: 1 1 46168 (46168)
I0802 07:11:25.972412  2592 net.cpp:156] Memory required for data: 221084
I0802 07:11:25.972430  2592 layer_factory.hpp:77] Creating layer probs
I0802 07:11:25.972451  2592 net.cpp:91] Creating Layer probs
I0802 07:11:25.972460  2592 net.cpp:425] probs <- predict
I0802 07:11:25.972472  2592 net.cpp:399] probs -> probs
I0802 07:11:25.973537  2592 net.cpp:141] Setting up probs
I0802 07:11:25.973553  2592 net.cpp:148] Top shape: 1 1 46168 (46168)
I0802 07:11:25.973558  2592 net.cpp:156] Memory required for data: 405756
I0802 07:11:25.973565  2592 net.cpp:219] probs does not need backward computation.
I0802 07:11:25.973572  2592 net.cpp:219] predict does not need backward computation.
I0802 07:11:25.973577  2592 net.cpp:219] lstm2 does not need backward computation.
I0802 07:11:25.973583  2592 net.cpp:219] concat does not need backward computation.
I0802 07:11:25.973590  2592 net.cpp:219] lstm1 does not need backward computation.
I0802 07:11:25.973597  2592 net.cpp:219] embedding does not need backward computation.
I0802 07:11:25.973603  2592 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0802 07:11:25.973613  2592 net.cpp:219] reshape_frames does not need backward computation.
I0802 07:11:25.973619  2592 net.cpp:219] embed_encoder does not need backward computation.
I0802 07:11:25.973625  2592 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0802 07:11:25.973631  2592 net.cpp:219] input does not need backward computation.
I0802 07:11:25.973636  2592 net.cpp:261] This network produces output probs
I0802 07:11:25.973652  2592 net.cpp:274] Network initialization done.
I0802 07:11:26.105489  2602 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0802 07:11:26.168270  2602 net.cpp:752] Ignoring source layer loss
I0802 07:11:26.365738  2592 net.cpp:752] Ignoring source layer data
I0802 07:11:26.365780  2592 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0802 07:11:26.365787  2592 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0802 07:11:26.481205  2592 net.cpp:752] Ignoring source layer cross_entropy_loss
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1470136239/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-08-02 07:11:39,562 ERROR Logger contains an invalid element or attribute "appender"
2016-08-02 07:11:42,510 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld4755157273230229825/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0802 07:11:49.274821  2761 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0802 07:11:49.275017  2761 layer_factory.hpp:77] Creating layer data
I0802 07:11:49.275040  2761 net.cpp:91] Creating Layer data
I0802 07:11:49.275051  2761 net.cpp:399] data -> data
I0802 07:11:49.749769  2761 net.cpp:141] Setting up data
I0802 07:11:49.749873  2761 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0802 07:11:49.749881  2761 net.cpp:156] Memory required for data: 6183480
I0802 07:11:49.749902  2761 layer_factory.hpp:77] Creating layer conv1
I0802 07:11:49.749934  2761 net.cpp:91] Creating Layer conv1
I0802 07:11:49.749943  2761 net.cpp:425] conv1 <- data
I0802 07:11:49.749958  2761 net.cpp:399] conv1 -> conv1
I0802 07:11:49.977172  2761 net.cpp:141] Setting up conv1
I0802 07:11:49.977222  2761 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0802 07:11:49.977231  2761 net.cpp:156] Memory required for data: 17799480
I0802 07:11:49.977260  2761 layer_factory.hpp:77] Creating layer relu1
I0802 07:11:49.977280  2761 net.cpp:91] Creating Layer relu1
I0802 07:11:49.977288  2761 net.cpp:425] relu1 <- conv1
I0802 07:11:49.977298  2761 net.cpp:386] relu1 -> conv1 (in-place)
I0802 07:11:49.977783  2761 net.cpp:141] Setting up relu1
I0802 07:11:49.977799  2761 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0802 07:11:49.977805  2761 net.cpp:156] Memory required for data: 29415480
I0802 07:11:49.977812  2761 layer_factory.hpp:77] Creating layer pool1
I0802 07:11:49.977825  2761 net.cpp:91] Creating Layer pool1
I0802 07:11:49.977830  2761 net.cpp:425] pool1 <- conv1
I0802 07:11:49.977838  2761 net.cpp:399] pool1 -> pool1
I0802 07:11:49.977916  2761 net.cpp:141] Setting up pool1
I0802 07:11:49.977928  2761 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0802 07:11:49.977933  2761 net.cpp:156] Memory required for data: 32214840
I0802 07:11:49.977939  2761 layer_factory.hpp:77] Creating layer norm1
I0802 07:11:49.977957  2761 net.cpp:91] Creating Layer norm1
I0802 07:11:49.977962  2761 net.cpp:425] norm1 <- pool1
I0802 07:11:49.977969  2761 net.cpp:399] norm1 -> norm1
I0802 07:11:49.978487  2761 net.cpp:141] Setting up norm1
I0802 07:11:49.978502  2761 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0802 07:11:49.978507  2761 net.cpp:156] Memory required for data: 35014200
I0802 07:11:49.978513  2761 layer_factory.hpp:77] Creating layer conv2
I0802 07:11:49.978531  2761 net.cpp:91] Creating Layer conv2
I0802 07:11:49.978538  2761 net.cpp:425] conv2 <- norm1
I0802 07:11:49.978545  2761 net.cpp:399] conv2 -> conv2
I0802 07:11:49.982771  2761 net.cpp:141] Setting up conv2
I0802 07:11:49.982794  2761 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0802 07:11:49.982800  2761 net.cpp:156] Memory required for data: 42479160
I0802 07:11:49.982813  2761 layer_factory.hpp:77] Creating layer relu2
I0802 07:11:49.982825  2761 net.cpp:91] Creating Layer relu2
I0802 07:11:49.982831  2761 net.cpp:425] relu2 <- conv2
I0802 07:11:49.982838  2761 net.cpp:386] relu2 -> conv2 (in-place)
I0802 07:11:49.983324  2761 net.cpp:141] Setting up relu2
I0802 07:11:49.983338  2761 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0802 07:11:49.983345  2761 net.cpp:156] Memory required for data: 49944120
I0802 07:11:49.983350  2761 layer_factory.hpp:77] Creating layer pool2
I0802 07:11:49.983361  2761 net.cpp:91] Creating Layer pool2
I0802 07:11:49.983366  2761 net.cpp:425] pool2 <- conv2
I0802 07:11:49.983376  2761 net.cpp:399] pool2 -> pool2
I0802 07:11:49.983448  2761 net.cpp:141] Setting up pool2
I0802 07:11:49.983461  2761 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:49.983466  2761 net.cpp:156] Memory required for data: 51674680
I0802 07:11:49.983472  2761 layer_factory.hpp:77] Creating layer norm2
I0802 07:11:49.983485  2761 net.cpp:91] Creating Layer norm2
I0802 07:11:49.983491  2761 net.cpp:425] norm2 <- pool2
I0802 07:11:49.983500  2761 net.cpp:399] norm2 -> norm2
I0802 07:11:49.983791  2761 net.cpp:141] Setting up norm2
I0802 07:11:49.983805  2761 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:49.983814  2761 net.cpp:156] Memory required for data: 53405240
I0802 07:11:49.983824  2761 layer_factory.hpp:77] Creating layer conv3
I0802 07:11:49.983840  2761 net.cpp:91] Creating Layer conv3
I0802 07:11:49.983846  2761 net.cpp:425] conv3 <- norm2
I0802 07:11:49.983855  2761 net.cpp:399] conv3 -> conv3
I0802 07:11:49.987915  2761 net.cpp:141] Setting up conv3
I0802 07:11:49.987938  2761 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:49.987944  2761 net.cpp:156] Memory required for data: 56001080
I0802 07:11:49.987959  2761 layer_factory.hpp:77] Creating layer relu3
I0802 07:11:49.987970  2761 net.cpp:91] Creating Layer relu3
I0802 07:11:49.987977  2761 net.cpp:425] relu3 <- conv3
I0802 07:11:49.987985  2761 net.cpp:386] relu3 -> conv3 (in-place)
I0802 07:11:49.988484  2761 net.cpp:141] Setting up relu3
I0802 07:11:49.988499  2761 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:49.988504  2761 net.cpp:156] Memory required for data: 58596920
I0802 07:11:49.988510  2761 layer_factory.hpp:77] Creating layer conv4
I0802 07:11:49.988526  2761 net.cpp:91] Creating Layer conv4
I0802 07:11:49.988533  2761 net.cpp:425] conv4 <- conv3
I0802 07:11:49.988541  2761 net.cpp:399] conv4 -> conv4
I0802 07:11:49.994760  2761 net.cpp:141] Setting up conv4
I0802 07:11:49.994792  2761 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:49.994803  2761 net.cpp:156] Memory required for data: 61192760
I0802 07:11:49.994822  2761 layer_factory.hpp:77] Creating layer relu4
I0802 07:11:49.994843  2761 net.cpp:91] Creating Layer relu4
I0802 07:11:49.994854  2761 net.cpp:425] relu4 <- conv4
I0802 07:11:49.994868  2761 net.cpp:386] relu4 -> conv4 (in-place)
I0802 07:11:49.995556  2761 net.cpp:141] Setting up relu4
I0802 07:11:49.995579  2761 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0802 07:11:49.995589  2761 net.cpp:156] Memory required for data: 63788600
I0802 07:11:49.995599  2761 layer_factory.hpp:77] Creating layer conv5
I0802 07:11:49.995620  2761 net.cpp:91] Creating Layer conv5
I0802 07:11:49.995631  2761 net.cpp:425] conv5 <- conv4
I0802 07:11:49.995651  2761 net.cpp:399] conv5 -> conv5
I0802 07:11:50.001799  2761 net.cpp:141] Setting up conv5
I0802 07:11:50.001827  2761 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:50.001838  2761 net.cpp:156] Memory required for data: 65519160
I0802 07:11:50.001864  2761 layer_factory.hpp:77] Creating layer relu5
I0802 07:11:50.001883  2761 net.cpp:91] Creating Layer relu5
I0802 07:11:50.001889  2761 net.cpp:425] relu5 <- conv5
I0802 07:11:50.001899  2761 net.cpp:386] relu5 -> conv5 (in-place)
I0802 07:11:50.002413  2761 net.cpp:141] Setting up relu5
I0802 07:11:50.002429  2761 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0802 07:11:50.002436  2761 net.cpp:156] Memory required for data: 67249720
I0802 07:11:50.002442  2761 layer_factory.hpp:77] Creating layer pool5
I0802 07:11:50.002454  2761 net.cpp:91] Creating Layer pool5
I0802 07:11:50.002460  2761 net.cpp:425] pool5 <- conv5
I0802 07:11:50.002467  2761 net.cpp:399] pool5 -> pool5
I0802 07:11:50.002539  2761 net.cpp:141] Setting up pool5
I0802 07:11:50.002550  2761 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0802 07:11:50.002555  2761 net.cpp:156] Memory required for data: 67618360
I0802 07:11:50.002560  2761 layer_factory.hpp:77] Creating layer fc6
I0802 07:11:50.002589  2761 net.cpp:91] Creating Layer fc6
I0802 07:11:50.002595  2761 net.cpp:425] fc6 <- pool5
I0802 07:11:50.002604  2761 net.cpp:399] fc6 -> fc6
I0802 07:11:50.112746  2751 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld4755157273230229825/s2vt.words_to_preds.prototxt
I0802 07:11:50.112812  2751 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0802 07:11:50.112821  2751 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0802 07:11:50.113112  2751 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0802 07:11:50.113227  2751 layer_factory.hpp:77] Creating layer input
I0802 07:11:50.113245  2751 net.cpp:91] Creating Layer input
I0802 07:11:50.113255  2751 net.cpp:399] input -> frames_fc7
I0802 07:11:50.113275  2751 net.cpp:399] input -> cont_sentence
I0802 07:11:50.113287  2751 net.cpp:399] input -> input_sentence
I0802 07:11:50.113299  2751 net.cpp:399] input -> stage_indicator
I0802 07:11:50.113483  2751 net.cpp:141] Setting up input
I0802 07:11:50.113498  2751 net.cpp:148] Top shape: 1 4096 (4096)
I0802 07:11:50.113505  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.113512  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.113518  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.113523  2751 net.cpp:156] Memory required for data: 16396
I0802 07:11:50.113529  2751 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0802 07:11:50.113554  2751 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0802 07:11:50.113560  2751 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0802 07:11:50.113590  2751 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0802 07:11:50.113602  2751 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0802 07:11:50.113662  2751 net.cpp:141] Setting up cont_sentence_input_1_split
I0802 07:11:50.113679  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.113685  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.113690  2751 net.cpp:156] Memory required for data: 16404
I0802 07:11:50.113695  2751 layer_factory.hpp:77] Creating layer embed_encoder
I0802 07:11:50.113710  2751 net.cpp:91] Creating Layer embed_encoder
I0802 07:11:50.113716  2751 net.cpp:425] embed_encoder <- frames_fc7
I0802 07:11:50.113726  2751 net.cpp:399] embed_encoder -> embedded_in_frames
I0802 07:11:50.118871  2761 net.cpp:141] Setting up fc6
I0802 07:11:50.118924  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.118932  2761 net.cpp:156] Memory required for data: 67782200
I0802 07:11:50.118949  2761 layer_factory.hpp:77] Creating layer relu6
I0802 07:11:50.118968  2761 net.cpp:91] Creating Layer relu6
I0802 07:11:50.118974  2761 net.cpp:425] relu6 <- fc6
I0802 07:11:50.118984  2761 net.cpp:386] relu6 -> fc6 (in-place)
I0802 07:11:50.119390  2761 net.cpp:141] Setting up relu6
I0802 07:11:50.119405  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.119410  2761 net.cpp:156] Memory required for data: 67946040
I0802 07:11:50.119416  2761 layer_factory.hpp:77] Creating layer drop6
I0802 07:11:50.119431  2761 net.cpp:91] Creating Layer drop6
I0802 07:11:50.119437  2761 net.cpp:425] drop6 <- fc6
I0802 07:11:50.119446  2761 net.cpp:386] drop6 -> fc6 (in-place)
I0802 07:11:50.119501  2761 net.cpp:141] Setting up drop6
I0802 07:11:50.119511  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.119516  2761 net.cpp:156] Memory required for data: 68109880
I0802 07:11:50.119521  2761 layer_factory.hpp:77] Creating layer fc7
I0802 07:11:50.119539  2761 net.cpp:91] Creating Layer fc7
I0802 07:11:50.119545  2761 net.cpp:425] fc7 <- fc6
I0802 07:11:50.119555  2761 net.cpp:399] fc7 -> fc7
I0802 07:11:50.167160  2751 net.cpp:141] Setting up embed_encoder
I0802 07:11:50.167224  2751 net.cpp:148] Top shape: 1 500 (500)
I0802 07:11:50.167232  2751 net.cpp:156] Memory required for data: 18404
I0802 07:11:50.167258  2751 layer_factory.hpp:77] Creating layer reshape_frames
I0802 07:11:50.167280  2751 net.cpp:91] Creating Layer reshape_frames
I0802 07:11:50.167290  2751 net.cpp:425] reshape_frames <- embedded_in_frames
I0802 07:11:50.167306  2751 net.cpp:399] reshape_frames -> embedded_input_frames
I0802 07:11:50.167371  2751 net.cpp:141] Setting up reshape_frames
I0802 07:11:50.167382  2751 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:50.167387  2751 net.cpp:156] Memory required for data: 20404
I0802 07:11:50.167392  2751 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0802 07:11:50.167407  2751 net.cpp:91] Creating Layer reshape_stage_indicator
I0802 07:11:50.167413  2751 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0802 07:11:50.167423  2751 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0802 07:11:50.167469  2751 net.cpp:141] Setting up reshape_stage_indicator
I0802 07:11:50.167479  2751 net.cpp:148] Top shape: 1 1 1 (1)
I0802 07:11:50.167484  2751 net.cpp:156] Memory required for data: 20408
I0802 07:11:50.167490  2751 layer_factory.hpp:77] Creating layer embedding
I0802 07:11:50.167506  2751 net.cpp:91] Creating Layer embedding
I0802 07:11:50.167511  2751 net.cpp:425] embedding <- input_sentence
I0802 07:11:50.167521  2751 net.cpp:399] embedding -> embedded_input_sentence
I0802 07:11:50.212569  2761 net.cpp:141] Setting up fc7
I0802 07:11:50.212626  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.212633  2761 net.cpp:156] Memory required for data: 68273720
I0802 07:11:50.212651  2761 layer_factory.hpp:77] Creating layer relu7
I0802 07:11:50.212669  2761 net.cpp:91] Creating Layer relu7
I0802 07:11:50.212677  2761 net.cpp:425] relu7 <- fc7
I0802 07:11:50.212692  2761 net.cpp:386] relu7 -> fc7 (in-place)
I0802 07:11:50.213423  2761 net.cpp:141] Setting up relu7
I0802 07:11:50.213441  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.213446  2761 net.cpp:156] Memory required for data: 68437560
I0802 07:11:50.213452  2761 layer_factory.hpp:77] Creating layer drop7
I0802 07:11:50.213465  2761 net.cpp:91] Creating Layer drop7
I0802 07:11:50.213471  2761 net.cpp:425] drop7 <- fc7
I0802 07:11:50.213484  2761 net.cpp:386] drop7 -> fc7 (in-place)
I0802 07:11:50.213536  2761 net.cpp:141] Setting up drop7
I0802 07:11:50.213546  2761 net.cpp:148] Top shape: 10 4096 (40960)
I0802 07:11:50.213551  2761 net.cpp:156] Memory required for data: 68601400
I0802 07:11:50.213556  2761 layer_factory.hpp:77] Creating layer fc8
I0802 07:11:50.213567  2761 net.cpp:91] Creating Layer fc8
I0802 07:11:50.213573  2761 net.cpp:425] fc8 <- fc7
I0802 07:11:50.213580  2761 net.cpp:399] fc8 -> fc8
I0802 07:11:50.227514  2761 net.cpp:141] Setting up fc8
I0802 07:11:50.227567  2761 net.cpp:148] Top shape: 10 1000 (10000)
I0802 07:11:50.227574  2761 net.cpp:156] Memory required for data: 68641400
I0802 07:11:50.227592  2761 layer_factory.hpp:77] Creating layer prob
I0802 07:11:50.227613  2761 net.cpp:91] Creating Layer prob
I0802 07:11:50.227622  2761 net.cpp:425] prob <- fc8
I0802 07:11:50.227632  2761 net.cpp:399] prob -> prob
I0802 07:11:50.228143  2761 net.cpp:141] Setting up prob
I0802 07:11:50.228157  2761 net.cpp:148] Top shape: 10 1000 (10000)
I0802 07:11:50.228163  2761 net.cpp:156] Memory required for data: 68681400
I0802 07:11:50.228168  2761 net.cpp:219] prob does not need backward computation.
I0802 07:11:50.228173  2761 net.cpp:219] fc8 does not need backward computation.
I0802 07:11:50.228178  2761 net.cpp:219] drop7 does not need backward computation.
I0802 07:11:50.228183  2761 net.cpp:219] relu7 does not need backward computation.
I0802 07:11:50.228188  2761 net.cpp:219] fc7 does not need backward computation.
I0802 07:11:50.228193  2761 net.cpp:219] drop6 does not need backward computation.
I0802 07:11:50.228199  2761 net.cpp:219] relu6 does not need backward computation.
I0802 07:11:50.228202  2761 net.cpp:219] fc6 does not need backward computation.
I0802 07:11:50.228209  2761 net.cpp:219] pool5 does not need backward computation.
I0802 07:11:50.228214  2761 net.cpp:219] relu5 does not need backward computation.
I0802 07:11:50.228217  2761 net.cpp:219] conv5 does not need backward computation.
I0802 07:11:50.228222  2761 net.cpp:219] relu4 does not need backward computation.
I0802 07:11:50.228227  2761 net.cpp:219] conv4 does not need backward computation.
I0802 07:11:50.228232  2761 net.cpp:219] relu3 does not need backward computation.
I0802 07:11:50.228237  2761 net.cpp:219] conv3 does not need backward computation.
I0802 07:11:50.228242  2761 net.cpp:219] norm2 does not need backward computation.
I0802 07:11:50.228248  2761 net.cpp:219] pool2 does not need backward computation.
I0802 07:11:50.228253  2761 net.cpp:219] relu2 does not need backward computation.
I0802 07:11:50.228257  2761 net.cpp:219] conv2 does not need backward computation.
I0802 07:11:50.228262  2761 net.cpp:219] norm1 does not need backward computation.
I0802 07:11:50.228267  2761 net.cpp:219] pool1 does not need backward computation.
I0802 07:11:50.228273  2761 net.cpp:219] relu1 does not need backward computation.
I0802 07:11:50.228278  2761 net.cpp:219] conv1 does not need backward computation.
I0802 07:11:50.228282  2761 net.cpp:219] data does not need backward computation.
I0802 07:11:50.228286  2761 net.cpp:261] This network produces output prob
I0802 07:11:50.228313  2761 net.cpp:274] Network initialization done.
I0802 07:11:50.413578  2751 net.cpp:141] Setting up embedding
I0802 07:11:50.413628  2751 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:50.413635  2751 net.cpp:156] Memory required for data: 22408
I0802 07:11:50.413653  2751 layer_factory.hpp:77] Creating layer lstm1
I0802 07:11:50.413681  2751 net.cpp:91] Creating Layer lstm1
I0802 07:11:50.413691  2751 net.cpp:425] lstm1 <- embedded_input_frames
I0802 07:11:50.413700  2751 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0802 07:11:50.413710  2751 net.cpp:399] lstm1 -> lstm1
I0802 07:11:50.413738  2751 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0802 07:11:50.414114  2751 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0802 07:11:50.414216  2751 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:50.414230  2751 net.cpp:91] Creating Layer lstm1_
I0802 07:11:50.414238  2751 net.cpp:399] lstm1_ -> x
I0802 07:11:50.414252  2751 net.cpp:399] lstm1_ -> cont
I0802 07:11:50.414330  2751 net.cpp:141] Setting up lstm1_
I0802 07:11:50.414342  2751 net.cpp:148] Top shape: 1 1 500 (500)
I0802 07:11:50.414350  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.414355  2751 net.cpp:156] Memory required for data: 2004
I0802 07:11:50.414361  2751 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:50.414373  2751 net.cpp:91] Creating Layer lstm1_
I0802 07:11:50.414381  2751 net.cpp:399] lstm1_ -> c_0
I0802 07:11:50.414394  2751 net.cpp:399] lstm1_ -> h_0
I0802 07:11:50.414448  2751 net.cpp:141] Setting up lstm1_
I0802 07:11:50.414458  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.414465  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.414470  2751 net.cpp:156] Memory required for data: 10004
I0802 07:11:50.414475  2751 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0802 07:11:50.414489  2751 net.cpp:91] Creating Layer lstm1_cont_slice
I0802 07:11:50.414494  2751 net.cpp:425] lstm1_cont_slice <- cont
I0802 07:11:50.414502  2751 net.cpp:399] lstm1_cont_slice -> cont_1
I0802 07:11:50.414547  2751 net.cpp:141] Setting up lstm1_cont_slice
I0802 07:11:50.414557  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.414562  2751 net.cpp:156] Memory required for data: 10008
I0802 07:11:50.414568  2751 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0802 07:11:50.414577  2751 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0802 07:11:50.414582  2751 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0802 07:11:50.414592  2751 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0802 07:11:50.414602  2751 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0802 07:11:50.414654  2751 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0802 07:11:50.414664  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.414669  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.414674  2751 net.cpp:156] Memory required for data: 10016
I0802 07:11:50.414680  2751 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0802 07:11:50.414692  2751 net.cpp:91] Creating Layer lstm1_x_transform
I0802 07:11:50.414698  2751 net.cpp:425] lstm1_x_transform <- x
I0802 07:11:50.414710  2751 net.cpp:399] lstm1_x_transform -> W_xc_x
I0802 07:11:50.437082  2751 net.cpp:141] Setting up lstm1_x_transform
I0802 07:11:50.437129  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.437134  2751 net.cpp:156] Memory required for data: 26016
I0802 07:11:50.437157  2751 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0802 07:11:50.437175  2751 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0802 07:11:50.437181  2751 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0802 07:11:50.437191  2751 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0802 07:11:50.437242  2751 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0802 07:11:50.437252  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.437258  2751 net.cpp:156] Memory required for data: 42016
I0802 07:11:50.437263  2751 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0802 07:11:50.437276  2751 net.cpp:91] Creating Layer lstm1_h_conted_0
I0802 07:11:50.437283  2751 net.cpp:425] lstm1_h_conted_0 <- h_0
I0802 07:11:50.437289  2751 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0802 07:11:50.437297  2751 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0802 07:11:50.437427  2751 net.cpp:141] Setting up lstm1_h_conted_0
I0802 07:11:50.437438  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.437443  2751 net.cpp:156] Memory required for data: 46016
I0802 07:11:50.437448  2751 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0802 07:11:50.437463  2751 net.cpp:91] Creating Layer lstm1_transform_1
I0802 07:11:50.437469  2751 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0802 07:11:50.437477  2751 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0802 07:11:50.462369  2761 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld4755157273230229825/bvlc_reference_caffenet.caffemodel
I0802 07:11:50.462415  2761 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0802 07:11:50.462421  2761 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0802 07:11:50.462426  2761 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld4755157273230229825/bvlc_reference_caffenet.caffemodel
I0802 07:11:50.482442  2751 net.cpp:141] Setting up lstm1_transform_1
I0802 07:11:50.482486  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.482493  2751 net.cpp:156] Memory required for data: 62016
I0802 07:11:50.482512  2751 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0802 07:11:50.482535  2751 net.cpp:91] Creating Layer lstm1_gate_input_1
I0802 07:11:50.482543  2751 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0802 07:11:50.482553  2751 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0802 07:11:50.482563  2751 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0802 07:11:50.482630  2751 net.cpp:141] Setting up lstm1_gate_input_1
I0802 07:11:50.482640  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.482645  2751 net.cpp:156] Memory required for data: 78016
I0802 07:11:50.482651  2751 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0802 07:11:50.482661  2751 net.cpp:91] Creating Layer lstm1_unit_1
I0802 07:11:50.482666  2751 net.cpp:425] lstm1_unit_1 <- c_0
I0802 07:11:50.482673  2751 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0802 07:11:50.482679  2751 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0802 07:11:50.482687  2751 net.cpp:399] lstm1_unit_1 -> c_1
I0802 07:11:50.482697  2751 net.cpp:399] lstm1_unit_1 -> h_1
I0802 07:11:50.482767  2751 net.cpp:141] Setting up lstm1_unit_1
I0802 07:11:50.482777  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.482784  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.482789  2751 net.cpp:156] Memory required for data: 86016
I0802 07:11:50.482795  2751 layer_factory.hpp:77] Creating layer lstm1_
I0802 07:11:50.482806  2751 net.cpp:91] Creating Layer lstm1_
I0802 07:11:50.482812  2751 net.cpp:425] lstm1_ <- c_1
I0802 07:11:50.482820  2751 net.cpp:399] lstm1_ -> c_T
I0802 07:11:50.482854  2751 net.cpp:141] Setting up lstm1_
I0802 07:11:50.482863  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.482868  2751 net.cpp:156] Memory required for data: 90016
I0802 07:11:50.482874  2751 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0802 07:11:50.482884  2751 net.cpp:91] Creating Layer lstm1_h_concat
I0802 07:11:50.482889  2751 net.cpp:425] lstm1_h_concat <- h_1
I0802 07:11:50.482900  2751 net.cpp:399] lstm1_h_concat -> h
I0802 07:11:50.482950  2751 net.cpp:141] Setting up lstm1_h_concat
I0802 07:11:50.482960  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.482965  2751 net.cpp:156] Memory required for data: 94016
I0802 07:11:50.482970  2751 layer_factory.hpp:77] Creating layer h_pseudoloss
I0802 07:11:50.482985  2751 net.cpp:91] Creating Layer h_pseudoloss
I0802 07:11:50.482990  2751 net.cpp:425] h_pseudoloss <- h
I0802 07:11:50.482998  2751 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0802 07:11:50.483109  2751 net.cpp:141] Setting up h_pseudoloss
I0802 07:11:50.483120  2751 net.cpp:148] Top shape: (1)
I0802 07:11:50.483125  2751 net.cpp:151]     with loss weight 1
I0802 07:11:50.483168  2751 net.cpp:156] Memory required for data: 94020
I0802 07:11:50.483175  2751 net.cpp:217] h_pseudoloss needs backward computation.
I0802 07:11:50.483180  2751 net.cpp:217] lstm1_h_concat needs backward computation.
I0802 07:11:50.483184  2751 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:50.483189  2751 net.cpp:217] lstm1_unit_1 needs backward computation.
I0802 07:11:50.483196  2751 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0802 07:11:50.483201  2751 net.cpp:217] lstm1_transform_1 needs backward computation.
I0802 07:11:50.483209  2751 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0802 07:11:50.483217  2751 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0802 07:11:50.483222  2751 net.cpp:217] lstm1_x_transform needs backward computation.
I0802 07:11:50.483227  2751 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0802 07:11:50.483233  2751 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0802 07:11:50.483239  2751 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:50.483243  2751 net.cpp:219] lstm1_ does not need backward computation.
I0802 07:11:50.483247  2751 net.cpp:261] This network produces output c_T
I0802 07:11:50.483253  2751 net.cpp:261] This network produces output h_pseudoloss
I0802 07:11:50.483268  2751 net.cpp:274] Network initialization done.
I0802 07:11:50.483328  2751 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0802 07:11:50.483335  2751 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0802 07:11:50.483340  2751 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0802 07:11:50.483459  2751 net.cpp:141] Setting up lstm1
I0802 07:11:50.483472  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.483479  2751 net.cpp:156] Memory required for data: 26408
I0802 07:11:50.483495  2751 layer_factory.hpp:77] Creating layer concat
I0802 07:11:50.483505  2751 net.cpp:91] Creating Layer concat
I0802 07:11:50.483512  2751 net.cpp:425] concat <- lstm1
I0802 07:11:50.483520  2751 net.cpp:425] concat <- embedded_input_sentence
I0802 07:11:50.483526  2751 net.cpp:425] concat <- reshaped_stage_indicator
I0802 07:11:50.483535  2751 net.cpp:399] concat -> lstm1_video_sequence
I0802 07:11:50.483572  2751 net.cpp:141] Setting up concat
I0802 07:11:50.483582  2751 net.cpp:148] Top shape: 1 1 1501 (1501)
I0802 07:11:50.483587  2751 net.cpp:156] Memory required for data: 32412
I0802 07:11:50.483592  2751 layer_factory.hpp:77] Creating layer lstm2
I0802 07:11:50.483606  2751 net.cpp:91] Creating Layer lstm2
I0802 07:11:50.483611  2751 net.cpp:425] lstm2 <- lstm1_video_sequence
I0802 07:11:50.483618  2751 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0802 07:11:50.483626  2751 net.cpp:399] lstm2 -> lstm2
I0802 07:11:50.483638  2751 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0802 07:11:50.483927  2751 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0802 07:11:50.484030  2751 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:50.484046  2751 net.cpp:91] Creating Layer lstm2_
I0802 07:11:50.484055  2751 net.cpp:399] lstm2_ -> x
I0802 07:11:50.484066  2751 net.cpp:399] lstm2_ -> cont
I0802 07:11:50.484127  2751 net.cpp:141] Setting up lstm2_
I0802 07:11:50.484138  2751 net.cpp:148] Top shape: 1 1 1501 (1501)
I0802 07:11:50.484144  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.484149  2751 net.cpp:156] Memory required for data: 6008
I0802 07:11:50.484155  2751 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:50.484169  2751 net.cpp:91] Creating Layer lstm2_
I0802 07:11:50.484175  2751 net.cpp:399] lstm2_ -> c_0
I0802 07:11:50.484185  2751 net.cpp:399] lstm2_ -> h_0
I0802 07:11:50.484242  2751 net.cpp:141] Setting up lstm2_
I0802 07:11:50.484252  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.484258  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.484263  2751 net.cpp:156] Memory required for data: 14008
I0802 07:11:50.484268  2751 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0802 07:11:50.484277  2751 net.cpp:91] Creating Layer lstm2_cont_slice
I0802 07:11:50.484283  2751 net.cpp:425] lstm2_cont_slice <- cont
I0802 07:11:50.484293  2751 net.cpp:399] lstm2_cont_slice -> cont_1
I0802 07:11:50.484329  2751 net.cpp:141] Setting up lstm2_cont_slice
I0802 07:11:50.484343  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.484347  2751 net.cpp:156] Memory required for data: 14012
I0802 07:11:50.484354  2751 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0802 07:11:50.484360  2751 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0802 07:11:50.484365  2751 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0802 07:11:50.484372  2751 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0802 07:11:50.484381  2751 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0802 07:11:50.484436  2751 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0802 07:11:50.484444  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.484452  2751 net.cpp:148] Top shape: 1 1 (1)
I0802 07:11:50.484457  2751 net.cpp:156] Memory required for data: 14020
I0802 07:11:50.484462  2751 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0802 07:11:50.484474  2751 net.cpp:91] Creating Layer lstm2_x_transform
I0802 07:11:50.484480  2751 net.cpp:425] lstm2_x_transform <- x
I0802 07:11:50.484489  2751 net.cpp:399] lstm2_x_transform -> W_xc_x
I0802 07:11:50.548315  2751 net.cpp:141] Setting up lstm2_x_transform
I0802 07:11:50.548365  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.548372  2751 net.cpp:156] Memory required for data: 30020
I0802 07:11:50.548393  2751 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0802 07:11:50.548410  2751 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0802 07:11:50.548418  2751 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0802 07:11:50.548434  2751 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0802 07:11:50.548485  2751 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0802 07:11:50.548496  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.548501  2751 net.cpp:156] Memory required for data: 46020
I0802 07:11:50.548506  2751 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0802 07:11:50.548517  2751 net.cpp:91] Creating Layer lstm2_h_conted_0
I0802 07:11:50.548523  2751 net.cpp:425] lstm2_h_conted_0 <- h_0
I0802 07:11:50.548529  2751 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0802 07:11:50.548542  2751 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0802 07:11:50.548641  2751 net.cpp:141] Setting up lstm2_h_conted_0
I0802 07:11:50.548652  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.548657  2751 net.cpp:156] Memory required for data: 50020
I0802 07:11:50.548662  2751 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0802 07:11:50.548688  2751 net.cpp:91] Creating Layer lstm2_transform_1
I0802 07:11:50.548694  2751 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0802 07:11:50.548703  2751 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0802 07:11:50.591285  2751 net.cpp:141] Setting up lstm2_transform_1
I0802 07:11:50.591336  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.591341  2751 net.cpp:156] Memory required for data: 66020
I0802 07:11:50.591361  2751 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0802 07:11:50.591383  2751 net.cpp:91] Creating Layer lstm2_gate_input_1
I0802 07:11:50.591392  2751 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0802 07:11:50.591400  2751 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0802 07:11:50.591413  2751 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0802 07:11:50.591464  2751 net.cpp:141] Setting up lstm2_gate_input_1
I0802 07:11:50.591473  2751 net.cpp:148] Top shape: 1 1 4000 (4000)
I0802 07:11:50.591478  2751 net.cpp:156] Memory required for data: 82020
I0802 07:11:50.591483  2751 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0802 07:11:50.591496  2751 net.cpp:91] Creating Layer lstm2_unit_1
I0802 07:11:50.591502  2751 net.cpp:425] lstm2_unit_1 <- c_0
I0802 07:11:50.591509  2751 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0802 07:11:50.591516  2751 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0802 07:11:50.591522  2751 net.cpp:399] lstm2_unit_1 -> c_1
I0802 07:11:50.591532  2751 net.cpp:399] lstm2_unit_1 -> h_1
I0802 07:11:50.591601  2751 net.cpp:141] Setting up lstm2_unit_1
I0802 07:11:50.591611  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.591619  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.591622  2751 net.cpp:156] Memory required for data: 90020
I0802 07:11:50.591629  2751 layer_factory.hpp:77] Creating layer lstm2_
I0802 07:11:50.591639  2751 net.cpp:91] Creating Layer lstm2_
I0802 07:11:50.591644  2751 net.cpp:425] lstm2_ <- c_1
I0802 07:11:50.591653  2751 net.cpp:399] lstm2_ -> c_T
I0802 07:11:50.591687  2751 net.cpp:141] Setting up lstm2_
I0802 07:11:50.591696  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.591701  2751 net.cpp:156] Memory required for data: 94020
I0802 07:11:50.591706  2751 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0802 07:11:50.591717  2751 net.cpp:91] Creating Layer lstm2_h_concat
I0802 07:11:50.591722  2751 net.cpp:425] lstm2_h_concat <- h_1
I0802 07:11:50.591729  2751 net.cpp:399] lstm2_h_concat -> h
I0802 07:11:50.591770  2751 net.cpp:141] Setting up lstm2_h_concat
I0802 07:11:50.591780  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.591784  2751 net.cpp:156] Memory required for data: 98020
I0802 07:11:50.591789  2751 layer_factory.hpp:77] Creating layer h_pseudoloss
I0802 07:11:50.591800  2751 net.cpp:91] Creating Layer h_pseudoloss
I0802 07:11:50.591805  2751 net.cpp:425] h_pseudoloss <- h
I0802 07:11:50.591814  2751 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0802 07:11:50.591907  2751 net.cpp:141] Setting up h_pseudoloss
I0802 07:11:50.591917  2751 net.cpp:148] Top shape: (1)
I0802 07:11:50.591922  2751 net.cpp:151]     with loss weight 1
I0802 07:11:50.591943  2751 net.cpp:156] Memory required for data: 98024
I0802 07:11:50.591948  2751 net.cpp:217] h_pseudoloss needs backward computation.
I0802 07:11:50.591953  2751 net.cpp:217] lstm2_h_concat needs backward computation.
I0802 07:11:50.591958  2751 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:50.591964  2751 net.cpp:217] lstm2_unit_1 needs backward computation.
I0802 07:11:50.591972  2751 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0802 07:11:50.591979  2751 net.cpp:217] lstm2_transform_1 needs backward computation.
I0802 07:11:50.591984  2751 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0802 07:11:50.591989  2751 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0802 07:11:50.591995  2751 net.cpp:217] lstm2_x_transform needs backward computation.
I0802 07:11:50.592000  2751 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0802 07:11:50.592013  2751 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0802 07:11:50.592020  2751 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:50.592025  2751 net.cpp:219] lstm2_ does not need backward computation.
I0802 07:11:50.592030  2751 net.cpp:261] This network produces output c_T
I0802 07:11:50.592034  2751 net.cpp:261] This network produces output h_pseudoloss
I0802 07:11:50.592051  2751 net.cpp:274] Network initialization done.
I0802 07:11:50.592106  2751 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0802 07:11:50.592113  2751 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0802 07:11:50.592118  2751 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0802 07:11:50.592231  2751 net.cpp:141] Setting up lstm2
I0802 07:11:50.592244  2751 net.cpp:148] Top shape: 1 1 1000 (1000)
I0802 07:11:50.592249  2751 net.cpp:156] Memory required for data: 36412
I0802 07:11:50.592265  2751 layer_factory.hpp:77] Creating layer predict
I0802 07:11:50.592280  2751 net.cpp:91] Creating Layer predict
I0802 07:11:50.592288  2751 net.cpp:425] predict <- lstm2
I0802 07:11:50.592296  2751 net.cpp:399] predict -> predict
I0802 07:11:50.878988  2761 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0802 07:11:50.931015  2761 net.cpp:752] Ignoring source layer loss
I0802 07:11:51.134188  2751 net.cpp:141] Setting up predict
I0802 07:11:51.134264  2751 net.cpp:148] Top shape: 1 1 46168 (46168)
I0802 07:11:51.134273  2751 net.cpp:156] Memory required for data: 221084
I0802 07:11:51.134291  2751 layer_factory.hpp:77] Creating layer probs
I0802 07:11:51.134313  2751 net.cpp:91] Creating Layer probs
I0802 07:11:51.134335  2751 net.cpp:425] probs <- predict
I0802 07:11:51.134347  2751 net.cpp:399] probs -> probs
I0802 07:11:51.136986  2751 net.cpp:141] Setting up probs
I0802 07:11:51.137011  2751 net.cpp:148] Top shape: 1 1 46168 (46168)
I0802 07:11:51.137017  2751 net.cpp:156] Memory required for data: 405756
I0802 07:11:51.137023  2751 net.cpp:219] probs does not need backward computation.
I0802 07:11:51.137029  2751 net.cpp:219] predict does not need backward computation.
I0802 07:11:51.137037  2751 net.cpp:219] lstm2 does not need backward computation.
I0802 07:11:51.137043  2751 net.cpp:219] concat does not need backward computation.
I0802 07:11:51.137049  2751 net.cpp:219] lstm1 does not need backward computation.
I0802 07:11:51.137070  2751 net.cpp:219] embedding does not need backward computation.
I0802 07:11:51.137076  2751 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0802 07:11:51.137082  2751 net.cpp:219] reshape_frames does not need backward computation.
I0802 07:11:51.137087  2751 net.cpp:219] embed_encoder does not need backward computation.
I0802 07:11:51.137092  2751 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0802 07:11:51.137099  2751 net.cpp:219] input does not need backward computation.
I0802 07:11:51.137102  2751 net.cpp:261] This network produces output probs
I0802 07:11:51.137128  2751 net.cpp:274] Network initialization done.
I0802 07:11:51.505301  2751 net.cpp:752] Ignoring source layer data
I0802 07:11:51.505340  2751 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0802 07:11:51.505345  2751 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0802 07:11:51.604764  2751 net.cpp:752] Ignoring source layer cross_entropy_loss
