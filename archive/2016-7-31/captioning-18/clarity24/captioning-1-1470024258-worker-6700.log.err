SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1470024258/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-08-01 00:04:59,134 ERROR Logger contains an invalid element or attribute "appender"
2016-08-01 00:05:09,283 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld5793331974478773207/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0801 00:05:15.746803  1223 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0801 00:05:15.747009  1223 layer_factory.hpp:77] Creating layer data
I0801 00:05:15.747037  1223 net.cpp:91] Creating Layer data
I0801 00:05:15.747048  1223 net.cpp:399] data -> data
I0801 00:05:16.285920  1223 net.cpp:141] Setting up data
I0801 00:05:16.286020  1223 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0801 00:05:16.286028  1223 net.cpp:156] Memory required for data: 6183480
I0801 00:05:16.286047  1223 layer_factory.hpp:77] Creating layer conv1
I0801 00:05:16.286077  1223 net.cpp:91] Creating Layer conv1
I0801 00:05:16.286087  1223 net.cpp:425] conv1 <- data
I0801 00:05:16.286103  1223 net.cpp:399] conv1 -> conv1
I0801 00:05:16.486240  1213 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld5793331974478773207/s2vt.words_to_preds.prototxt
I0801 00:05:16.486292  1213 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0801 00:05:16.486301  1213 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0801 00:05:16.486588  1213 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0801 00:05:16.486696  1213 layer_factory.hpp:77] Creating layer input
I0801 00:05:16.486712  1213 net.cpp:91] Creating Layer input
I0801 00:05:16.486721  1213 net.cpp:399] input -> frames_fc7
I0801 00:05:16.486740  1213 net.cpp:399] input -> cont_sentence
I0801 00:05:16.486752  1213 net.cpp:399] input -> input_sentence
I0801 00:05:16.486763  1213 net.cpp:399] input -> stage_indicator
I0801 00:05:16.490279  1213 net.cpp:141] Setting up input
I0801 00:05:16.490303  1213 net.cpp:148] Top shape: 1 4096 (4096)
I0801 00:05:16.490310  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.490316  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.490324  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.490329  1213 net.cpp:156] Memory required for data: 16396
I0801 00:05:16.490334  1213 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0801 00:05:16.490355  1213 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0801 00:05:16.490360  1213 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0801 00:05:16.490383  1213 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0801 00:05:16.490396  1213 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0801 00:05:16.490665  1213 net.cpp:141] Setting up cont_sentence_input_1_split
I0801 00:05:16.490679  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.490684  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.490689  1213 net.cpp:156] Memory required for data: 16404
I0801 00:05:16.490695  1213 layer_factory.hpp:77] Creating layer embed_encoder
I0801 00:05:16.490715  1213 net.cpp:91] Creating Layer embed_encoder
I0801 00:05:16.490720  1213 net.cpp:425] embed_encoder <- frames_fc7
I0801 00:05:16.490730  1213 net.cpp:399] embed_encoder -> embedded_in_frames
I0801 00:05:16.510222  1223 net.cpp:141] Setting up conv1
I0801 00:05:16.510269  1223 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0801 00:05:16.510275  1223 net.cpp:156] Memory required for data: 17799480
I0801 00:05:16.510305  1223 layer_factory.hpp:77] Creating layer relu1
I0801 00:05:16.510325  1223 net.cpp:91] Creating Layer relu1
I0801 00:05:16.510332  1223 net.cpp:425] relu1 <- conv1
I0801 00:05:16.510340  1223 net.cpp:386] relu1 -> conv1 (in-place)
I0801 00:05:16.510790  1223 net.cpp:141] Setting up relu1
I0801 00:05:16.510804  1223 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0801 00:05:16.510809  1223 net.cpp:156] Memory required for data: 29415480
I0801 00:05:16.510815  1223 layer_factory.hpp:77] Creating layer pool1
I0801 00:05:16.510829  1223 net.cpp:91] Creating Layer pool1
I0801 00:05:16.510835  1223 net.cpp:425] pool1 <- conv1
I0801 00:05:16.510843  1223 net.cpp:399] pool1 -> pool1
I0801 00:05:16.510916  1223 net.cpp:141] Setting up pool1
I0801 00:05:16.510926  1223 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0801 00:05:16.510931  1223 net.cpp:156] Memory required for data: 32214840
I0801 00:05:16.510936  1223 layer_factory.hpp:77] Creating layer norm1
I0801 00:05:16.510954  1223 net.cpp:91] Creating Layer norm1
I0801 00:05:16.510960  1223 net.cpp:425] norm1 <- pool1
I0801 00:05:16.510967  1223 net.cpp:399] norm1 -> norm1
I0801 00:05:16.511435  1223 net.cpp:141] Setting up norm1
I0801 00:05:16.511447  1223 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0801 00:05:16.511452  1223 net.cpp:156] Memory required for data: 35014200
I0801 00:05:16.511458  1223 layer_factory.hpp:77] Creating layer conv2
I0801 00:05:16.511476  1223 net.cpp:91] Creating Layer conv2
I0801 00:05:16.511482  1223 net.cpp:425] conv2 <- norm1
I0801 00:05:16.511489  1223 net.cpp:399] conv2 -> conv2
I0801 00:05:16.515699  1223 net.cpp:141] Setting up conv2
I0801 00:05:16.515725  1223 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0801 00:05:16.515732  1223 net.cpp:156] Memory required for data: 42479160
I0801 00:05:16.515745  1223 layer_factory.hpp:77] Creating layer relu2
I0801 00:05:16.515756  1223 net.cpp:91] Creating Layer relu2
I0801 00:05:16.515763  1223 net.cpp:425] relu2 <- conv2
I0801 00:05:16.515769  1223 net.cpp:386] relu2 -> conv2 (in-place)
I0801 00:05:16.516222  1223 net.cpp:141] Setting up relu2
I0801 00:05:16.516235  1223 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0801 00:05:16.516240  1223 net.cpp:156] Memory required for data: 49944120
I0801 00:05:16.516245  1223 layer_factory.hpp:77] Creating layer pool2
I0801 00:05:16.516257  1223 net.cpp:91] Creating Layer pool2
I0801 00:05:16.516263  1223 net.cpp:425] pool2 <- conv2
I0801 00:05:16.516269  1223 net.cpp:399] pool2 -> pool2
I0801 00:05:16.516320  1223 net.cpp:141] Setting up pool2
I0801 00:05:16.516330  1223 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0801 00:05:16.516335  1223 net.cpp:156] Memory required for data: 51674680
I0801 00:05:16.516340  1223 layer_factory.hpp:77] Creating layer norm2
I0801 00:05:16.516351  1223 net.cpp:91] Creating Layer norm2
I0801 00:05:16.516356  1223 net.cpp:425] norm2 <- pool2
I0801 00:05:16.516363  1223 net.cpp:399] norm2 -> norm2
I0801 00:05:16.516597  1223 net.cpp:141] Setting up norm2
I0801 00:05:16.516609  1223 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0801 00:05:16.516614  1223 net.cpp:156] Memory required for data: 53405240
I0801 00:05:16.516620  1223 layer_factory.hpp:77] Creating layer conv3
I0801 00:05:16.516634  1223 net.cpp:91] Creating Layer conv3
I0801 00:05:16.516639  1223 net.cpp:425] conv3 <- norm2
I0801 00:05:16.516647  1223 net.cpp:399] conv3 -> conv3
I0801 00:05:16.519690  1213 net.cpp:141] Setting up embed_encoder
I0801 00:05:16.519726  1213 net.cpp:148] Top shape: 1 500 (500)
I0801 00:05:16.519733  1213 net.cpp:156] Memory required for data: 18404
I0801 00:05:16.519753  1213 layer_factory.hpp:77] Creating layer reshape_frames
I0801 00:05:16.519771  1213 net.cpp:91] Creating Layer reshape_frames
I0801 00:05:16.519779  1213 net.cpp:425] reshape_frames <- embedded_in_frames
I0801 00:05:16.519790  1213 net.cpp:399] reshape_frames -> embedded_input_frames
I0801 00:05:16.519969  1213 net.cpp:141] Setting up reshape_frames
I0801 00:05:16.519982  1213 net.cpp:148] Top shape: 1 1 500 (500)
I0801 00:05:16.519987  1213 net.cpp:156] Memory required for data: 20404
I0801 00:05:16.519994  1213 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0801 00:05:16.520014  1213 net.cpp:91] Creating Layer reshape_stage_indicator
I0801 00:05:16.520025  1213 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0801 00:05:16.520040  1213 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0801 00:05:16.520478  1213 net.cpp:141] Setting up reshape_stage_indicator
I0801 00:05:16.520490  1213 net.cpp:148] Top shape: 1 1 1 (1)
I0801 00:05:16.520495  1213 net.cpp:156] Memory required for data: 20408
I0801 00:05:16.520501  1213 layer_factory.hpp:77] Creating layer embedding
I0801 00:05:16.520517  1213 net.cpp:91] Creating Layer embedding
I0801 00:05:16.520524  1213 net.cpp:425] embedding <- input_sentence
I0801 00:05:16.520534  1213 net.cpp:399] embedding -> embedded_input_sentence
I0801 00:05:16.563333  1223 net.cpp:141] Setting up conv3
I0801 00:05:16.563365  1223 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0801 00:05:16.563371  1223 net.cpp:156] Memory required for data: 56001080
I0801 00:05:16.563387  1223 layer_factory.hpp:77] Creating layer relu3
I0801 00:05:16.563398  1223 net.cpp:91] Creating Layer relu3
I0801 00:05:16.563405  1223 net.cpp:425] relu3 <- conv3
I0801 00:05:16.563411  1223 net.cpp:386] relu3 -> conv3 (in-place)
I0801 00:05:16.563882  1223 net.cpp:141] Setting up relu3
I0801 00:05:16.563895  1223 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0801 00:05:16.563899  1223 net.cpp:156] Memory required for data: 58596920
I0801 00:05:16.563905  1223 layer_factory.hpp:77] Creating layer conv4
I0801 00:05:16.563922  1223 net.cpp:91] Creating Layer conv4
I0801 00:05:16.563928  1223 net.cpp:425] conv4 <- conv3
I0801 00:05:16.563936  1223 net.cpp:399] conv4 -> conv4
I0801 00:05:16.568114  1223 net.cpp:141] Setting up conv4
I0801 00:05:16.568140  1223 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0801 00:05:16.568145  1223 net.cpp:156] Memory required for data: 61192760
I0801 00:05:16.568156  1223 layer_factory.hpp:77] Creating layer relu4
I0801 00:05:16.568166  1223 net.cpp:91] Creating Layer relu4
I0801 00:05:16.568171  1223 net.cpp:425] relu4 <- conv4
I0801 00:05:16.568178  1223 net.cpp:386] relu4 -> conv4 (in-place)
I0801 00:05:16.568645  1223 net.cpp:141] Setting up relu4
I0801 00:05:16.568656  1223 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0801 00:05:16.568661  1223 net.cpp:156] Memory required for data: 63788600
I0801 00:05:16.568667  1223 layer_factory.hpp:77] Creating layer conv5
I0801 00:05:16.568686  1223 net.cpp:91] Creating Layer conv5
I0801 00:05:16.568691  1223 net.cpp:425] conv5 <- conv4
I0801 00:05:16.568699  1223 net.cpp:399] conv5 -> conv5
I0801 00:05:16.572589  1223 net.cpp:141] Setting up conv5
I0801 00:05:16.572612  1223 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0801 00:05:16.572618  1223 net.cpp:156] Memory required for data: 65519160
I0801 00:05:16.572630  1223 layer_factory.hpp:77] Creating layer relu5
I0801 00:05:16.572639  1223 net.cpp:91] Creating Layer relu5
I0801 00:05:16.572644  1223 net.cpp:425] relu5 <- conv5
I0801 00:05:16.572650  1223 net.cpp:386] relu5 -> conv5 (in-place)
I0801 00:05:16.573103  1223 net.cpp:141] Setting up relu5
I0801 00:05:16.573117  1223 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0801 00:05:16.573120  1223 net.cpp:156] Memory required for data: 67249720
I0801 00:05:16.573127  1223 layer_factory.hpp:77] Creating layer pool5
I0801 00:05:16.573137  1223 net.cpp:91] Creating Layer pool5
I0801 00:05:16.573143  1223 net.cpp:425] pool5 <- conv5
I0801 00:05:16.573153  1223 net.cpp:399] pool5 -> pool5
I0801 00:05:16.573212  1223 net.cpp:141] Setting up pool5
I0801 00:05:16.573221  1223 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0801 00:05:16.573225  1223 net.cpp:156] Memory required for data: 67618360
I0801 00:05:16.573230  1223 layer_factory.hpp:77] Creating layer fc6
I0801 00:05:16.573248  1223 net.cpp:91] Creating Layer fc6
I0801 00:05:16.573254  1223 net.cpp:425] fc6 <- pool5
I0801 00:05:16.573263  1223 net.cpp:399] fc6 -> fc6
I0801 00:05:16.691998  1223 net.cpp:141] Setting up fc6
I0801 00:05:16.692068  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.692076  1223 net.cpp:156] Memory required for data: 67782200
I0801 00:05:16.692092  1223 layer_factory.hpp:77] Creating layer relu6
I0801 00:05:16.692109  1223 net.cpp:91] Creating Layer relu6
I0801 00:05:16.692116  1223 net.cpp:425] relu6 <- fc6
I0801 00:05:16.692131  1223 net.cpp:386] relu6 -> fc6 (in-place)
I0801 00:05:16.692500  1223 net.cpp:141] Setting up relu6
I0801 00:05:16.692513  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.692518  1223 net.cpp:156] Memory required for data: 67946040
I0801 00:05:16.692524  1223 layer_factory.hpp:77] Creating layer drop6
I0801 00:05:16.692546  1223 net.cpp:91] Creating Layer drop6
I0801 00:05:16.692553  1223 net.cpp:425] drop6 <- fc6
I0801 00:05:16.692560  1223 net.cpp:386] drop6 -> fc6 (in-place)
I0801 00:05:16.692616  1223 net.cpp:141] Setting up drop6
I0801 00:05:16.692626  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.692631  1223 net.cpp:156] Memory required for data: 68109880
I0801 00:05:16.692637  1223 layer_factory.hpp:77] Creating layer fc7
I0801 00:05:16.692651  1223 net.cpp:91] Creating Layer fc7
I0801 00:05:16.692656  1223 net.cpp:425] fc7 <- fc6
I0801 00:05:16.692664  1223 net.cpp:399] fc7 -> fc7
I0801 00:05:16.741798  1223 net.cpp:141] Setting up fc7
I0801 00:05:16.741847  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.741854  1223 net.cpp:156] Memory required for data: 68273720
I0801 00:05:16.741870  1223 layer_factory.hpp:77] Creating layer relu7
I0801 00:05:16.741886  1223 net.cpp:91] Creating Layer relu7
I0801 00:05:16.741894  1223 net.cpp:425] relu7 <- fc7
I0801 00:05:16.741909  1223 net.cpp:386] relu7 -> fc7 (in-place)
I0801 00:05:16.742702  1223 net.cpp:141] Setting up relu7
I0801 00:05:16.742717  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.742722  1223 net.cpp:156] Memory required for data: 68437560
I0801 00:05:16.742727  1223 layer_factory.hpp:77] Creating layer drop7
I0801 00:05:16.742743  1223 net.cpp:91] Creating Layer drop7
I0801 00:05:16.742749  1223 net.cpp:425] drop7 <- fc7
I0801 00:05:16.742756  1223 net.cpp:386] drop7 -> fc7 (in-place)
I0801 00:05:16.742801  1223 net.cpp:141] Setting up drop7
I0801 00:05:16.742811  1223 net.cpp:148] Top shape: 10 4096 (40960)
I0801 00:05:16.742816  1223 net.cpp:156] Memory required for data: 68601400
I0801 00:05:16.742821  1223 layer_factory.hpp:77] Creating layer fc8
I0801 00:05:16.742833  1223 net.cpp:91] Creating Layer fc8
I0801 00:05:16.742838  1223 net.cpp:425] fc8 <- fc7
I0801 00:05:16.742851  1223 net.cpp:399] fc8 -> fc8
I0801 00:05:16.755241  1223 net.cpp:141] Setting up fc8
I0801 00:05:16.755290  1223 net.cpp:148] Top shape: 10 1000 (10000)
I0801 00:05:16.755296  1223 net.cpp:156] Memory required for data: 68641400
I0801 00:05:16.755311  1223 layer_factory.hpp:77] Creating layer prob
I0801 00:05:16.755328  1223 net.cpp:91] Creating Layer prob
I0801 00:05:16.755336  1223 net.cpp:425] prob <- fc8
I0801 00:05:16.755349  1223 net.cpp:399] prob -> prob
I0801 00:05:16.755807  1223 net.cpp:141] Setting up prob
I0801 00:05:16.755820  1223 net.cpp:148] Top shape: 10 1000 (10000)
I0801 00:05:16.755826  1223 net.cpp:156] Memory required for data: 68681400
I0801 00:05:16.755832  1223 net.cpp:219] prob does not need backward computation.
I0801 00:05:16.755838  1223 net.cpp:219] fc8 does not need backward computation.
I0801 00:05:16.755843  1223 net.cpp:219] drop7 does not need backward computation.
I0801 00:05:16.755848  1223 net.cpp:219] relu7 does not need backward computation.
I0801 00:05:16.755853  1223 net.cpp:219] fc7 does not need backward computation.
I0801 00:05:16.755858  1223 net.cpp:219] drop6 does not need backward computation.
I0801 00:05:16.755863  1223 net.cpp:219] relu6 does not need backward computation.
I0801 00:05:16.755868  1223 net.cpp:219] fc6 does not need backward computation.
I0801 00:05:16.755873  1223 net.cpp:219] pool5 does not need backward computation.
I0801 00:05:16.755878  1223 net.cpp:219] relu5 does not need backward computation.
I0801 00:05:16.755883  1223 net.cpp:219] conv5 does not need backward computation.
I0801 00:05:16.755888  1223 net.cpp:219] relu4 does not need backward computation.
I0801 00:05:16.755893  1223 net.cpp:219] conv4 does not need backward computation.
I0801 00:05:16.755898  1223 net.cpp:219] relu3 does not need backward computation.
I0801 00:05:16.755903  1223 net.cpp:219] conv3 does not need backward computation.
I0801 00:05:16.755909  1223 net.cpp:219] norm2 does not need backward computation.
I0801 00:05:16.755914  1223 net.cpp:219] pool2 does not need backward computation.
I0801 00:05:16.755919  1223 net.cpp:219] relu2 does not need backward computation.
I0801 00:05:16.755924  1223 net.cpp:219] conv2 does not need backward computation.
I0801 00:05:16.755929  1223 net.cpp:219] norm1 does not need backward computation.
I0801 00:05:16.755934  1223 net.cpp:219] pool1 does not need backward computation.
I0801 00:05:16.755939  1223 net.cpp:219] relu1 does not need backward computation.
I0801 00:05:16.755944  1223 net.cpp:219] conv1 does not need backward computation.
I0801 00:05:16.755949  1223 net.cpp:219] data does not need backward computation.
I0801 00:05:16.755954  1223 net.cpp:261] This network produces output prob
I0801 00:05:16.755980  1223 net.cpp:274] Network initialization done.
I0801 00:05:16.785279  1213 net.cpp:141] Setting up embedding
I0801 00:05:16.785333  1213 net.cpp:148] Top shape: 1 1 500 (500)
I0801 00:05:16.785341  1213 net.cpp:156] Memory required for data: 22408
I0801 00:05:16.785359  1213 layer_factory.hpp:77] Creating layer lstm1
I0801 00:05:16.785382  1213 net.cpp:91] Creating Layer lstm1
I0801 00:05:16.785392  1213 net.cpp:425] lstm1 <- embedded_input_frames
I0801 00:05:16.785401  1213 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0801 00:05:16.785413  1213 net.cpp:399] lstm1 -> lstm1
I0801 00:05:16.785452  1213 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0801 00:05:16.785823  1213 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0801 00:05:16.785940  1213 layer_factory.hpp:77] Creating layer lstm1_
I0801 00:05:16.785954  1213 net.cpp:91] Creating Layer lstm1_
I0801 00:05:16.785962  1213 net.cpp:399] lstm1_ -> x
I0801 00:05:16.785975  1213 net.cpp:399] lstm1_ -> cont
I0801 00:05:16.786046  1213 net.cpp:141] Setting up lstm1_
I0801 00:05:16.786058  1213 net.cpp:148] Top shape: 1 1 500 (500)
I0801 00:05:16.786065  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.786070  1213 net.cpp:156] Memory required for data: 2004
I0801 00:05:16.786077  1213 layer_factory.hpp:77] Creating layer lstm1_
I0801 00:05:16.786089  1213 net.cpp:91] Creating Layer lstm1_
I0801 00:05:16.786099  1213 net.cpp:399] lstm1_ -> c_0
I0801 00:05:16.786110  1213 net.cpp:399] lstm1_ -> h_0
I0801 00:05:16.786164  1213 net.cpp:141] Setting up lstm1_
I0801 00:05:16.786176  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.786182  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.786187  1213 net.cpp:156] Memory required for data: 10004
I0801 00:05:16.786193  1213 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0801 00:05:16.786203  1213 net.cpp:91] Creating Layer lstm1_cont_slice
I0801 00:05:16.786208  1213 net.cpp:425] lstm1_cont_slice <- cont
I0801 00:05:16.786216  1213 net.cpp:399] lstm1_cont_slice -> cont_1
I0801 00:05:16.786257  1213 net.cpp:141] Setting up lstm1_cont_slice
I0801 00:05:16.786267  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.786273  1213 net.cpp:156] Memory required for data: 10008
I0801 00:05:16.786278  1213 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0801 00:05:16.786286  1213 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0801 00:05:16.786291  1213 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0801 00:05:16.786303  1213 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0801 00:05:16.786314  1213 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0801 00:05:16.786365  1213 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0801 00:05:16.786375  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.786381  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.786386  1213 net.cpp:156] Memory required for data: 10016
I0801 00:05:16.786391  1213 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0801 00:05:16.786402  1213 net.cpp:91] Creating Layer lstm1_x_transform
I0801 00:05:16.786407  1213 net.cpp:425] lstm1_x_transform <- x
I0801 00:05:16.786419  1213 net.cpp:399] lstm1_x_transform -> W_xc_x
I0801 00:05:16.808758  1213 net.cpp:141] Setting up lstm1_x_transform
I0801 00:05:16.808804  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.808810  1213 net.cpp:156] Memory required for data: 26016
I0801 00:05:16.808832  1213 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0801 00:05:16.808848  1213 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0801 00:05:16.808856  1213 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0801 00:05:16.808866  1213 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0801 00:05:16.808917  1213 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0801 00:05:16.808928  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.808933  1213 net.cpp:156] Memory required for data: 42016
I0801 00:05:16.808939  1213 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0801 00:05:16.808950  1213 net.cpp:91] Creating Layer lstm1_h_conted_0
I0801 00:05:16.808956  1213 net.cpp:425] lstm1_h_conted_0 <- h_0
I0801 00:05:16.808962  1213 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0801 00:05:16.808971  1213 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0801 00:05:16.809077  1213 net.cpp:141] Setting up lstm1_h_conted_0
I0801 00:05:16.809087  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.809092  1213 net.cpp:156] Memory required for data: 46016
I0801 00:05:16.809098  1213 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0801 00:05:16.809110  1213 net.cpp:91] Creating Layer lstm1_transform_1
I0801 00:05:16.809116  1213 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0801 00:05:16.809125  1213 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0801 00:05:16.852602  1213 net.cpp:141] Setting up lstm1_transform_1
I0801 00:05:16.852660  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.852668  1213 net.cpp:156] Memory required for data: 62016
I0801 00:05:16.852689  1213 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0801 00:05:16.852710  1213 net.cpp:91] Creating Layer lstm1_gate_input_1
I0801 00:05:16.852717  1213 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0801 00:05:16.852726  1213 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0801 00:05:16.852735  1213 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0801 00:05:16.852798  1213 net.cpp:141] Setting up lstm1_gate_input_1
I0801 00:05:16.852809  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.852814  1213 net.cpp:156] Memory required for data: 78016
I0801 00:05:16.852819  1213 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0801 00:05:16.852833  1213 net.cpp:91] Creating Layer lstm1_unit_1
I0801 00:05:16.852838  1213 net.cpp:425] lstm1_unit_1 <- c_0
I0801 00:05:16.852845  1213 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0801 00:05:16.852851  1213 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0801 00:05:16.852859  1213 net.cpp:399] lstm1_unit_1 -> c_1
I0801 00:05:16.852869  1213 net.cpp:399] lstm1_unit_1 -> h_1
I0801 00:05:16.852941  1213 net.cpp:141] Setting up lstm1_unit_1
I0801 00:05:16.852952  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.852958  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.852963  1213 net.cpp:156] Memory required for data: 86016
I0801 00:05:16.852968  1213 layer_factory.hpp:77] Creating layer lstm1_
I0801 00:05:16.852978  1213 net.cpp:91] Creating Layer lstm1_
I0801 00:05:16.852983  1213 net.cpp:425] lstm1_ <- c_1
I0801 00:05:16.852991  1213 net.cpp:399] lstm1_ -> c_T
I0801 00:05:16.853024  1213 net.cpp:141] Setting up lstm1_
I0801 00:05:16.853034  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.853039  1213 net.cpp:156] Memory required for data: 90016
I0801 00:05:16.853044  1213 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0801 00:05:16.853057  1213 net.cpp:91] Creating Layer lstm1_h_concat
I0801 00:05:16.853063  1213 net.cpp:425] lstm1_h_concat <- h_1
I0801 00:05:16.853071  1213 net.cpp:399] lstm1_h_concat -> h
I0801 00:05:16.853119  1213 net.cpp:141] Setting up lstm1_h_concat
I0801 00:05:16.853129  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.853134  1213 net.cpp:156] Memory required for data: 94016
I0801 00:05:16.853139  1213 layer_factory.hpp:77] Creating layer h_pseudoloss
I0801 00:05:16.853155  1213 net.cpp:91] Creating Layer h_pseudoloss
I0801 00:05:16.853160  1213 net.cpp:425] h_pseudoloss <- h
I0801 00:05:16.853170  1213 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0801 00:05:16.853268  1213 net.cpp:141] Setting up h_pseudoloss
I0801 00:05:16.853289  1213 net.cpp:148] Top shape: (1)
I0801 00:05:16.853294  1213 net.cpp:151]     with loss weight 1
I0801 00:05:16.853337  1213 net.cpp:156] Memory required for data: 94020
I0801 00:05:16.853343  1213 net.cpp:217] h_pseudoloss needs backward computation.
I0801 00:05:16.853348  1213 net.cpp:217] lstm1_h_concat needs backward computation.
I0801 00:05:16.853353  1213 net.cpp:219] lstm1_ does not need backward computation.
I0801 00:05:16.853358  1213 net.cpp:217] lstm1_unit_1 needs backward computation.
I0801 00:05:16.853365  1213 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0801 00:05:16.853370  1213 net.cpp:217] lstm1_transform_1 needs backward computation.
I0801 00:05:16.853376  1213 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0801 00:05:16.853382  1213 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0801 00:05:16.853389  1213 net.cpp:217] lstm1_x_transform needs backward computation.
I0801 00:05:16.853394  1213 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0801 00:05:16.853399  1213 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0801 00:05:16.853405  1213 net.cpp:219] lstm1_ does not need backward computation.
I0801 00:05:16.853410  1213 net.cpp:219] lstm1_ does not need backward computation.
I0801 00:05:16.853415  1213 net.cpp:261] This network produces output c_T
I0801 00:05:16.853420  1213 net.cpp:261] This network produces output h_pseudoloss
I0801 00:05:16.853438  1213 net.cpp:274] Network initialization done.
I0801 00:05:16.853497  1213 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0801 00:05:16.853504  1213 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0801 00:05:16.853509  1213 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0801 00:05:16.853629  1213 net.cpp:141] Setting up lstm1
I0801 00:05:16.853643  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.853648  1213 net.cpp:156] Memory required for data: 26408
I0801 00:05:16.853662  1213 layer_factory.hpp:77] Creating layer concat
I0801 00:05:16.853672  1213 net.cpp:91] Creating Layer concat
I0801 00:05:16.853679  1213 net.cpp:425] concat <- lstm1
I0801 00:05:16.853688  1213 net.cpp:425] concat <- embedded_input_sentence
I0801 00:05:16.853693  1213 net.cpp:425] concat <- reshaped_stage_indicator
I0801 00:05:16.853701  1213 net.cpp:399] concat -> lstm1_video_sequence
I0801 00:05:16.853737  1213 net.cpp:141] Setting up concat
I0801 00:05:16.853747  1213 net.cpp:148] Top shape: 1 1 1501 (1501)
I0801 00:05:16.853752  1213 net.cpp:156] Memory required for data: 32412
I0801 00:05:16.853759  1213 layer_factory.hpp:77] Creating layer lstm2
I0801 00:05:16.853772  1213 net.cpp:91] Creating Layer lstm2
I0801 00:05:16.853778  1213 net.cpp:425] lstm2 <- lstm1_video_sequence
I0801 00:05:16.853785  1213 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0801 00:05:16.853793  1213 net.cpp:399] lstm2 -> lstm2
I0801 00:05:16.853804  1213 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0801 00:05:16.854086  1213 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0801 00:05:16.854182  1213 layer_factory.hpp:77] Creating layer lstm2_
I0801 00:05:16.854195  1213 net.cpp:91] Creating Layer lstm2_
I0801 00:05:16.854203  1213 net.cpp:399] lstm2_ -> x
I0801 00:05:16.854215  1213 net.cpp:399] lstm2_ -> cont
I0801 00:05:16.854274  1213 net.cpp:141] Setting up lstm2_
I0801 00:05:16.854285  1213 net.cpp:148] Top shape: 1 1 1501 (1501)
I0801 00:05:16.854291  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.854296  1213 net.cpp:156] Memory required for data: 6008
I0801 00:05:16.854302  1213 layer_factory.hpp:77] Creating layer lstm2_
I0801 00:05:16.854311  1213 net.cpp:91] Creating Layer lstm2_
I0801 00:05:16.854318  1213 net.cpp:399] lstm2_ -> c_0
I0801 00:05:16.854329  1213 net.cpp:399] lstm2_ -> h_0
I0801 00:05:16.854383  1213 net.cpp:141] Setting up lstm2_
I0801 00:05:16.854393  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.854400  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.854404  1213 net.cpp:156] Memory required for data: 14008
I0801 00:05:16.854409  1213 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0801 00:05:16.854427  1213 net.cpp:91] Creating Layer lstm2_cont_slice
I0801 00:05:16.854432  1213 net.cpp:425] lstm2_cont_slice <- cont
I0801 00:05:16.854444  1213 net.cpp:399] lstm2_cont_slice -> cont_1
I0801 00:05:16.854480  1213 net.cpp:141] Setting up lstm2_cont_slice
I0801 00:05:16.854490  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.854495  1213 net.cpp:156] Memory required for data: 14012
I0801 00:05:16.854499  1213 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0801 00:05:16.854506  1213 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0801 00:05:16.854512  1213 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0801 00:05:16.854519  1213 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0801 00:05:16.854538  1213 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0801 00:05:16.854588  1213 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0801 00:05:16.854598  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.854604  1213 net.cpp:148] Top shape: 1 1 (1)
I0801 00:05:16.854609  1213 net.cpp:156] Memory required for data: 14020
I0801 00:05:16.854614  1213 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0801 00:05:16.854626  1213 net.cpp:91] Creating Layer lstm2_x_transform
I0801 00:05:16.854632  1213 net.cpp:425] lstm2_x_transform <- x
I0801 00:05:16.854641  1213 net.cpp:399] lstm2_x_transform -> W_xc_x
I0801 00:05:16.918716  1213 net.cpp:141] Setting up lstm2_x_transform
I0801 00:05:16.918761  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.918768  1213 net.cpp:156] Memory required for data: 30020
I0801 00:05:16.918789  1213 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0801 00:05:16.918807  1213 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0801 00:05:16.918815  1213 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0801 00:05:16.918826  1213 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0801 00:05:16.918874  1213 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0801 00:05:16.918886  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.918890  1213 net.cpp:156] Memory required for data: 46020
I0801 00:05:16.918896  1213 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0801 00:05:16.918910  1213 net.cpp:91] Creating Layer lstm2_h_conted_0
I0801 00:05:16.918917  1213 net.cpp:425] lstm2_h_conted_0 <- h_0
I0801 00:05:16.918926  1213 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0801 00:05:16.918934  1213 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0801 00:05:16.919037  1213 net.cpp:141] Setting up lstm2_h_conted_0
I0801 00:05:16.919047  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.919052  1213 net.cpp:156] Memory required for data: 50020
I0801 00:05:16.919057  1213 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0801 00:05:16.919073  1213 net.cpp:91] Creating Layer lstm2_transform_1
I0801 00:05:16.919080  1213 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0801 00:05:16.919090  1213 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0801 00:05:16.962041  1213 net.cpp:141] Setting up lstm2_transform_1
I0801 00:05:16.962095  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.962102  1213 net.cpp:156] Memory required for data: 66020
I0801 00:05:16.962126  1213 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0801 00:05:16.962146  1213 net.cpp:91] Creating Layer lstm2_gate_input_1
I0801 00:05:16.962153  1213 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0801 00:05:16.962162  1213 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0801 00:05:16.962175  1213 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0801 00:05:16.962226  1213 net.cpp:141] Setting up lstm2_gate_input_1
I0801 00:05:16.962236  1213 net.cpp:148] Top shape: 1 1 4000 (4000)
I0801 00:05:16.962242  1213 net.cpp:156] Memory required for data: 82020
I0801 00:05:16.962247  1213 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0801 00:05:16.962260  1213 net.cpp:91] Creating Layer lstm2_unit_1
I0801 00:05:16.962266  1213 net.cpp:425] lstm2_unit_1 <- c_0
I0801 00:05:16.962273  1213 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0801 00:05:16.962280  1213 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0801 00:05:16.962287  1213 net.cpp:399] lstm2_unit_1 -> c_1
I0801 00:05:16.962297  1213 net.cpp:399] lstm2_unit_1 -> h_1
I0801 00:05:16.962365  1213 net.cpp:141] Setting up lstm2_unit_1
I0801 00:05:16.962375  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.962381  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.962386  1213 net.cpp:156] Memory required for data: 90020
I0801 00:05:16.962393  1213 layer_factory.hpp:77] Creating layer lstm2_
I0801 00:05:16.962401  1213 net.cpp:91] Creating Layer lstm2_
I0801 00:05:16.962407  1213 net.cpp:425] lstm2_ <- c_1
I0801 00:05:16.962417  1213 net.cpp:399] lstm2_ -> c_T
I0801 00:05:16.962450  1213 net.cpp:141] Setting up lstm2_
I0801 00:05:16.962460  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.962466  1213 net.cpp:156] Memory required for data: 94020
I0801 00:05:16.962471  1213 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0801 00:05:16.962481  1213 net.cpp:91] Creating Layer lstm2_h_concat
I0801 00:05:16.962486  1213 net.cpp:425] lstm2_h_concat <- h_1
I0801 00:05:16.962494  1213 net.cpp:399] lstm2_h_concat -> h
I0801 00:05:16.962533  1213 net.cpp:141] Setting up lstm2_h_concat
I0801 00:05:16.962543  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.962548  1213 net.cpp:156] Memory required for data: 98020
I0801 00:05:16.962553  1213 layer_factory.hpp:77] Creating layer h_pseudoloss
I0801 00:05:16.962563  1213 net.cpp:91] Creating Layer h_pseudoloss
I0801 00:05:16.962568  1213 net.cpp:425] h_pseudoloss <- h
I0801 00:05:16.962576  1213 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0801 00:05:16.962677  1213 net.cpp:141] Setting up h_pseudoloss
I0801 00:05:16.962688  1213 net.cpp:148] Top shape: (1)
I0801 00:05:16.962693  1213 net.cpp:151]     with loss weight 1
I0801 00:05:16.962713  1213 net.cpp:156] Memory required for data: 98024
I0801 00:05:16.962719  1213 net.cpp:217] h_pseudoloss needs backward computation.
I0801 00:05:16.962725  1213 net.cpp:217] lstm2_h_concat needs backward computation.
I0801 00:05:16.962730  1213 net.cpp:219] lstm2_ does not need backward computation.
I0801 00:05:16.962736  1213 net.cpp:217] lstm2_unit_1 needs backward computation.
I0801 00:05:16.962743  1213 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0801 00:05:16.962748  1213 net.cpp:217] lstm2_transform_1 needs backward computation.
I0801 00:05:16.962754  1213 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0801 00:05:16.962759  1213 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0801 00:05:16.962765  1213 net.cpp:217] lstm2_x_transform needs backward computation.
I0801 00:05:16.962770  1213 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0801 00:05:16.962776  1213 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0801 00:05:16.962782  1213 net.cpp:219] lstm2_ does not need backward computation.
I0801 00:05:16.962787  1213 net.cpp:219] lstm2_ does not need backward computation.
I0801 00:05:16.962791  1213 net.cpp:261] This network produces output c_T
I0801 00:05:16.962797  1213 net.cpp:261] This network produces output h_pseudoloss
I0801 00:05:16.962812  1213 net.cpp:274] Network initialization done.
I0801 00:05:16.962864  1213 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0801 00:05:16.962872  1213 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0801 00:05:16.962877  1213 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0801 00:05:16.962985  1213 net.cpp:141] Setting up lstm2
I0801 00:05:16.962996  1213 net.cpp:148] Top shape: 1 1 1000 (1000)
I0801 00:05:16.963001  1213 net.cpp:156] Memory required for data: 36412
I0801 00:05:16.963016  1213 layer_factory.hpp:77] Creating layer predict
I0801 00:05:16.963030  1213 net.cpp:91] Creating Layer predict
I0801 00:05:16.963038  1213 net.cpp:425] predict <- lstm2
I0801 00:05:16.963048  1213 net.cpp:399] predict -> predict
I0801 00:05:17.058318  1223 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld5793331974478773207/bvlc_reference_caffenet.caffemodel
I0801 00:05:17.058363  1223 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0801 00:05:17.058369  1223 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0801 00:05:17.058374  1223 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld5793331974478773207/bvlc_reference_caffenet.caffemodel
I0801 00:05:17.447885  1213 net.cpp:141] Setting up predict
I0801 00:05:17.447935  1213 net.cpp:148] Top shape: 1 1 46168 (46168)
I0801 00:05:17.447943  1213 net.cpp:156] Memory required for data: 221084
I0801 00:05:17.447957  1213 layer_factory.hpp:77] Creating layer probs
I0801 00:05:17.447975  1213 net.cpp:91] Creating Layer probs
I0801 00:05:17.447983  1213 net.cpp:425] probs <- predict
I0801 00:05:17.447994  1213 net.cpp:399] probs -> probs
I0801 00:05:17.448969  1213 net.cpp:141] Setting up probs
I0801 00:05:17.448989  1213 net.cpp:148] Top shape: 1 1 46168 (46168)
I0801 00:05:17.448995  1213 net.cpp:156] Memory required for data: 405756
I0801 00:05:17.449002  1213 net.cpp:219] probs does not need backward computation.
I0801 00:05:17.449007  1213 net.cpp:219] predict does not need backward computation.
I0801 00:05:17.449013  1213 net.cpp:219] lstm2 does not need backward computation.
I0801 00:05:17.449020  1213 net.cpp:219] concat does not need backward computation.
I0801 00:05:17.449028  1213 net.cpp:219] lstm1 does not need backward computation.
I0801 00:05:17.449034  1213 net.cpp:219] embedding does not need backward computation.
I0801 00:05:17.449040  1213 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0801 00:05:17.449046  1213 net.cpp:219] reshape_frames does not need backward computation.
I0801 00:05:17.449051  1213 net.cpp:219] embed_encoder does not need backward computation.
I0801 00:05:17.449057  1213 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0801 00:05:17.449066  1213 net.cpp:219] input does not need backward computation.
I0801 00:05:17.449071  1213 net.cpp:261] This network produces output probs
I0801 00:05:17.449089  1213 net.cpp:274] Network initialization done.
I0801 00:05:17.452215  1223 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0801 00:05:17.507773  1223 net.cpp:752] Ignoring source layer loss
I0801 00:05:17.854420  1213 net.cpp:752] Ignoring source layer data
I0801 00:05:17.854455  1213 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0801 00:05:17.854461  1213 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0801 00:05:17.928783  1213 net.cpp:752] Ignoring source layer cross_entropy_loss
