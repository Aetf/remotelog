SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1469046332/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-07-20 16:26:16,127 ERROR Logger contains an invalid element or attribute "appender"
2016-07-20 16:26:31,107 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld886598422143268237/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0720 16:26:43.527073 27595 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0720 16:26:43.527274 27595 layer_factory.hpp:77] Creating layer data
I0720 16:26:43.527302 27595 net.cpp:91] Creating Layer data
I0720 16:26:43.527313 27595 net.cpp:399] data -> data
I0720 16:26:43.532095 27601 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0720 16:26:43.532217 27601 layer_factory.hpp:77] Creating layer data
I0720 16:26:43.532232 27601 net.cpp:91] Creating Layer data
I0720 16:26:43.532239 27601 net.cpp:399] data -> data
I0720 16:26:43.955615 27585 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld886598422143268237/s2vt.words_to_preds.prototxt
I0720 16:26:43.955682 27585 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0720 16:26:43.955691 27585 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0720 16:26:43.956012 27585 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0720 16:26:43.956190 27585 layer_factory.hpp:77] Creating layer input
I0720 16:26:43.956208 27585 net.cpp:91] Creating Layer input
I0720 16:26:43.956218 27585 net.cpp:399] input -> frames_fc7
I0720 16:26:43.956238 27585 net.cpp:399] input -> cont_sentence
I0720 16:26:43.956253 27585 net.cpp:399] input -> input_sentence
I0720 16:26:43.956262 27585 net.cpp:399] input -> stage_indicator
I0720 16:26:44.449641 27595 net.cpp:141] Setting up data
I0720 16:26:44.449720 27595 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0720 16:26:44.449728 27595 net.cpp:156] Memory required for data: 6183480
I0720 16:26:44.449754 27595 layer_factory.hpp:77] Creating layer conv1
I0720 16:26:44.449791 27595 net.cpp:91] Creating Layer conv1
I0720 16:26:44.449801 27595 net.cpp:425] conv1 <- data
I0720 16:26:44.449817 27595 net.cpp:399] conv1 -> conv1
I0720 16:26:44.449841 27585 net.cpp:141] Setting up input
I0720 16:26:44.449859 27585 net.cpp:148] Top shape: 1 4096 (4096)
I0720 16:26:44.449867 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.449872 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.449877 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.449882 27585 net.cpp:156] Memory required for data: 16396
I0720 16:26:44.449887 27585 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0720 16:26:44.449905 27585 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0720 16:26:44.449911 27585 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0720 16:26:44.449942 27585 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0720 16:26:44.449955 27585 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0720 16:26:44.450129 27585 net.cpp:141] Setting up cont_sentence_input_1_split
I0720 16:26:44.450140 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.450146 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.450150 27585 net.cpp:156] Memory required for data: 16404
I0720 16:26:44.450155 27585 layer_factory.hpp:77] Creating layer embed_encoder
I0720 16:26:44.450177 27585 net.cpp:91] Creating Layer embed_encoder
I0720 16:26:44.450182 27585 net.cpp:425] embed_encoder <- frames_fc7
I0720 16:26:44.450201 27585 net.cpp:399] embed_encoder -> embedded_in_frames
I0720 16:26:44.489964 27601 net.cpp:141] Setting up data
I0720 16:26:44.490020 27601 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0720 16:26:44.490026 27601 net.cpp:156] Memory required for data: 6183480
I0720 16:26:44.490036 27601 layer_factory.hpp:77] Creating layer conv1
I0720 16:26:44.490053 27585 net.cpp:141] Setting up embed_encoder
I0720 16:26:44.490061 27601 net.cpp:91] Creating Layer conv1
I0720 16:26:44.490075 27585 net.cpp:148] Top shape: 1 500 (500)
I0720 16:26:44.490075 27601 net.cpp:425] conv1 <- data
I0720 16:26:44.490083 27585 net.cpp:156] Memory required for data: 18404
I0720 16:26:44.490092 27601 net.cpp:399] conv1 -> conv1
I0720 16:26:44.490109 27585 layer_factory.hpp:77] Creating layer reshape_frames
I0720 16:26:44.490134 27585 net.cpp:91] Creating Layer reshape_frames
I0720 16:26:44.490141 27585 net.cpp:425] reshape_frames <- embedded_in_frames
I0720 16:26:44.490150 27585 net.cpp:399] reshape_frames -> embedded_input_frames
I0720 16:26:44.495472 27585 net.cpp:141] Setting up reshape_frames
I0720 16:26:44.495493 27585 net.cpp:148] Top shape: 1 1 500 (500)
I0720 16:26:44.495498 27585 net.cpp:156] Memory required for data: 20404
I0720 16:26:44.495504 27585 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0720 16:26:44.495515 27585 net.cpp:91] Creating Layer reshape_stage_indicator
I0720 16:26:44.495522 27585 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0720 16:26:44.495532 27585 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0720 16:26:44.495656 27585 net.cpp:141] Setting up reshape_stage_indicator
I0720 16:26:44.495666 27585 net.cpp:148] Top shape: 1 1 1 (1)
I0720 16:26:44.495671 27585 net.cpp:156] Memory required for data: 20408
I0720 16:26:44.495676 27585 layer_factory.hpp:77] Creating layer embedding
I0720 16:26:44.495692 27585 net.cpp:91] Creating Layer embedding
I0720 16:26:44.495697 27585 net.cpp:425] embedding <- input_sentence
I0720 16:26:44.495703 27585 net.cpp:399] embedding -> embedded_input_sentence
I0720 16:26:44.720630 27585 net.cpp:141] Setting up embedding
I0720 16:26:44.720680 27585 net.cpp:148] Top shape: 1 1 500 (500)
I0720 16:26:44.720687 27585 net.cpp:156] Memory required for data: 22408
I0720 16:26:44.720706 27585 layer_factory.hpp:77] Creating layer lstm1
I0720 16:26:44.720728 27585 net.cpp:91] Creating Layer lstm1
I0720 16:26:44.720736 27585 net.cpp:425] lstm1 <- embedded_input_frames
I0720 16:26:44.720746 27585 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0720 16:26:44.720754 27585 net.cpp:399] lstm1 -> lstm1
I0720 16:26:44.720791 27585 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0720 16:26:44.721177 27585 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0720 16:26:44.721271 27585 layer_factory.hpp:77] Creating layer lstm1_
I0720 16:26:44.721288 27585 net.cpp:91] Creating Layer lstm1_
I0720 16:26:44.721295 27585 net.cpp:399] lstm1_ -> x
I0720 16:26:44.721308 27585 net.cpp:399] lstm1_ -> cont
I0720 16:26:44.736240 27585 net.cpp:141] Setting up lstm1_
I0720 16:26:44.736277 27585 net.cpp:148] Top shape: 1 1 500 (500)
I0720 16:26:44.736284 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.736289 27585 net.cpp:156] Memory required for data: 2004
I0720 16:26:44.736297 27585 layer_factory.hpp:77] Creating layer lstm1_
I0720 16:26:44.736325 27585 net.cpp:91] Creating Layer lstm1_
I0720 16:26:44.736333 27585 net.cpp:399] lstm1_ -> c_0
I0720 16:26:44.736351 27585 net.cpp:399] lstm1_ -> h_0
I0720 16:26:44.760751 27585 net.cpp:141] Setting up lstm1_
I0720 16:26:44.760792 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.760800 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.760804 27585 net.cpp:156] Memory required for data: 10004
I0720 16:26:44.760812 27585 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0720 16:26:44.760830 27585 net.cpp:91] Creating Layer lstm1_cont_slice
I0720 16:26:44.760836 27585 net.cpp:425] lstm1_cont_slice <- cont
I0720 16:26:44.760848 27585 net.cpp:399] lstm1_cont_slice -> cont_1
I0720 16:26:44.775943 27585 net.cpp:141] Setting up lstm1_cont_slice
I0720 16:26:44.775972 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.775979 27585 net.cpp:156] Memory required for data: 10008
I0720 16:26:44.775985 27585 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0720 16:26:44.775995 27585 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0720 16:26:44.776000 27585 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0720 16:26:44.776008 27585 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0720 16:26:44.776017 27585 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0720 16:26:44.788663 27585 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0720 16:26:44.788694 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.788702 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.788705 27585 net.cpp:156] Memory required for data: 10016
I0720 16:26:44.788712 27585 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0720 16:26:44.788734 27585 net.cpp:91] Creating Layer lstm1_x_transform
I0720 16:26:44.788739 27585 net.cpp:425] lstm1_x_transform <- x
I0720 16:26:44.788749 27585 net.cpp:399] lstm1_x_transform -> W_xc_x
I0720 16:26:44.862424 27585 net.cpp:141] Setting up lstm1_x_transform
I0720 16:26:44.862480 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:44.862488 27585 net.cpp:156] Memory required for data: 26016
I0720 16:26:44.862512 27585 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0720 16:26:44.862529 27585 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0720 16:26:44.862536 27585 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0720 16:26:44.862546 27585 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0720 16:26:44.865924 27585 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0720 16:26:44.865944 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:44.865950 27585 net.cpp:156] Memory required for data: 42016
I0720 16:26:44.865955 27585 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0720 16:26:44.865968 27585 net.cpp:91] Creating Layer lstm1_h_conted_0
I0720 16:26:44.865973 27585 net.cpp:425] lstm1_h_conted_0 <- h_0
I0720 16:26:44.865979 27585 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0720 16:26:44.865986 27585 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0720 16:26:44.897106 27585 net.cpp:141] Setting up lstm1_h_conted_0
I0720 16:26:44.897155 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.897161 27585 net.cpp:156] Memory required for data: 46016
I0720 16:26:44.897169 27585 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0720 16:26:44.897192 27585 net.cpp:91] Creating Layer lstm1_transform_1
I0720 16:26:44.897199 27585 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0720 16:26:44.897212 27585 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0720 16:26:44.930883 27595 net.cpp:141] Setting up conv1
I0720 16:26:44.930937 27595 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 16:26:44.930943 27595 net.cpp:156] Memory required for data: 17799480
I0720 16:26:44.930968 27595 layer_factory.hpp:77] Creating layer relu1
I0720 16:26:44.930990 27595 net.cpp:91] Creating Layer relu1
I0720 16:26:44.930997 27595 net.cpp:425] relu1 <- conv1
I0720 16:26:44.931010 27595 net.cpp:386] relu1 -> conv1 (in-place)
I0720 16:26:44.931848 27595 net.cpp:141] Setting up relu1
I0720 16:26:44.931862 27595 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 16:26:44.931869 27595 net.cpp:156] Memory required for data: 29415480
I0720 16:26:44.931874 27595 layer_factory.hpp:77] Creating layer pool1
I0720 16:26:44.931886 27595 net.cpp:91] Creating Layer pool1
I0720 16:26:44.931892 27595 net.cpp:425] pool1 <- conv1
I0720 16:26:44.931903 27595 net.cpp:399] pool1 -> pool1
I0720 16:26:44.932272 27595 net.cpp:141] Setting up pool1
I0720 16:26:44.932312 27595 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 16:26:44.932318 27595 net.cpp:156] Memory required for data: 32214840
I0720 16:26:44.932327 27595 layer_factory.hpp:77] Creating layer norm1
I0720 16:26:44.932353 27595 net.cpp:91] Creating Layer norm1
I0720 16:26:44.932359 27595 net.cpp:425] norm1 <- pool1
I0720 16:26:44.932374 27595 net.cpp:399] norm1 -> norm1
I0720 16:26:44.935072 27595 net.cpp:141] Setting up norm1
I0720 16:26:44.935096 27595 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 16:26:44.935101 27595 net.cpp:156] Memory required for data: 35014200
I0720 16:26:44.935106 27595 layer_factory.hpp:77] Creating layer conv2
I0720 16:26:44.935122 27595 net.cpp:91] Creating Layer conv2
I0720 16:26:44.935127 27595 net.cpp:425] conv2 <- norm1
I0720 16:26:44.935138 27595 net.cpp:399] conv2 -> conv2
I0720 16:26:44.935660 27601 net.cpp:141] Setting up conv1
I0720 16:26:44.935681 27601 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 16:26:44.935688 27601 net.cpp:156] Memory required for data: 17799480
I0720 16:26:44.935703 27601 layer_factory.hpp:77] Creating layer relu1
I0720 16:26:44.935714 27601 net.cpp:91] Creating Layer relu1
I0720 16:26:44.935719 27601 net.cpp:425] relu1 <- conv1
I0720 16:26:44.935727 27601 net.cpp:386] relu1 -> conv1 (in-place)
I0720 16:26:44.936560 27601 net.cpp:141] Setting up relu1
I0720 16:26:44.936573 27601 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 16:26:44.936578 27601 net.cpp:156] Memory required for data: 29415480
I0720 16:26:44.936583 27601 layer_factory.hpp:77] Creating layer pool1
I0720 16:26:44.936609 27601 net.cpp:91] Creating Layer pool1
I0720 16:26:44.936615 27601 net.cpp:425] pool1 <- conv1
I0720 16:26:44.936622 27601 net.cpp:399] pool1 -> pool1
I0720 16:26:44.938277 27601 net.cpp:141] Setting up pool1
I0720 16:26:44.938292 27601 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 16:26:44.938297 27601 net.cpp:156] Memory required for data: 32214840
I0720 16:26:44.938302 27601 layer_factory.hpp:77] Creating layer norm1
I0720 16:26:44.938313 27601 net.cpp:91] Creating Layer norm1
I0720 16:26:44.938318 27601 net.cpp:425] norm1 <- pool1
I0720 16:26:44.938324 27601 net.cpp:399] norm1 -> norm1
I0720 16:26:44.939369 27601 net.cpp:141] Setting up norm1
I0720 16:26:44.939385 27601 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 16:26:44.939390 27601 net.cpp:156] Memory required for data: 35014200
I0720 16:26:44.939395 27601 layer_factory.hpp:77] Creating layer conv2
I0720 16:26:44.939409 27601 net.cpp:91] Creating Layer conv2
I0720 16:26:44.939414 27601 net.cpp:425] conv2 <- norm1
I0720 16:26:44.939421 27601 net.cpp:399] conv2 -> conv2
I0720 16:26:44.945122 27595 net.cpp:141] Setting up conv2
I0720 16:26:44.945147 27595 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 16:26:44.945152 27595 net.cpp:156] Memory required for data: 42479160
I0720 16:26:44.945166 27595 layer_factory.hpp:77] Creating layer relu2
I0720 16:26:44.945180 27595 net.cpp:91] Creating Layer relu2
I0720 16:26:44.945185 27595 net.cpp:425] relu2 <- conv2
I0720 16:26:44.945194 27595 net.cpp:386] relu2 -> conv2 (in-place)
I0720 16:26:44.946249 27595 net.cpp:141] Setting up relu2
I0720 16:26:44.946267 27595 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 16:26:44.946271 27595 net.cpp:156] Memory required for data: 49944120
I0720 16:26:44.946277 27595 layer_factory.hpp:77] Creating layer pool2
I0720 16:26:44.946286 27595 net.cpp:91] Creating Layer pool2
I0720 16:26:44.946291 27595 net.cpp:425] pool2 <- conv2
I0720 16:26:44.946297 27595 net.cpp:399] pool2 -> pool2
I0720 16:26:44.946648 27595 net.cpp:141] Setting up pool2
I0720 16:26:44.946660 27595 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.946665 27595 net.cpp:156] Memory required for data: 51674680
I0720 16:26:44.946669 27595 layer_factory.hpp:77] Creating layer norm2
I0720 16:26:44.946682 27595 net.cpp:91] Creating Layer norm2
I0720 16:26:44.946697 27595 net.cpp:425] norm2 <- pool2
I0720 16:26:44.946709 27595 net.cpp:399] norm2 -> norm2
I0720 16:26:44.947093 27595 net.cpp:141] Setting up norm2
I0720 16:26:44.947104 27595 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.947108 27595 net.cpp:156] Memory required for data: 53405240
I0720 16:26:44.947113 27595 layer_factory.hpp:77] Creating layer conv3
I0720 16:26:44.947131 27595 net.cpp:91] Creating Layer conv3
I0720 16:26:44.947136 27595 net.cpp:425] conv3 <- norm2
I0720 16:26:44.947146 27595 net.cpp:399] conv3 -> conv3
I0720 16:26:44.949018 27601 net.cpp:141] Setting up conv2
I0720 16:26:44.949040 27601 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 16:26:44.949045 27601 net.cpp:156] Memory required for data: 42479160
I0720 16:26:44.949059 27601 layer_factory.hpp:77] Creating layer relu2
I0720 16:26:44.949067 27601 net.cpp:91] Creating Layer relu2
I0720 16:26:44.949072 27601 net.cpp:425] relu2 <- conv2
I0720 16:26:44.949079 27601 net.cpp:386] relu2 -> conv2 (in-place)
I0720 16:26:44.951169 27601 net.cpp:141] Setting up relu2
I0720 16:26:44.951189 27601 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 16:26:44.951194 27601 net.cpp:156] Memory required for data: 49944120
I0720 16:26:44.951198 27601 layer_factory.hpp:77] Creating layer pool2
I0720 16:26:44.951208 27601 net.cpp:91] Creating Layer pool2
I0720 16:26:44.951213 27601 net.cpp:425] pool2 <- conv2
I0720 16:26:44.951223 27601 net.cpp:399] pool2 -> pool2
I0720 16:26:44.952466 27601 net.cpp:141] Setting up pool2
I0720 16:26:44.952479 27601 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.952484 27601 net.cpp:156] Memory required for data: 51674680
I0720 16:26:44.952488 27601 layer_factory.hpp:77] Creating layer norm2
I0720 16:26:44.952503 27601 net.cpp:91] Creating Layer norm2
I0720 16:26:44.952508 27601 net.cpp:425] norm2 <- pool2
I0720 16:26:44.952515 27601 net.cpp:399] norm2 -> norm2
I0720 16:26:44.952817 27601 net.cpp:141] Setting up norm2
I0720 16:26:44.952831 27601 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.952834 27601 net.cpp:156] Memory required for data: 53405240
I0720 16:26:44.952839 27601 layer_factory.hpp:77] Creating layer conv3
I0720 16:26:44.952854 27601 net.cpp:91] Creating Layer conv3
I0720 16:26:44.952858 27601 net.cpp:425] conv3 <- norm2
I0720 16:26:44.952865 27601 net.cpp:399] conv3 -> conv3
I0720 16:26:44.953996 27585 net.cpp:141] Setting up lstm1_transform_1
I0720 16:26:44.954016 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:44.954021 27585 net.cpp:156] Memory required for data: 62016
I0720 16:26:44.954032 27585 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0720 16:26:44.954046 27585 net.cpp:91] Creating Layer lstm1_gate_input_1
I0720 16:26:44.954051 27585 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0720 16:26:44.954058 27585 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0720 16:26:44.954066 27585 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0720 16:26:44.954171 27585 net.cpp:141] Setting up lstm1_gate_input_1
I0720 16:26:44.954182 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:44.954187 27585 net.cpp:156] Memory required for data: 78016
I0720 16:26:44.954191 27585 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0720 16:26:44.954203 27585 net.cpp:91] Creating Layer lstm1_unit_1
I0720 16:26:44.954208 27585 net.cpp:425] lstm1_unit_1 <- c_0
I0720 16:26:44.954215 27585 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0720 16:26:44.954219 27585 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0720 16:26:44.954226 27585 net.cpp:399] lstm1_unit_1 -> c_1
I0720 16:26:44.954233 27585 net.cpp:399] lstm1_unit_1 -> h_1
I0720 16:26:44.956979 27585 net.cpp:141] Setting up lstm1_unit_1
I0720 16:26:44.957000 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.957006 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.957011 27585 net.cpp:156] Memory required for data: 86016
I0720 16:26:44.957016 27585 layer_factory.hpp:77] Creating layer lstm1_
I0720 16:26:44.957026 27585 net.cpp:91] Creating Layer lstm1_
I0720 16:26:44.957031 27585 net.cpp:425] lstm1_ <- c_1
I0720 16:26:44.957038 27585 net.cpp:399] lstm1_ -> c_T
I0720 16:26:44.957784 27585 net.cpp:141] Setting up lstm1_
I0720 16:26:44.957798 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.957803 27585 net.cpp:156] Memory required for data: 90016
I0720 16:26:44.957808 27585 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0720 16:26:44.957829 27585 net.cpp:91] Creating Layer lstm1_h_concat
I0720 16:26:44.957834 27585 net.cpp:425] lstm1_h_concat <- h_1
I0720 16:26:44.957841 27585 net.cpp:399] lstm1_h_concat -> h
I0720 16:26:44.958463 27585 net.cpp:141] Setting up lstm1_h_concat
I0720 16:26:44.958473 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.958478 27585 net.cpp:156] Memory required for data: 94016
I0720 16:26:44.958482 27585 layer_factory.hpp:77] Creating layer h_pseudoloss
I0720 16:26:44.958499 27585 net.cpp:91] Creating Layer h_pseudoloss
I0720 16:26:44.958504 27585 net.cpp:425] h_pseudoloss <- h
I0720 16:26:44.958511 27585 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0720 16:26:44.958750 27585 net.cpp:141] Setting up h_pseudoloss
I0720 16:26:44.958761 27585 net.cpp:148] Top shape: (1)
I0720 16:26:44.958766 27585 net.cpp:151]     with loss weight 1
I0720 16:26:44.958806 27585 net.cpp:156] Memory required for data: 94020
I0720 16:26:44.958812 27585 net.cpp:217] h_pseudoloss needs backward computation.
I0720 16:26:44.958817 27585 net.cpp:217] lstm1_h_concat needs backward computation.
I0720 16:26:44.958822 27585 net.cpp:219] lstm1_ does not need backward computation.
I0720 16:26:44.958825 27585 net.cpp:217] lstm1_unit_1 needs backward computation.
I0720 16:26:44.958832 27585 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0720 16:26:44.958835 27585 net.cpp:217] lstm1_transform_1 needs backward computation.
I0720 16:26:44.958840 27585 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0720 16:26:44.958845 27585 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0720 16:26:44.958850 27585 net.cpp:217] lstm1_x_transform needs backward computation.
I0720 16:26:44.958855 27585 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0720 16:26:44.958860 27585 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0720 16:26:44.958864 27585 net.cpp:219] lstm1_ does not need backward computation.
I0720 16:26:44.958868 27585 net.cpp:219] lstm1_ does not need backward computation.
I0720 16:26:44.958871 27585 net.cpp:261] This network produces output c_T
I0720 16:26:44.958878 27585 net.cpp:261] This network produces output h_pseudoloss
I0720 16:26:44.958897 27585 net.cpp:274] Network initialization done.
I0720 16:26:44.958950 27595 net.cpp:141] Setting up conv3
I0720 16:26:44.958957 27585 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0720 16:26:44.958964 27585 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0720 16:26:44.958966 27595 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.958968 27585 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0720 16:26:44.958977 27595 net.cpp:156] Memory required for data: 56001080
I0720 16:26:44.958992 27595 layer_factory.hpp:77] Creating layer relu3
I0720 16:26:44.959002 27595 net.cpp:91] Creating Layer relu3
I0720 16:26:44.959007 27595 net.cpp:425] relu3 <- conv3
I0720 16:26:44.959014 27595 net.cpp:386] relu3 -> conv3 (in-place)
I0720 16:26:44.960402 27585 net.cpp:141] Setting up lstm1
I0720 16:26:44.960414 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.960418 27585 net.cpp:156] Memory required for data: 26408
I0720 16:26:44.960422 27595 net.cpp:141] Setting up relu3
I0720 16:26:44.960432 27585 layer_factory.hpp:77] Creating layer concat
I0720 16:26:44.960434 27595 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.960439 27595 net.cpp:156] Memory required for data: 58596920
I0720 16:26:44.960440 27585 net.cpp:91] Creating Layer concat
I0720 16:26:44.960444 27595 layer_factory.hpp:77] Creating layer conv4
I0720 16:26:44.960446 27585 net.cpp:425] concat <- lstm1
I0720 16:26:44.960453 27585 net.cpp:425] concat <- embedded_input_sentence
I0720 16:26:44.960458 27595 net.cpp:91] Creating Layer conv4
I0720 16:26:44.960458 27585 net.cpp:425] concat <- reshaped_stage_indicator
I0720 16:26:44.960465 27595 net.cpp:425] conv4 <- conv3
I0720 16:26:44.960472 27585 net.cpp:399] concat -> lstm1_video_sequence
I0720 16:26:44.960477 27595 net.cpp:399] conv4 -> conv4
I0720 16:26:44.960541 27585 net.cpp:141] Setting up concat
I0720 16:26:44.960552 27585 net.cpp:148] Top shape: 1 1 1501 (1501)
I0720 16:26:44.960556 27585 net.cpp:156] Memory required for data: 32412
I0720 16:26:44.960561 27585 layer_factory.hpp:77] Creating layer lstm2
I0720 16:26:44.960573 27585 net.cpp:91] Creating Layer lstm2
I0720 16:26:44.960578 27585 net.cpp:425] lstm2 <- lstm1_video_sequence
I0720 16:26:44.960584 27585 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0720 16:26:44.960590 27585 net.cpp:399] lstm2 -> lstm2
I0720 16:26:44.960602 27585 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0720 16:26:44.960863 27585 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0720 16:26:44.960954 27585 layer_factory.hpp:77] Creating layer lstm2_
I0720 16:26:44.960965 27585 net.cpp:91] Creating Layer lstm2_
I0720 16:26:44.960971 27585 net.cpp:399] lstm2_ -> x
I0720 16:26:44.960983 27585 net.cpp:399] lstm2_ -> cont
I0720 16:26:44.961076 27601 net.cpp:141] Setting up conv3
I0720 16:26:44.961094 27601 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.961099 27601 net.cpp:156] Memory required for data: 56001080
I0720 16:26:44.961112 27601 layer_factory.hpp:77] Creating layer relu3
I0720 16:26:44.961120 27601 net.cpp:91] Creating Layer relu3
I0720 16:26:44.961124 27601 net.cpp:425] relu3 <- conv3
I0720 16:26:44.961127 27585 net.cpp:141] Setting up lstm2_
I0720 16:26:44.961132 27601 net.cpp:386] relu3 -> conv3 (in-place)
I0720 16:26:44.961143 27585 net.cpp:148] Top shape: 1 1 1501 (1501)
I0720 16:26:44.961148 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.961153 27585 net.cpp:156] Memory required for data: 6008
I0720 16:26:44.961158 27585 layer_factory.hpp:77] Creating layer lstm2_
I0720 16:26:44.961166 27585 net.cpp:91] Creating Layer lstm2_
I0720 16:26:44.961174 27585 net.cpp:399] lstm2_ -> c_0
I0720 16:26:44.961185 27585 net.cpp:399] lstm2_ -> h_0
I0720 16:26:44.962204 27601 net.cpp:141] Setting up relu3
I0720 16:26:44.962218 27601 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.962222 27601 net.cpp:156] Memory required for data: 58596920
I0720 16:26:44.962227 27601 layer_factory.hpp:77] Creating layer conv4
I0720 16:26:44.962239 27601 net.cpp:91] Creating Layer conv4
I0720 16:26:44.962244 27601 net.cpp:425] conv4 <- conv3
I0720 16:26:44.962255 27601 net.cpp:399] conv4 -> conv4
I0720 16:26:44.963527 27585 net.cpp:141] Setting up lstm2_
I0720 16:26:44.963538 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.963544 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:44.963548 27585 net.cpp:156] Memory required for data: 14008
I0720 16:26:44.963552 27585 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0720 16:26:44.963562 27585 net.cpp:91] Creating Layer lstm2_cont_slice
I0720 16:26:44.963567 27585 net.cpp:425] lstm2_cont_slice <- cont
I0720 16:26:44.963575 27585 net.cpp:399] lstm2_cont_slice -> cont_1
I0720 16:26:44.963682 27585 net.cpp:141] Setting up lstm2_cont_slice
I0720 16:26:44.963693 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.963697 27585 net.cpp:156] Memory required for data: 14012
I0720 16:26:44.963701 27585 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0720 16:26:44.963708 27585 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0720 16:26:44.963713 27585 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0720 16:26:44.963721 27585 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0720 16:26:44.963731 27585 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0720 16:26:44.965600 27585 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0720 16:26:44.965611 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.965616 27585 net.cpp:148] Top shape: 1 1 (1)
I0720 16:26:44.965620 27585 net.cpp:156] Memory required for data: 14020
I0720 16:26:44.965626 27585 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0720 16:26:44.965638 27585 net.cpp:91] Creating Layer lstm2_x_transform
I0720 16:26:44.965643 27585 net.cpp:425] lstm2_x_transform <- x
I0720 16:26:44.965651 27585 net.cpp:399] lstm2_x_transform -> W_xc_x
I0720 16:26:44.982074 27595 net.cpp:141] Setting up conv4
I0720 16:26:44.982123 27595 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.982131 27595 net.cpp:156] Memory required for data: 61192760
I0720 16:26:44.982146 27595 layer_factory.hpp:77] Creating layer relu4
I0720 16:26:44.982161 27595 net.cpp:91] Creating Layer relu4
I0720 16:26:44.982168 27595 net.cpp:425] relu4 <- conv4
I0720 16:26:44.982179 27595 net.cpp:386] relu4 -> conv4 (in-place)
I0720 16:26:44.983060 27601 net.cpp:141] Setting up conv4
I0720 16:26:44.983080 27601 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.983081 27595 net.cpp:141] Setting up relu4
I0720 16:26:44.983085 27601 net.cpp:156] Memory required for data: 61192760
I0720 16:26:44.983098 27595 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.983103 27595 net.cpp:156] Memory required for data: 63788600
I0720 16:26:44.983103 27601 layer_factory.hpp:77] Creating layer relu4
I0720 16:26:44.983108 27595 layer_factory.hpp:77] Creating layer conv5
I0720 16:26:44.983114 27601 net.cpp:91] Creating Layer relu4
I0720 16:26:44.983119 27601 net.cpp:425] relu4 <- conv4
I0720 16:26:44.983127 27595 net.cpp:91] Creating Layer conv5
I0720 16:26:44.983129 27601 net.cpp:386] relu4 -> conv4 (in-place)
I0720 16:26:44.983134 27595 net.cpp:425] conv5 <- conv4
I0720 16:26:44.983141 27595 net.cpp:399] conv5 -> conv5
I0720 16:26:44.984052 27601 net.cpp:141] Setting up relu4
I0720 16:26:44.984069 27601 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 16:26:44.984078 27601 net.cpp:156] Memory required for data: 63788600
I0720 16:26:44.984087 27601 layer_factory.hpp:77] Creating layer conv5
I0720 16:26:44.984107 27601 net.cpp:91] Creating Layer conv5
I0720 16:26:44.984115 27601 net.cpp:425] conv5 <- conv4
I0720 16:26:44.984127 27601 net.cpp:399] conv5 -> conv5
I0720 16:26:44.992779 27595 net.cpp:141] Setting up conv5
I0720 16:26:44.992807 27595 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.992813 27595 net.cpp:156] Memory required for data: 65519160
I0720 16:26:44.992830 27595 layer_factory.hpp:77] Creating layer relu5
I0720 16:26:44.992844 27595 net.cpp:91] Creating Layer relu5
I0720 16:26:44.992851 27595 net.cpp:425] relu5 <- conv5
I0720 16:26:44.992856 27595 net.cpp:386] relu5 -> conv5 (in-place)
I0720 16:26:44.994094 27595 net.cpp:141] Setting up relu5
I0720 16:26:44.994113 27595 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.994118 27595 net.cpp:156] Memory required for data: 67249720
I0720 16:26:44.994123 27595 layer_factory.hpp:77] Creating layer pool5
I0720 16:26:44.994133 27595 net.cpp:91] Creating Layer pool5
I0720 16:26:44.994138 27595 net.cpp:425] pool5 <- conv5
I0720 16:26:44.994150 27595 net.cpp:399] pool5 -> pool5
I0720 16:26:44.994187 27601 net.cpp:141] Setting up conv5
I0720 16:26:44.994204 27601 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:44.994209 27601 net.cpp:156] Memory required for data: 65519160
I0720 16:26:44.994225 27601 layer_factory.hpp:77] Creating layer relu5
I0720 16:26:44.994235 27601 net.cpp:91] Creating Layer relu5
I0720 16:26:44.994240 27601 net.cpp:425] relu5 <- conv5
I0720 16:26:44.994247 27601 net.cpp:386] relu5 -> conv5 (in-place)
I0720 16:26:44.994258 27595 net.cpp:141] Setting up pool5
I0720 16:26:44.994269 27595 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0720 16:26:44.994273 27595 net.cpp:156] Memory required for data: 67618360
I0720 16:26:44.994278 27595 layer_factory.hpp:77] Creating layer fc6
I0720 16:26:44.994295 27595 net.cpp:91] Creating Layer fc6
I0720 16:26:44.994299 27595 net.cpp:425] fc6 <- pool5
I0720 16:26:44.994308 27595 net.cpp:399] fc6 -> fc6
I0720 16:26:45.052495 27601 net.cpp:141] Setting up relu5
I0720 16:26:45.052557 27601 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 16:26:45.052564 27601 net.cpp:156] Memory required for data: 67249720
I0720 16:26:45.052574 27601 layer_factory.hpp:77] Creating layer pool5
I0720 16:26:45.052597 27601 net.cpp:91] Creating Layer pool5
I0720 16:26:45.052603 27601 net.cpp:425] pool5 <- conv5
I0720 16:26:45.052619 27601 net.cpp:399] pool5 -> pool5
I0720 16:26:45.061030 27601 net.cpp:141] Setting up pool5
I0720 16:26:45.061079 27601 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0720 16:26:45.061089 27601 net.cpp:156] Memory required for data: 67618360
I0720 16:26:45.061100 27601 layer_factory.hpp:77] Creating layer fc6
I0720 16:26:45.061130 27601 net.cpp:91] Creating Layer fc6
I0720 16:26:45.061141 27601 net.cpp:425] fc6 <- pool5
I0720 16:26:45.061161 27601 net.cpp:399] fc6 -> fc6
I0720 16:26:45.061206 27585 net.cpp:141] Setting up lstm2_x_transform
I0720 16:26:45.061225 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:45.061230 27585 net.cpp:156] Memory required for data: 30020
I0720 16:26:45.061244 27585 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0720 16:26:45.061257 27585 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0720 16:26:45.061262 27585 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0720 16:26:45.061270 27585 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0720 16:26:45.127698 27585 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0720 16:26:45.127756 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:45.127763 27585 net.cpp:156] Memory required for data: 46020
I0720 16:26:45.127773 27585 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0720 16:26:45.127791 27585 net.cpp:91] Creating Layer lstm2_h_conted_0
I0720 16:26:45.127797 27585 net.cpp:425] lstm2_h_conted_0 <- h_0
I0720 16:26:45.127809 27585 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0720 16:26:45.127816 27585 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0720 16:26:45.131911 27595 net.cpp:141] Setting up fc6
I0720 16:26:45.131922 27585 net.cpp:141] Setting up lstm2_h_conted_0
I0720 16:26:45.131947 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.131953 27595 net.cpp:156] Memory required for data: 67782200
I0720 16:26:45.131954 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.131960 27585 net.cpp:156] Memory required for data: 50020
I0720 16:26:45.131966 27585 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0720 16:26:45.131968 27595 layer_factory.hpp:77] Creating layer relu6
I0720 16:26:45.131979 27595 net.cpp:91] Creating Layer relu6
I0720 16:26:45.131983 27585 net.cpp:91] Creating Layer lstm2_transform_1
I0720 16:26:45.131986 27595 net.cpp:425] relu6 <- fc6
I0720 16:26:45.131989 27585 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0720 16:26:45.131995 27595 net.cpp:386] relu6 -> fc6 (in-place)
I0720 16:26:45.132001 27585 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0720 16:26:45.143787 27595 net.cpp:141] Setting up relu6
I0720 16:26:45.143847 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.143854 27595 net.cpp:156] Memory required for data: 67946040
I0720 16:26:45.143864 27595 layer_factory.hpp:77] Creating layer drop6
I0720 16:26:45.143884 27595 net.cpp:91] Creating Layer drop6
I0720 16:26:45.143893 27595 net.cpp:425] drop6 <- fc6
I0720 16:26:45.143908 27595 net.cpp:386] drop6 -> fc6 (in-place)
I0720 16:26:45.144064 27595 net.cpp:141] Setting up drop6
I0720 16:26:45.144074 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.144078 27595 net.cpp:156] Memory required for data: 68109880
I0720 16:26:45.144083 27595 layer_factory.hpp:77] Creating layer fc7
I0720 16:26:45.144095 27595 net.cpp:91] Creating Layer fc7
I0720 16:26:45.144103 27595 net.cpp:425] fc7 <- fc6
I0720 16:26:45.144109 27595 net.cpp:399] fc7 -> fc7
I0720 16:26:45.177431 27585 net.cpp:141] Setting up lstm2_transform_1
I0720 16:26:45.177481 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:45.177487 27585 net.cpp:156] Memory required for data: 66020
I0720 16:26:45.177508 27585 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0720 16:26:45.177531 27585 net.cpp:91] Creating Layer lstm2_gate_input_1
I0720 16:26:45.177538 27585 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0720 16:26:45.177547 27585 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0720 16:26:45.177556 27585 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0720 16:26:45.177675 27585 net.cpp:141] Setting up lstm2_gate_input_1
I0720 16:26:45.177685 27585 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 16:26:45.177690 27585 net.cpp:156] Memory required for data: 82020
I0720 16:26:45.177695 27585 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0720 16:26:45.177707 27585 net.cpp:91] Creating Layer lstm2_unit_1
I0720 16:26:45.177711 27585 net.cpp:425] lstm2_unit_1 <- c_0
I0720 16:26:45.177717 27585 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0720 16:26:45.177722 27585 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0720 16:26:45.177729 27585 net.cpp:399] lstm2_unit_1 -> c_1
I0720 16:26:45.177741 27585 net.cpp:399] lstm2_unit_1 -> h_1
I0720 16:26:45.177757 27601 net.cpp:141] Setting up fc6
I0720 16:26:45.177778 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.177785 27601 net.cpp:156] Memory required for data: 67782200
I0720 16:26:45.177803 27601 layer_factory.hpp:77] Creating layer relu6
I0720 16:26:45.177819 27601 net.cpp:91] Creating Layer relu6
I0720 16:26:45.177827 27601 net.cpp:425] relu6 <- fc6
I0720 16:26:45.177837 27601 net.cpp:386] relu6 -> fc6 (in-place)
I0720 16:26:45.177850 27585 net.cpp:141] Setting up lstm2_unit_1
I0720 16:26:45.177860 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.177865 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.177870 27585 net.cpp:156] Memory required for data: 90020
I0720 16:26:45.177875 27585 layer_factory.hpp:77] Creating layer lstm2_
I0720 16:26:45.177882 27585 net.cpp:91] Creating Layer lstm2_
I0720 16:26:45.177886 27585 net.cpp:425] lstm2_ <- c_1
I0720 16:26:45.177896 27585 net.cpp:399] lstm2_ -> c_T
I0720 16:26:45.177948 27585 net.cpp:141] Setting up lstm2_
I0720 16:26:45.177958 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.177963 27585 net.cpp:156] Memory required for data: 94020
I0720 16:26:45.177966 27585 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0720 16:26:45.177979 27585 net.cpp:91] Creating Layer lstm2_h_concat
I0720 16:26:45.177984 27585 net.cpp:425] lstm2_h_concat <- h_1
I0720 16:26:45.177991 27585 net.cpp:399] lstm2_h_concat -> h
I0720 16:26:45.178206 27585 net.cpp:141] Setting up lstm2_h_concat
I0720 16:26:45.178217 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.178221 27585 net.cpp:156] Memory required for data: 98020
I0720 16:26:45.178225 27585 layer_factory.hpp:77] Creating layer h_pseudoloss
I0720 16:26:45.178238 27585 net.cpp:91] Creating Layer h_pseudoloss
I0720 16:26:45.178243 27585 net.cpp:425] h_pseudoloss <- h
I0720 16:26:45.178249 27585 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0720 16:26:45.178460 27585 net.cpp:141] Setting up h_pseudoloss
I0720 16:26:45.178472 27585 net.cpp:148] Top shape: (1)
I0720 16:26:45.178477 27585 net.cpp:151]     with loss weight 1
I0720 16:26:45.178495 27585 net.cpp:156] Memory required for data: 98024
I0720 16:26:45.178500 27585 net.cpp:217] h_pseudoloss needs backward computation.
I0720 16:26:45.178505 27585 net.cpp:217] lstm2_h_concat needs backward computation.
I0720 16:26:45.178509 27585 net.cpp:219] lstm2_ does not need backward computation.
I0720 16:26:45.178514 27585 net.cpp:217] lstm2_unit_1 needs backward computation.
I0720 16:26:45.178519 27585 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0720 16:26:45.178522 27585 net.cpp:217] lstm2_transform_1 needs backward computation.
I0720 16:26:45.178522 27601 net.cpp:141] Setting up relu6
I0720 16:26:45.178529 27585 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0720 16:26:45.178546 27585 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0720 16:26:45.178546 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.178551 27585 net.cpp:217] lstm2_x_transform needs backward computation.
I0720 16:26:45.178557 27585 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0720 16:26:45.178557 27601 net.cpp:156] Memory required for data: 67946040
I0720 16:26:45.178562 27585 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0720 16:26:45.178568 27585 net.cpp:219] lstm2_ does not need backward computation.
I0720 16:26:45.178566 27601 layer_factory.hpp:77] Creating layer drop6
I0720 16:26:45.178577 27585 net.cpp:219] lstm2_ does not need backward computation.
I0720 16:26:45.178588 27585 net.cpp:261] This network produces output c_T
I0720 16:26:45.178593 27585 net.cpp:261] This network produces output h_pseudoloss
I0720 16:26:45.178599 27601 net.cpp:91] Creating Layer drop6
I0720 16:26:45.178611 27585 net.cpp:274] Network initialization done.
I0720 16:26:45.178611 27601 net.cpp:425] drop6 <- fc6
I0720 16:26:45.178624 27601 net.cpp:386] drop6 -> fc6 (in-place)
I0720 16:26:45.178663 27585 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0720 16:26:45.178668 27585 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0720 16:26:45.178673 27585 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0720 16:26:45.178769 27601 net.cpp:141] Setting up drop6
I0720 16:26:45.178788 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.178798 27601 net.cpp:156] Memory required for data: 68109880
I0720 16:26:45.178807 27601 layer_factory.hpp:77] Creating layer fc7
I0720 16:26:45.178833 27601 net.cpp:91] Creating Layer fc7
I0720 16:26:45.178845 27601 net.cpp:425] fc7 <- fc6
I0720 16:26:45.178863 27601 net.cpp:399] fc7 -> fc7
I0720 16:26:45.178903 27585 net.cpp:141] Setting up lstm2
I0720 16:26:45.178916 27585 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 16:26:45.178920 27585 net.cpp:156] Memory required for data: 36412
I0720 16:26:45.178935 27585 layer_factory.hpp:77] Creating layer predict
I0720 16:26:45.178946 27585 net.cpp:91] Creating Layer predict
I0720 16:26:45.178951 27585 net.cpp:425] predict <- lstm2
I0720 16:26:45.178959 27585 net.cpp:399] predict -> predict
I0720 16:26:45.296121 27595 net.cpp:141] Setting up fc7
I0720 16:26:45.296185 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.296190 27595 net.cpp:156] Memory required for data: 68273720
I0720 16:26:45.296207 27595 layer_factory.hpp:77] Creating layer relu7
I0720 16:26:45.296226 27595 net.cpp:91] Creating Layer relu7
I0720 16:26:45.296234 27595 net.cpp:425] relu7 <- fc7
I0720 16:26:45.296244 27595 net.cpp:386] relu7 -> fc7 (in-place)
I0720 16:26:45.299046 27595 net.cpp:141] Setting up relu7
I0720 16:26:45.299101 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.299108 27595 net.cpp:156] Memory required for data: 68437560
I0720 16:26:45.299116 27595 layer_factory.hpp:77] Creating layer drop7
I0720 16:26:45.299139 27595 net.cpp:91] Creating Layer drop7
I0720 16:26:45.299146 27595 net.cpp:425] drop7 <- fc7
I0720 16:26:45.299157 27595 net.cpp:386] drop7 -> fc7 (in-place)
I0720 16:26:45.299281 27595 net.cpp:141] Setting up drop7
I0720 16:26:45.299291 27595 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.299298 27595 net.cpp:156] Memory required for data: 68601400
I0720 16:26:45.299302 27595 layer_factory.hpp:77] Creating layer fc8
I0720 16:26:45.299314 27595 net.cpp:91] Creating Layer fc8
I0720 16:26:45.299319 27595 net.cpp:425] fc8 <- fc7
I0720 16:26:45.299326 27595 net.cpp:399] fc8 -> fc8
I0720 16:26:45.311878 27601 net.cpp:141] Setting up fc7
I0720 16:26:45.311944 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.311952 27601 net.cpp:156] Memory required for data: 68273720
I0720 16:26:45.311977 27601 layer_factory.hpp:77] Creating layer relu7
I0720 16:26:45.312002 27601 net.cpp:91] Creating Layer relu7
I0720 16:26:45.312012 27601 net.cpp:425] relu7 <- fc7
I0720 16:26:45.312036 27601 net.cpp:386] relu7 -> fc7 (in-place)
I0720 16:26:45.315059 27601 net.cpp:141] Setting up relu7
I0720 16:26:45.315119 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.315129 27601 net.cpp:156] Memory required for data: 68437560
I0720 16:26:45.315143 27601 layer_factory.hpp:77] Creating layer drop7
I0720 16:26:45.315168 27601 net.cpp:91] Creating Layer drop7
I0720 16:26:45.315181 27601 net.cpp:425] drop7 <- fc7
I0720 16:26:45.315206 27601 net.cpp:386] drop7 -> fc7 (in-place)
I0720 16:26:45.315358 27601 net.cpp:141] Setting up drop7
I0720 16:26:45.315373 27601 net.cpp:148] Top shape: 10 4096 (40960)
I0720 16:26:45.315381 27601 net.cpp:156] Memory required for data: 68601400
I0720 16:26:45.315388 27601 layer_factory.hpp:77] Creating layer fc8
I0720 16:26:45.315412 27601 net.cpp:91] Creating Layer fc8
I0720 16:26:45.315419 27601 net.cpp:425] fc8 <- fc7
I0720 16:26:45.315431 27601 net.cpp:399] fc8 -> fc8
I0720 16:26:45.325639 27595 net.cpp:141] Setting up fc8
I0720 16:26:45.325697 27595 net.cpp:148] Top shape: 10 1000 (10000)
I0720 16:26:45.325703 27595 net.cpp:156] Memory required for data: 68641400
I0720 16:26:45.325721 27595 layer_factory.hpp:77] Creating layer prob
I0720 16:26:45.325739 27595 net.cpp:91] Creating Layer prob
I0720 16:26:45.325747 27595 net.cpp:425] prob <- fc8
I0720 16:26:45.325762 27595 net.cpp:399] prob -> prob
I0720 16:26:45.326277 27595 net.cpp:141] Setting up prob
I0720 16:26:45.326292 27595 net.cpp:148] Top shape: 10 1000 (10000)
I0720 16:26:45.326297 27595 net.cpp:156] Memory required for data: 68681400
I0720 16:26:45.326302 27595 net.cpp:219] prob does not need backward computation.
I0720 16:26:45.326306 27595 net.cpp:219] fc8 does not need backward computation.
I0720 16:26:45.326311 27595 net.cpp:219] drop7 does not need backward computation.
I0720 16:26:45.326315 27595 net.cpp:219] relu7 does not need backward computation.
I0720 16:26:45.326319 27595 net.cpp:219] fc7 does not need backward computation.
I0720 16:26:45.326323 27595 net.cpp:219] drop6 does not need backward computation.
I0720 16:26:45.326328 27595 net.cpp:219] relu6 does not need backward computation.
I0720 16:26:45.326331 27595 net.cpp:219] fc6 does not need backward computation.
I0720 16:26:45.326336 27595 net.cpp:219] pool5 does not need backward computation.
I0720 16:26:45.326340 27595 net.cpp:219] relu5 does not need backward computation.
I0720 16:26:45.326344 27595 net.cpp:219] conv5 does not need backward computation.
I0720 16:26:45.326349 27595 net.cpp:219] relu4 does not need backward computation.
I0720 16:26:45.326352 27595 net.cpp:219] conv4 does not need backward computation.
I0720 16:26:45.326356 27595 net.cpp:219] relu3 does not need backward computation.
I0720 16:26:45.326360 27595 net.cpp:219] conv3 does not need backward computation.
I0720 16:26:45.326365 27595 net.cpp:219] norm2 does not need backward computation.
I0720 16:26:45.326370 27595 net.cpp:219] pool2 does not need backward computation.
I0720 16:26:45.326373 27595 net.cpp:219] relu2 does not need backward computation.
I0720 16:26:45.326377 27595 net.cpp:219] conv2 does not need backward computation.
I0720 16:26:45.326382 27595 net.cpp:219] norm1 does not need backward computation.
I0720 16:26:45.326386 27595 net.cpp:219] pool1 does not need backward computation.
I0720 16:26:45.326391 27595 net.cpp:219] relu1 does not need backward computation.
I0720 16:26:45.326395 27595 net.cpp:219] conv1 does not need backward computation.
I0720 16:26:45.326400 27595 net.cpp:219] data does not need backward computation.
I0720 16:26:45.326403 27595 net.cpp:261] This network produces output prob
I0720 16:26:45.326421 27595 net.cpp:274] Network initialization done.
I0720 16:26:45.330540 27601 net.cpp:141] Setting up fc8
I0720 16:26:45.330601 27601 net.cpp:148] Top shape: 10 1000 (10000)
I0720 16:26:45.330615 27601 net.cpp:156] Memory required for data: 68641400
I0720 16:26:45.330641 27601 layer_factory.hpp:77] Creating layer prob
I0720 16:26:45.330667 27601 net.cpp:91] Creating Layer prob
I0720 16:26:45.330682 27601 net.cpp:425] prob <- fc8
I0720 16:26:45.330720 27601 net.cpp:399] prob -> prob
I0720 16:26:45.331596 27601 net.cpp:141] Setting up prob
I0720 16:26:45.331620 27601 net.cpp:148] Top shape: 10 1000 (10000)
I0720 16:26:45.331631 27601 net.cpp:156] Memory required for data: 68681400
I0720 16:26:45.331641 27601 net.cpp:219] prob does not need backward computation.
I0720 16:26:45.331651 27601 net.cpp:219] fc8 does not need backward computation.
I0720 16:26:45.331660 27601 net.cpp:219] drop7 does not need backward computation.
I0720 16:26:45.331668 27601 net.cpp:219] relu7 does not need backward computation.
I0720 16:26:45.331676 27601 net.cpp:219] fc7 does not need backward computation.
I0720 16:26:45.331686 27601 net.cpp:219] drop6 does not need backward computation.
I0720 16:26:45.331693 27601 net.cpp:219] relu6 does not need backward computation.
I0720 16:26:45.331701 27601 net.cpp:219] fc6 does not need backward computation.
I0720 16:26:45.331710 27601 net.cpp:219] pool5 does not need backward computation.
I0720 16:26:45.331719 27601 net.cpp:219] relu5 does not need backward computation.
I0720 16:26:45.331727 27601 net.cpp:219] conv5 does not need backward computation.
I0720 16:26:45.331737 27601 net.cpp:219] relu4 does not need backward computation.
I0720 16:26:45.331744 27601 net.cpp:219] conv4 does not need backward computation.
I0720 16:26:45.331755 27601 net.cpp:219] relu3 does not need backward computation.
I0720 16:26:45.331764 27601 net.cpp:219] conv3 does not need backward computation.
I0720 16:26:45.331773 27601 net.cpp:219] norm2 does not need backward computation.
I0720 16:26:45.331784 27601 net.cpp:219] pool2 does not need backward computation.
I0720 16:26:45.331791 27601 net.cpp:219] relu2 does not need backward computation.
I0720 16:26:45.331800 27601 net.cpp:219] conv2 does not need backward computation.
I0720 16:26:45.331809 27601 net.cpp:219] norm1 does not need backward computation.
I0720 16:26:45.331820 27601 net.cpp:219] pool1 does not need backward computation.
I0720 16:26:45.331830 27601 net.cpp:219] relu1 does not need backward computation.
I0720 16:26:45.331837 27601 net.cpp:219] conv1 does not need backward computation.
I0720 16:26:45.331846 27601 net.cpp:219] data does not need backward computation.
I0720 16:26:45.331856 27601 net.cpp:261] This network produces output prob
I0720 16:26:45.331900 27601 net.cpp:274] Network initialization done.
I0720 16:26:45.559648 27595 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld886598422143268237/bvlc_reference_caffenet.caffemodel
I0720 16:26:45.559700 27595 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0720 16:26:45.559706 27595 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0720 16:26:45.559711 27595 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld886598422143268237/bvlc_reference_caffenet.caffemodel
I0720 16:26:45.578516 27601 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld886598422143268237/bvlc_reference_caffenet.caffemodel
I0720 16:26:45.578582 27601 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0720 16:26:45.578588 27601 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0720 16:26:45.578593 27601 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld886598422143268237/bvlc_reference_caffenet.caffemodel
I0720 16:26:45.644785 27585 net.cpp:141] Setting up predict
I0720 16:26:45.644870 27585 net.cpp:148] Top shape: 1 1 46168 (46168)
I0720 16:26:45.644877 27585 net.cpp:156] Memory required for data: 221084
I0720 16:26:45.644893 27585 layer_factory.hpp:77] Creating layer probs
I0720 16:26:45.644912 27585 net.cpp:91] Creating Layer probs
I0720 16:26:45.644919 27585 net.cpp:425] probs <- predict
I0720 16:26:45.644932 27585 net.cpp:399] probs -> probs
I0720 16:26:45.647295 27585 net.cpp:141] Setting up probs
I0720 16:26:45.647332 27585 net.cpp:148] Top shape: 1 1 46168 (46168)
I0720 16:26:45.647338 27585 net.cpp:156] Memory required for data: 405756
I0720 16:26:45.647344 27585 net.cpp:219] probs does not need backward computation.
I0720 16:26:45.647351 27585 net.cpp:219] predict does not need backward computation.
I0720 16:26:45.647354 27585 net.cpp:219] lstm2 does not need backward computation.
I0720 16:26:45.647361 27585 net.cpp:219] concat does not need backward computation.
I0720 16:26:45.647366 27585 net.cpp:219] lstm1 does not need backward computation.
I0720 16:26:45.647372 27585 net.cpp:219] embedding does not need backward computation.
I0720 16:26:45.647377 27585 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0720 16:26:45.647382 27585 net.cpp:219] reshape_frames does not need backward computation.
I0720 16:26:45.647385 27585 net.cpp:219] embed_encoder does not need backward computation.
I0720 16:26:45.647390 27585 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0720 16:26:45.647395 27585 net.cpp:219] input does not need backward computation.
I0720 16:26:45.647399 27585 net.cpp:261] This network produces output probs
I0720 16:26:45.647416 27585 net.cpp:274] Network initialization done.
I0720 16:26:45.949894 27601 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0720 16:26:45.971750 27585 net.cpp:752] Ignoring source layer data
I0720 16:26:45.971793 27585 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0720 16:26:45.971798 27585 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0720 16:26:45.977329 27595 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0720 16:26:46.001814 27601 net.cpp:752] Ignoring source layer loss
I0720 16:26:46.039698 27595 net.cpp:752] Ignoring source layer loss
I0720 16:26:46.045481 27585 net.cpp:752] Ignoring source layer cross_entropy_loss
