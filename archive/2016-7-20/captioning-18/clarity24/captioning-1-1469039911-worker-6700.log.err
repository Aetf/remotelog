SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1469039911/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-07-20 14:38:51,227 ERROR Logger contains an invalid element or attribute "appender"
2016-07-20 14:38:54,206 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld4132497111785329636/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0720 14:39:00.275584 27812 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0720 14:39:00.275809 27812 layer_factory.hpp:77] Creating layer data
I0720 14:39:00.275837 27812 net.cpp:91] Creating Layer data
I0720 14:39:00.275848 27812 net.cpp:399] data -> data
I0720 14:39:00.800926 27812 net.cpp:141] Setting up data
I0720 14:39:00.801007 27812 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0720 14:39:00.801013 27812 net.cpp:156] Memory required for data: 6183480
I0720 14:39:00.801030 27812 layer_factory.hpp:77] Creating layer conv1
I0720 14:39:00.801059 27812 net.cpp:91] Creating Layer conv1
I0720 14:39:00.801069 27812 net.cpp:425] conv1 <- data
I0720 14:39:00.801080 27812 net.cpp:399] conv1 -> conv1
I0720 14:39:00.820963 27802 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld4132497111785329636/s2vt.words_to_preds.prototxt
I0720 14:39:00.821012 27802 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0720 14:39:00.821019 27802 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0720 14:39:00.821254 27802 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0720 14:39:00.821349 27802 layer_factory.hpp:77] Creating layer input
I0720 14:39:00.821364 27802 net.cpp:91] Creating Layer input
I0720 14:39:00.821372 27802 net.cpp:399] input -> frames_fc7
I0720 14:39:00.821388 27802 net.cpp:399] input -> cont_sentence
I0720 14:39:00.821398 27802 net.cpp:399] input -> input_sentence
I0720 14:39:00.821408 27802 net.cpp:399] input -> stage_indicator
I0720 14:39:00.824035 27802 net.cpp:141] Setting up input
I0720 14:39:00.824057 27802 net.cpp:148] Top shape: 1 4096 (4096)
I0720 14:39:00.824064 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:00.824069 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:00.824075 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:00.824079 27802 net.cpp:156] Memory required for data: 16396
I0720 14:39:00.824084 27802 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0720 14:39:00.824105 27802 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0720 14:39:00.824110 27802 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0720 14:39:00.824133 27802 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0720 14:39:00.824144 27802 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0720 14:39:00.836501 27802 net.cpp:141] Setting up cont_sentence_input_1_split
I0720 14:39:00.836534 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:00.836540 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:00.836545 27802 net.cpp:156] Memory required for data: 16404
I0720 14:39:00.836552 27802 layer_factory.hpp:77] Creating layer embed_encoder
I0720 14:39:00.836578 27802 net.cpp:91] Creating Layer embed_encoder
I0720 14:39:00.836585 27802 net.cpp:425] embed_encoder <- frames_fc7
I0720 14:39:00.836596 27802 net.cpp:399] embed_encoder -> embedded_in_frames
I0720 14:39:00.863636 27802 net.cpp:141] Setting up embed_encoder
I0720 14:39:00.863677 27802 net.cpp:148] Top shape: 1 500 (500)
I0720 14:39:00.863683 27802 net.cpp:156] Memory required for data: 18404
I0720 14:39:00.863708 27802 layer_factory.hpp:77] Creating layer reshape_frames
I0720 14:39:00.863732 27802 net.cpp:91] Creating Layer reshape_frames
I0720 14:39:00.863740 27802 net.cpp:425] reshape_frames <- embedded_in_frames
I0720 14:39:00.863751 27802 net.cpp:399] reshape_frames -> embedded_input_frames
I0720 14:39:00.863801 27802 net.cpp:141] Setting up reshape_frames
I0720 14:39:00.863809 27802 net.cpp:148] Top shape: 1 1 500 (500)
I0720 14:39:00.863814 27802 net.cpp:156] Memory required for data: 20404
I0720 14:39:00.863818 27802 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0720 14:39:00.863828 27802 net.cpp:91] Creating Layer reshape_stage_indicator
I0720 14:39:00.863832 27802 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0720 14:39:00.863845 27802 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0720 14:39:00.863921 27802 net.cpp:141] Setting up reshape_stage_indicator
I0720 14:39:00.863932 27802 net.cpp:148] Top shape: 1 1 1 (1)
I0720 14:39:00.863936 27802 net.cpp:156] Memory required for data: 20408
I0720 14:39:00.863941 27802 layer_factory.hpp:77] Creating layer embedding
I0720 14:39:00.863952 27802 net.cpp:91] Creating Layer embedding
I0720 14:39:00.863957 27802 net.cpp:425] embedding <- input_sentence
I0720 14:39:00.863965 27802 net.cpp:399] embedding -> embedded_input_sentence
I0720 14:39:01.083326 27802 net.cpp:141] Setting up embedding
I0720 14:39:01.083370 27802 net.cpp:148] Top shape: 1 1 500 (500)
I0720 14:39:01.083376 27802 net.cpp:156] Memory required for data: 22408
I0720 14:39:01.083394 27802 layer_factory.hpp:77] Creating layer lstm1
I0720 14:39:01.083410 27802 net.cpp:91] Creating Layer lstm1
I0720 14:39:01.083417 27802 net.cpp:425] lstm1 <- embedded_input_frames
I0720 14:39:01.083425 27802 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0720 14:39:01.083436 27802 net.cpp:399] lstm1 -> lstm1
I0720 14:39:01.083470 27802 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0720 14:39:01.083799 27802 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0720 14:39:01.083889 27802 layer_factory.hpp:77] Creating layer lstm1_
I0720 14:39:01.083899 27802 net.cpp:91] Creating Layer lstm1_
I0720 14:39:01.083905 27802 net.cpp:399] lstm1_ -> x
I0720 14:39:01.083916 27802 net.cpp:399] lstm1_ -> cont
I0720 14:39:01.085847 27802 net.cpp:141] Setting up lstm1_
I0720 14:39:01.085865 27802 net.cpp:148] Top shape: 1 1 500 (500)
I0720 14:39:01.085871 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.085875 27802 net.cpp:156] Memory required for data: 2004
I0720 14:39:01.085880 27802 layer_factory.hpp:77] Creating layer lstm1_
I0720 14:39:01.085891 27802 net.cpp:91] Creating Layer lstm1_
I0720 14:39:01.085901 27802 net.cpp:399] lstm1_ -> c_0
I0720 14:39:01.085913 27802 net.cpp:399] lstm1_ -> h_0
I0720 14:39:01.087738 27802 net.cpp:141] Setting up lstm1_
I0720 14:39:01.087756 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.087764 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.087766 27802 net.cpp:156] Memory required for data: 10004
I0720 14:39:01.087771 27802 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0720 14:39:01.087785 27802 net.cpp:91] Creating Layer lstm1_cont_slice
I0720 14:39:01.087790 27802 net.cpp:425] lstm1_cont_slice <- cont
I0720 14:39:01.087797 27802 net.cpp:399] lstm1_cont_slice -> cont_1
I0720 14:39:01.088002 27802 net.cpp:141] Setting up lstm1_cont_slice
I0720 14:39:01.088012 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.088017 27802 net.cpp:156] Memory required for data: 10008
I0720 14:39:01.088021 27802 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0720 14:39:01.088029 27802 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0720 14:39:01.088033 27802 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0720 14:39:01.088043 27802 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0720 14:39:01.088052 27802 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0720 14:39:01.088155 27802 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0720 14:39:01.088165 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.088170 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.088173 27802 net.cpp:156] Memory required for data: 10016
I0720 14:39:01.088178 27802 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0720 14:39:01.088188 27802 net.cpp:91] Creating Layer lstm1_x_transform
I0720 14:39:01.088192 27802 net.cpp:425] lstm1_x_transform <- x
I0720 14:39:01.088201 27802 net.cpp:399] lstm1_x_transform -> W_xc_x
I0720 14:39:01.096525 27812 net.cpp:141] Setting up conv1
I0720 14:39:01.096575 27812 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 14:39:01.096582 27812 net.cpp:156] Memory required for data: 17799480
I0720 14:39:01.096607 27812 layer_factory.hpp:77] Creating layer relu1
I0720 14:39:01.096627 27812 net.cpp:91] Creating Layer relu1
I0720 14:39:01.096635 27812 net.cpp:425] relu1 <- conv1
I0720 14:39:01.096643 27812 net.cpp:386] relu1 -> conv1 (in-place)
I0720 14:39:01.097955 27812 net.cpp:141] Setting up relu1
I0720 14:39:01.097975 27812 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0720 14:39:01.097981 27812 net.cpp:156] Memory required for data: 29415480
I0720 14:39:01.097988 27812 layer_factory.hpp:77] Creating layer pool1
I0720 14:39:01.098003 27812 net.cpp:91] Creating Layer pool1
I0720 14:39:01.098009 27812 net.cpp:425] pool1 <- conv1
I0720 14:39:01.098017 27812 net.cpp:399] pool1 -> pool1
I0720 14:39:01.098096 27812 net.cpp:141] Setting up pool1
I0720 14:39:01.098107 27812 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 14:39:01.098114 27812 net.cpp:156] Memory required for data: 32214840
I0720 14:39:01.098119 27812 layer_factory.hpp:77] Creating layer norm1
I0720 14:39:01.098137 27812 net.cpp:91] Creating Layer norm1
I0720 14:39:01.098143 27812 net.cpp:425] norm1 <- pool1
I0720 14:39:01.098150 27812 net.cpp:399] norm1 -> norm1
I0720 14:39:01.099534 27812 net.cpp:141] Setting up norm1
I0720 14:39:01.099560 27812 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0720 14:39:01.099572 27812 net.cpp:156] Memory required for data: 35014200
I0720 14:39:01.099583 27812 layer_factory.hpp:77] Creating layer conv2
I0720 14:39:01.099609 27812 net.cpp:91] Creating Layer conv2
I0720 14:39:01.099622 27812 net.cpp:425] conv2 <- norm1
I0720 14:39:01.099635 27812 net.cpp:399] conv2 -> conv2
I0720 14:39:01.107599 27812 net.cpp:141] Setting up conv2
I0720 14:39:01.107636 27812 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 14:39:01.107648 27812 net.cpp:156] Memory required for data: 42479160
I0720 14:39:01.107678 27812 layer_factory.hpp:77] Creating layer relu2
I0720 14:39:01.107697 27812 net.cpp:91] Creating Layer relu2
I0720 14:39:01.107707 27812 net.cpp:425] relu2 <- conv2
I0720 14:39:01.107720 27812 net.cpp:386] relu2 -> conv2 (in-place)
I0720 14:39:01.109417 27802 net.cpp:141] Setting up lstm1_x_transform
I0720 14:39:01.109453 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.109458 27802 net.cpp:156] Memory required for data: 26016
I0720 14:39:01.109477 27802 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0720 14:39:01.109489 27802 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0720 14:39:01.109495 27802 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0720 14:39:01.109504 27802 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0720 14:39:01.109589 27802 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0720 14:39:01.109601 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.109604 27802 net.cpp:156] Memory required for data: 42016
I0720 14:39:01.109609 27802 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0720 14:39:01.109614 27812 net.cpp:141] Setting up relu2
I0720 14:39:01.109622 27802 net.cpp:91] Creating Layer lstm1_h_conted_0
I0720 14:39:01.109639 27802 net.cpp:425] lstm1_h_conted_0 <- h_0
I0720 14:39:01.109644 27812 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0720 14:39:01.109647 27802 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0720 14:39:01.109658 27812 net.cpp:156] Memory required for data: 49944120
I0720 14:39:01.109665 27802 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0720 14:39:01.109668 27812 layer_factory.hpp:77] Creating layer pool2
I0720 14:39:01.109683 27812 net.cpp:91] Creating Layer pool2
I0720 14:39:01.109693 27812 net.cpp:425] pool2 <- conv2
I0720 14:39:01.109704 27812 net.cpp:399] pool2 -> pool2
I0720 14:39:01.109845 27802 net.cpp:141] Setting up lstm1_h_conted_0
I0720 14:39:01.109855 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.109860 27802 net.cpp:156] Memory required for data: 46016
I0720 14:39:01.109864 27802 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0720 14:39:01.109875 27802 net.cpp:91] Creating Layer lstm1_transform_1
I0720 14:39:01.109880 27802 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0720 14:39:01.109889 27802 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0720 14:39:01.109905 27812 net.cpp:141] Setting up pool2
I0720 14:39:01.109923 27812 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 14:39:01.109932 27812 net.cpp:156] Memory required for data: 51674680
I0720 14:39:01.109941 27812 layer_factory.hpp:77] Creating layer norm2
I0720 14:39:01.109966 27812 net.cpp:91] Creating Layer norm2
I0720 14:39:01.109975 27812 net.cpp:425] norm2 <- pool2
I0720 14:39:01.110005 27812 net.cpp:399] norm2 -> norm2
I0720 14:39:01.118424 27812 net.cpp:141] Setting up norm2
I0720 14:39:01.118449 27812 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 14:39:01.118455 27812 net.cpp:156] Memory required for data: 53405240
I0720 14:39:01.118463 27812 layer_factory.hpp:77] Creating layer conv3
I0720 14:39:01.118479 27812 net.cpp:91] Creating Layer conv3
I0720 14:39:01.118486 27812 net.cpp:425] conv3 <- norm2
I0720 14:39:01.118496 27812 net.cpp:399] conv3 -> conv3
I0720 14:39:01.124068 27812 net.cpp:141] Setting up conv3
I0720 14:39:01.124095 27812 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 14:39:01.124102 27812 net.cpp:156] Memory required for data: 56001080
I0720 14:39:01.124117 27812 layer_factory.hpp:77] Creating layer relu3
I0720 14:39:01.124132 27812 net.cpp:91] Creating Layer relu3
I0720 14:39:01.124138 27812 net.cpp:425] relu3 <- conv3
I0720 14:39:01.124146 27812 net.cpp:386] relu3 -> conv3 (in-place)
I0720 14:39:01.125213 27812 net.cpp:141] Setting up relu3
I0720 14:39:01.125231 27812 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 14:39:01.125236 27812 net.cpp:156] Memory required for data: 58596920
I0720 14:39:01.125242 27812 layer_factory.hpp:77] Creating layer conv4
I0720 14:39:01.125257 27812 net.cpp:91] Creating Layer conv4
I0720 14:39:01.125264 27812 net.cpp:425] conv4 <- conv3
I0720 14:39:01.125277 27812 net.cpp:399] conv4 -> conv4
I0720 14:39:01.132241 27812 net.cpp:141] Setting up conv4
I0720 14:39:01.132272 27812 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 14:39:01.132278 27812 net.cpp:156] Memory required for data: 61192760
I0720 14:39:01.132290 27812 layer_factory.hpp:77] Creating layer relu4
I0720 14:39:01.132307 27812 net.cpp:91] Creating Layer relu4
I0720 14:39:01.132313 27812 net.cpp:425] relu4 <- conv4
I0720 14:39:01.132321 27812 net.cpp:386] relu4 -> conv4 (in-place)
I0720 14:39:01.133324 27812 net.cpp:141] Setting up relu4
I0720 14:39:01.133342 27812 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0720 14:39:01.133348 27812 net.cpp:156] Memory required for data: 63788600
I0720 14:39:01.133353 27812 layer_factory.hpp:77] Creating layer conv5
I0720 14:39:01.133373 27812 net.cpp:91] Creating Layer conv5
I0720 14:39:01.133379 27812 net.cpp:425] conv5 <- conv4
I0720 14:39:01.133388 27812 net.cpp:399] conv5 -> conv5
I0720 14:39:01.140159 27812 net.cpp:141] Setting up conv5
I0720 14:39:01.140185 27812 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 14:39:01.140192 27812 net.cpp:156] Memory required for data: 65519160
I0720 14:39:01.140208 27812 layer_factory.hpp:77] Creating layer relu5
I0720 14:39:01.140223 27812 net.cpp:91] Creating Layer relu5
I0720 14:39:01.140229 27812 net.cpp:425] relu5 <- conv5
I0720 14:39:01.140236 27812 net.cpp:386] relu5 -> conv5 (in-place)
I0720 14:39:01.141080 27812 net.cpp:141] Setting up relu5
I0720 14:39:01.141099 27812 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0720 14:39:01.141105 27812 net.cpp:156] Memory required for data: 67249720
I0720 14:39:01.141111 27812 layer_factory.hpp:77] Creating layer pool5
I0720 14:39:01.141126 27812 net.cpp:91] Creating Layer pool5
I0720 14:39:01.141132 27812 net.cpp:425] pool5 <- conv5
I0720 14:39:01.141144 27812 net.cpp:399] pool5 -> pool5
I0720 14:39:01.141214 27812 net.cpp:141] Setting up pool5
I0720 14:39:01.141224 27812 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0720 14:39:01.141229 27812 net.cpp:156] Memory required for data: 67618360
I0720 14:39:01.141234 27812 layer_factory.hpp:77] Creating layer fc6
I0720 14:39:01.141255 27812 net.cpp:91] Creating Layer fc6
I0720 14:39:01.141261 27812 net.cpp:425] fc6 <- pool5
I0720 14:39:01.141269 27812 net.cpp:399] fc6 -> fc6
I0720 14:39:01.210357 27802 net.cpp:141] Setting up lstm1_transform_1
I0720 14:39:01.210407 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.210415 27802 net.cpp:156] Memory required for data: 62016
I0720 14:39:01.210440 27802 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0720 14:39:01.210467 27802 net.cpp:91] Creating Layer lstm1_gate_input_1
I0720 14:39:01.210479 27802 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0720 14:39:01.210489 27802 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0720 14:39:01.210501 27802 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0720 14:39:01.210583 27802 net.cpp:141] Setting up lstm1_gate_input_1
I0720 14:39:01.210597 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.210604 27802 net.cpp:156] Memory required for data: 78016
I0720 14:39:01.210613 27802 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0720 14:39:01.210624 27802 net.cpp:91] Creating Layer lstm1_unit_1
I0720 14:39:01.210633 27802 net.cpp:425] lstm1_unit_1 <- c_0
I0720 14:39:01.210642 27802 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0720 14:39:01.210650 27802 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0720 14:39:01.210661 27802 net.cpp:399] lstm1_unit_1 -> c_1
I0720 14:39:01.210675 27802 net.cpp:399] lstm1_unit_1 -> h_1
I0720 14:39:01.210795 27802 net.cpp:141] Setting up lstm1_unit_1
I0720 14:39:01.210811 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.210821 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.210829 27802 net.cpp:156] Memory required for data: 86016
I0720 14:39:01.210836 27802 layer_factory.hpp:77] Creating layer lstm1_
I0720 14:39:01.210852 27802 net.cpp:91] Creating Layer lstm1_
I0720 14:39:01.210861 27802 net.cpp:425] lstm1_ <- c_1
I0720 14:39:01.210872 27802 net.cpp:399] lstm1_ -> c_T
I0720 14:39:01.210917 27802 net.cpp:141] Setting up lstm1_
I0720 14:39:01.210930 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.210937 27802 net.cpp:156] Memory required for data: 90016
I0720 14:39:01.210944 27802 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0720 14:39:01.210961 27802 net.cpp:91] Creating Layer lstm1_h_concat
I0720 14:39:01.210970 27802 net.cpp:425] lstm1_h_concat <- h_1
I0720 14:39:01.210981 27802 net.cpp:399] lstm1_h_concat -> h
I0720 14:39:01.211045 27802 net.cpp:141] Setting up lstm1_h_concat
I0720 14:39:01.211057 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.211064 27802 net.cpp:156] Memory required for data: 94016
I0720 14:39:01.211072 27802 layer_factory.hpp:77] Creating layer h_pseudoloss
I0720 14:39:01.211091 27802 net.cpp:91] Creating Layer h_pseudoloss
I0720 14:39:01.211099 27802 net.cpp:425] h_pseudoloss <- h
I0720 14:39:01.211114 27802 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0720 14:39:01.211254 27802 net.cpp:141] Setting up h_pseudoloss
I0720 14:39:01.211273 27802 net.cpp:148] Top shape: (1)
I0720 14:39:01.211282 27802 net.cpp:151]     with loss weight 1
I0720 14:39:01.211328 27802 net.cpp:156] Memory required for data: 94020
I0720 14:39:01.211336 27802 net.cpp:217] h_pseudoloss needs backward computation.
I0720 14:39:01.211344 27802 net.cpp:217] lstm1_h_concat needs backward computation.
I0720 14:39:01.211351 27802 net.cpp:219] lstm1_ does not need backward computation.
I0720 14:39:01.211359 27802 net.cpp:217] lstm1_unit_1 needs backward computation.
I0720 14:39:01.211366 27802 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0720 14:39:01.211374 27802 net.cpp:217] lstm1_transform_1 needs backward computation.
I0720 14:39:01.211381 27802 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0720 14:39:01.211390 27802 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0720 14:39:01.211397 27802 net.cpp:217] lstm1_x_transform needs backward computation.
I0720 14:39:01.211405 27802 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0720 14:39:01.211412 27802 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0720 14:39:01.211426 27802 net.cpp:219] lstm1_ does not need backward computation.
I0720 14:39:01.211432 27802 net.cpp:219] lstm1_ does not need backward computation.
I0720 14:39:01.211437 27802 net.cpp:261] This network produces output c_T
I0720 14:39:01.211446 27802 net.cpp:261] This network produces output h_pseudoloss
I0720 14:39:01.211467 27802 net.cpp:274] Network initialization done.
I0720 14:39:01.211541 27802 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0720 14:39:01.211550 27802 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0720 14:39:01.211557 27802 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0720 14:39:01.211712 27802 net.cpp:141] Setting up lstm1
I0720 14:39:01.211729 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.211735 27802 net.cpp:156] Memory required for data: 26408
I0720 14:39:01.211755 27802 layer_factory.hpp:77] Creating layer concat
I0720 14:39:01.211767 27802 net.cpp:91] Creating Layer concat
I0720 14:39:01.211776 27802 net.cpp:425] concat <- lstm1
I0720 14:39:01.211786 27802 net.cpp:425] concat <- embedded_input_sentence
I0720 14:39:01.211794 27802 net.cpp:425] concat <- reshaped_stage_indicator
I0720 14:39:01.211805 27802 net.cpp:399] concat -> lstm1_video_sequence
I0720 14:39:01.211850 27802 net.cpp:141] Setting up concat
I0720 14:39:01.211863 27802 net.cpp:148] Top shape: 1 1 1501 (1501)
I0720 14:39:01.211869 27802 net.cpp:156] Memory required for data: 32412
I0720 14:39:01.211877 27802 layer_factory.hpp:77] Creating layer lstm2
I0720 14:39:01.211894 27802 net.cpp:91] Creating Layer lstm2
I0720 14:39:01.211901 27802 net.cpp:425] lstm2 <- lstm1_video_sequence
I0720 14:39:01.211910 27802 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0720 14:39:01.211921 27802 net.cpp:399] lstm2 -> lstm2
I0720 14:39:01.211935 27802 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0720 14:39:01.212344 27802 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0720 14:39:01.212479 27802 layer_factory.hpp:77] Creating layer lstm2_
I0720 14:39:01.212501 27802 net.cpp:91] Creating Layer lstm2_
I0720 14:39:01.212512 27802 net.cpp:399] lstm2_ -> x
I0720 14:39:01.212528 27802 net.cpp:399] lstm2_ -> cont
I0720 14:39:01.212627 27802 net.cpp:141] Setting up lstm2_
I0720 14:39:01.212644 27802 net.cpp:148] Top shape: 1 1 1501 (1501)
I0720 14:39:01.214445 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.214457 27802 net.cpp:156] Memory required for data: 6008
I0720 14:39:01.214469 27802 layer_factory.hpp:77] Creating layer lstm2_
I0720 14:39:01.214498 27802 net.cpp:91] Creating Layer lstm2_
I0720 14:39:01.214509 27802 net.cpp:399] lstm2_ -> c_0
I0720 14:39:01.214529 27802 net.cpp:399] lstm2_ -> h_0
I0720 14:39:01.214699 27802 net.cpp:141] Setting up lstm2_
I0720 14:39:01.214712 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.214720 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.214723 27802 net.cpp:156] Memory required for data: 14008
I0720 14:39:01.214728 27802 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0720 14:39:01.214741 27802 net.cpp:91] Creating Layer lstm2_cont_slice
I0720 14:39:01.214748 27802 net.cpp:425] lstm2_cont_slice <- cont
I0720 14:39:01.214757 27802 net.cpp:399] lstm2_cont_slice -> cont_1
I0720 14:39:01.214809 27802 net.cpp:141] Setting up lstm2_cont_slice
I0720 14:39:01.214819 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.214824 27802 net.cpp:156] Memory required for data: 14012
I0720 14:39:01.214830 27802 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0720 14:39:01.214843 27802 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0720 14:39:01.214848 27802 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0720 14:39:01.214855 27802 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0720 14:39:01.214864 27802 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0720 14:39:01.214920 27802 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0720 14:39:01.214929 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.214936 27802 net.cpp:148] Top shape: 1 1 (1)
I0720 14:39:01.214939 27802 net.cpp:156] Memory required for data: 14020
I0720 14:39:01.214944 27802 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0720 14:39:01.214962 27802 net.cpp:91] Creating Layer lstm2_x_transform
I0720 14:39:01.214967 27802 net.cpp:425] lstm2_x_transform <- x
I0720 14:39:01.214978 27802 net.cpp:399] lstm2_x_transform -> W_xc_x
I0720 14:39:01.260615 27812 net.cpp:141] Setting up fc6
I0720 14:39:01.260664 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.260673 27812 net.cpp:156] Memory required for data: 67782200
I0720 14:39:01.260691 27812 layer_factory.hpp:77] Creating layer relu6
I0720 14:39:01.260710 27812 net.cpp:91] Creating Layer relu6
I0720 14:39:01.260718 27812 net.cpp:425] relu6 <- fc6
I0720 14:39:01.260735 27812 net.cpp:386] relu6 -> fc6 (in-place)
I0720 14:39:01.261173 27812 net.cpp:141] Setting up relu6
I0720 14:39:01.261191 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.261198 27812 net.cpp:156] Memory required for data: 67946040
I0720 14:39:01.261205 27812 layer_factory.hpp:77] Creating layer drop6
I0720 14:39:01.261236 27812 net.cpp:91] Creating Layer drop6
I0720 14:39:01.261245 27812 net.cpp:425] drop6 <- fc6
I0720 14:39:01.261253 27812 net.cpp:386] drop6 -> fc6 (in-place)
I0720 14:39:01.261322 27812 net.cpp:141] Setting up drop6
I0720 14:39:01.261333 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.261340 27812 net.cpp:156] Memory required for data: 68109880
I0720 14:39:01.261348 27812 layer_factory.hpp:77] Creating layer fc7
I0720 14:39:01.261360 27812 net.cpp:91] Creating Layer fc7
I0720 14:39:01.261368 27812 net.cpp:425] fc7 <- fc6
I0720 14:39:01.261381 27812 net.cpp:399] fc7 -> fc7
I0720 14:39:01.297827 27802 net.cpp:141] Setting up lstm2_x_transform
I0720 14:39:01.297896 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.297914 27802 net.cpp:156] Memory required for data: 30020
I0720 14:39:01.297951 27802 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0720 14:39:01.297983 27802 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0720 14:39:01.298001 27802 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0720 14:39:01.298024 27802 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0720 14:39:01.298126 27802 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0720 14:39:01.298153 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.298166 27802 net.cpp:156] Memory required for data: 46020
I0720 14:39:01.298179 27802 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0720 14:39:01.298203 27802 net.cpp:91] Creating Layer lstm2_h_conted_0
I0720 14:39:01.298218 27802 net.cpp:425] lstm2_h_conted_0 <- h_0
I0720 14:39:01.298236 27802 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0720 14:39:01.298256 27802 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0720 14:39:01.298513 27802 net.cpp:141] Setting up lstm2_h_conted_0
I0720 14:39:01.298538 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.298552 27802 net.cpp:156] Memory required for data: 50020
I0720 14:39:01.298565 27802 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0720 14:39:01.298593 27802 net.cpp:91] Creating Layer lstm2_transform_1
I0720 14:39:01.298607 27802 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0720 14:39:01.298631 27802 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0720 14:39:01.314723 27812 net.cpp:141] Setting up fc7
I0720 14:39:01.314770 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.314776 27812 net.cpp:156] Memory required for data: 68273720
I0720 14:39:01.314793 27812 layer_factory.hpp:77] Creating layer relu7
I0720 14:39:01.314808 27812 net.cpp:91] Creating Layer relu7
I0720 14:39:01.314816 27812 net.cpp:425] relu7 <- fc7
I0720 14:39:01.314824 27812 net.cpp:386] relu7 -> fc7 (in-place)
I0720 14:39:01.316226 27812 net.cpp:141] Setting up relu7
I0720 14:39:01.316242 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.316246 27812 net.cpp:156] Memory required for data: 68437560
I0720 14:39:01.316251 27812 layer_factory.hpp:77] Creating layer drop7
I0720 14:39:01.316262 27812 net.cpp:91] Creating Layer drop7
I0720 14:39:01.316267 27812 net.cpp:425] drop7 <- fc7
I0720 14:39:01.316279 27812 net.cpp:386] drop7 -> fc7 (in-place)
I0720 14:39:01.316318 27812 net.cpp:141] Setting up drop7
I0720 14:39:01.316325 27812 net.cpp:148] Top shape: 10 4096 (40960)
I0720 14:39:01.316332 27812 net.cpp:156] Memory required for data: 68601400
I0720 14:39:01.316337 27812 layer_factory.hpp:77] Creating layer fc8
I0720 14:39:01.316347 27812 net.cpp:91] Creating Layer fc8
I0720 14:39:01.316352 27812 net.cpp:425] fc8 <- fc7
I0720 14:39:01.316359 27812 net.cpp:399] fc8 -> fc8
I0720 14:39:01.328562 27812 net.cpp:141] Setting up fc8
I0720 14:39:01.328604 27812 net.cpp:148] Top shape: 10 1000 (10000)
I0720 14:39:01.328610 27812 net.cpp:156] Memory required for data: 68641400
I0720 14:39:01.328624 27812 layer_factory.hpp:77] Creating layer prob
I0720 14:39:01.328639 27812 net.cpp:91] Creating Layer prob
I0720 14:39:01.328647 27812 net.cpp:425] prob <- fc8
I0720 14:39:01.328661 27812 net.cpp:399] prob -> prob
I0720 14:39:01.329077 27812 net.cpp:141] Setting up prob
I0720 14:39:01.329087 27812 net.cpp:148] Top shape: 10 1000 (10000)
I0720 14:39:01.329092 27812 net.cpp:156] Memory required for data: 68681400
I0720 14:39:01.329097 27812 net.cpp:219] prob does not need backward computation.
I0720 14:39:01.329102 27812 net.cpp:219] fc8 does not need backward computation.
I0720 14:39:01.329107 27812 net.cpp:219] drop7 does not need backward computation.
I0720 14:39:01.329111 27812 net.cpp:219] relu7 does not need backward computation.
I0720 14:39:01.329115 27812 net.cpp:219] fc7 does not need backward computation.
I0720 14:39:01.329120 27812 net.cpp:219] drop6 does not need backward computation.
I0720 14:39:01.329124 27812 net.cpp:219] relu6 does not need backward computation.
I0720 14:39:01.329129 27812 net.cpp:219] fc6 does not need backward computation.
I0720 14:39:01.329133 27812 net.cpp:219] pool5 does not need backward computation.
I0720 14:39:01.329138 27812 net.cpp:219] relu5 does not need backward computation.
I0720 14:39:01.329144 27812 net.cpp:219] conv5 does not need backward computation.
I0720 14:39:01.329147 27812 net.cpp:219] relu4 does not need backward computation.
I0720 14:39:01.329152 27812 net.cpp:219] conv4 does not need backward computation.
I0720 14:39:01.329156 27812 net.cpp:219] relu3 does not need backward computation.
I0720 14:39:01.329161 27812 net.cpp:219] conv3 does not need backward computation.
I0720 14:39:01.329165 27812 net.cpp:219] norm2 does not need backward computation.
I0720 14:39:01.329170 27812 net.cpp:219] pool2 does not need backward computation.
I0720 14:39:01.329174 27812 net.cpp:219] relu2 does not need backward computation.
I0720 14:39:01.329180 27812 net.cpp:219] conv2 does not need backward computation.
I0720 14:39:01.329183 27812 net.cpp:219] norm1 does not need backward computation.
I0720 14:39:01.329188 27812 net.cpp:219] pool1 does not need backward computation.
I0720 14:39:01.329192 27812 net.cpp:219] relu1 does not need backward computation.
I0720 14:39:01.329196 27812 net.cpp:219] conv1 does not need backward computation.
I0720 14:39:01.329201 27812 net.cpp:219] data does not need backward computation.
I0720 14:39:01.329205 27812 net.cpp:261] This network produces output prob
I0720 14:39:01.329226 27812 net.cpp:274] Network initialization done.
I0720 14:39:01.337471 27802 net.cpp:141] Setting up lstm2_transform_1
I0720 14:39:01.337513 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.337519 27802 net.cpp:156] Memory required for data: 66020
I0720 14:39:01.337538 27802 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0720 14:39:01.337553 27802 net.cpp:91] Creating Layer lstm2_gate_input_1
I0720 14:39:01.337559 27802 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0720 14:39:01.337568 27802 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0720 14:39:01.337575 27802 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0720 14:39:01.337626 27802 net.cpp:141] Setting up lstm2_gate_input_1
I0720 14:39:01.337635 27802 net.cpp:148] Top shape: 1 1 4000 (4000)
I0720 14:39:01.337640 27802 net.cpp:156] Memory required for data: 82020
I0720 14:39:01.337643 27802 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0720 14:39:01.337654 27802 net.cpp:91] Creating Layer lstm2_unit_1
I0720 14:39:01.337658 27802 net.cpp:425] lstm2_unit_1 <- c_0
I0720 14:39:01.337664 27802 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0720 14:39:01.337669 27802 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0720 14:39:01.337676 27802 net.cpp:399] lstm2_unit_1 -> c_1
I0720 14:39:01.337683 27802 net.cpp:399] lstm2_unit_1 -> h_1
I0720 14:39:01.337748 27802 net.cpp:141] Setting up lstm2_unit_1
I0720 14:39:01.337756 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.337761 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.337765 27802 net.cpp:156] Memory required for data: 90020
I0720 14:39:01.337770 27802 layer_factory.hpp:77] Creating layer lstm2_
I0720 14:39:01.337777 27802 net.cpp:91] Creating Layer lstm2_
I0720 14:39:01.337782 27802 net.cpp:425] lstm2_ <- c_1
I0720 14:39:01.337788 27802 net.cpp:399] lstm2_ -> c_T
I0720 14:39:01.337817 27802 net.cpp:141] Setting up lstm2_
I0720 14:39:01.337826 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.337829 27802 net.cpp:156] Memory required for data: 94020
I0720 14:39:01.337833 27802 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0720 14:39:01.337846 27802 net.cpp:91] Creating Layer lstm2_h_concat
I0720 14:39:01.337851 27802 net.cpp:425] lstm2_h_concat <- h_1
I0720 14:39:01.337857 27802 net.cpp:399] lstm2_h_concat -> h
I0720 14:39:01.337891 27802 net.cpp:141] Setting up lstm2_h_concat
I0720 14:39:01.337899 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.337903 27802 net.cpp:156] Memory required for data: 98020
I0720 14:39:01.337908 27802 layer_factory.hpp:77] Creating layer h_pseudoloss
I0720 14:39:01.337915 27802 net.cpp:91] Creating Layer h_pseudoloss
I0720 14:39:01.337919 27802 net.cpp:425] h_pseudoloss <- h
I0720 14:39:01.337929 27802 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0720 14:39:01.338013 27802 net.cpp:141] Setting up h_pseudoloss
I0720 14:39:01.338026 27802 net.cpp:148] Top shape: (1)
I0720 14:39:01.338029 27802 net.cpp:151]     with loss weight 1
I0720 14:39:01.338047 27802 net.cpp:156] Memory required for data: 98024
I0720 14:39:01.338050 27802 net.cpp:217] h_pseudoloss needs backward computation.
I0720 14:39:01.338055 27802 net.cpp:217] lstm2_h_concat needs backward computation.
I0720 14:39:01.338059 27802 net.cpp:219] lstm2_ does not need backward computation.
I0720 14:39:01.338063 27802 net.cpp:217] lstm2_unit_1 needs backward computation.
I0720 14:39:01.338069 27802 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0720 14:39:01.338073 27802 net.cpp:217] lstm2_transform_1 needs backward computation.
I0720 14:39:01.338078 27802 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0720 14:39:01.338083 27802 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0720 14:39:01.338088 27802 net.cpp:217] lstm2_x_transform needs backward computation.
I0720 14:39:01.338093 27802 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0720 14:39:01.338096 27802 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0720 14:39:01.338101 27802 net.cpp:219] lstm2_ does not need backward computation.
I0720 14:39:01.338105 27802 net.cpp:219] lstm2_ does not need backward computation.
I0720 14:39:01.338109 27802 net.cpp:261] This network produces output c_T
I0720 14:39:01.338114 27802 net.cpp:261] This network produces output h_pseudoloss
I0720 14:39:01.338129 27802 net.cpp:274] Network initialization done.
I0720 14:39:01.338176 27802 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0720 14:39:01.338181 27802 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0720 14:39:01.338186 27802 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0720 14:39:01.338285 27802 net.cpp:141] Setting up lstm2
I0720 14:39:01.338297 27802 net.cpp:148] Top shape: 1 1 1000 (1000)
I0720 14:39:01.338302 27802 net.cpp:156] Memory required for data: 36412
I0720 14:39:01.338315 27802 layer_factory.hpp:77] Creating layer predict
I0720 14:39:01.338325 27802 net.cpp:91] Creating Layer predict
I0720 14:39:01.338330 27802 net.cpp:425] predict <- lstm2
I0720 14:39:01.338338 27802 net.cpp:399] predict -> predict
I0720 14:39:01.560269 27812 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld4132497111785329636/bvlc_reference_caffenet.caffemodel
I0720 14:39:01.560307 27812 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0720 14:39:01.560312 27812 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0720 14:39:01.560315 27812 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld4132497111785329636/bvlc_reference_caffenet.caffemodel
I0720 14:39:01.779135 27802 net.cpp:141] Setting up predict
I0720 14:39:01.779180 27802 net.cpp:148] Top shape: 1 1 46168 (46168)
I0720 14:39:01.779186 27802 net.cpp:156] Memory required for data: 221084
I0720 14:39:01.779197 27802 layer_factory.hpp:77] Creating layer probs
I0720 14:39:01.779212 27802 net.cpp:91] Creating Layer probs
I0720 14:39:01.779219 27802 net.cpp:425] probs <- predict
I0720 14:39:01.779228 27802 net.cpp:399] probs -> probs
I0720 14:39:01.781370 27802 net.cpp:141] Setting up probs
I0720 14:39:01.781390 27802 net.cpp:148] Top shape: 1 1 46168 (46168)
I0720 14:39:01.781395 27802 net.cpp:156] Memory required for data: 405756
I0720 14:39:01.781400 27802 net.cpp:219] probs does not need backward computation.
I0720 14:39:01.781406 27802 net.cpp:219] predict does not need backward computation.
I0720 14:39:01.781410 27802 net.cpp:219] lstm2 does not need backward computation.
I0720 14:39:01.781416 27802 net.cpp:219] concat does not need backward computation.
I0720 14:39:01.781422 27802 net.cpp:219] lstm1 does not need backward computation.
I0720 14:39:01.781427 27802 net.cpp:219] embedding does not need backward computation.
I0720 14:39:01.781432 27802 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0720 14:39:01.781436 27802 net.cpp:219] reshape_frames does not need backward computation.
I0720 14:39:01.781441 27802 net.cpp:219] embed_encoder does not need backward computation.
I0720 14:39:01.781446 27802 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0720 14:39:01.781451 27802 net.cpp:219] input does not need backward computation.
I0720 14:39:01.781455 27802 net.cpp:261] This network produces output probs
I0720 14:39:01.781468 27802 net.cpp:274] Network initialization done.
I0720 14:39:01.923702 27812 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0720 14:39:01.973384 27812 net.cpp:752] Ignoring source layer loss
I0720 14:39:02.106822 27802 net.cpp:752] Ignoring source layer data
I0720 14:39:02.106851 27802 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0720 14:39:02.106856 27802 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0720 14:39:02.193145 27802 net.cpp:752] Ignoring source layer cross_entropy_loss
