SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm102/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/work/run/storm102/data/supervisor/stormdist/captioning-1-1473816139/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/peifeng/work/run/storm102/data/workers/ea79241a-3689-45ef-924f-6af8359cb04a/tmp/cvld5953182427152014651/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0913 21:22:59.000610 24286 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0913 21:22:59.000809 24286 layer_factory.hpp:77] Creating layer data
I0913 21:22:59.000841 24286 net.cpp:91] Creating Layer data
I0913 21:22:59.000851 24286 net.cpp:399] data -> data
I0913 21:22:59.538089 24286 net.cpp:141] Setting up data
I0913 21:22:59.538194 24286 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0913 21:22:59.538202 24286 net.cpp:156] Memory required for data: 6183480
I0913 21:22:59.538220 24286 layer_factory.hpp:77] Creating layer conv1
I0913 21:22:59.538252 24286 net.cpp:91] Creating Layer conv1
I0913 21:22:59.538261 24286 net.cpp:425] conv1 <- data
I0913 21:22:59.538275 24286 net.cpp:399] conv1 -> conv1
I0913 21:22:59.721329 24286 net.cpp:141] Setting up conv1
I0913 21:22:59.721381 24286 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:22:59.721388 24286 net.cpp:156] Memory required for data: 17799480
I0913 21:22:59.721417 24286 layer_factory.hpp:77] Creating layer relu1
I0913 21:22:59.721438 24286 net.cpp:91] Creating Layer relu1
I0913 21:22:59.721446 24286 net.cpp:425] relu1 <- conv1
I0913 21:22:59.721453 24286 net.cpp:386] relu1 -> conv1 (in-place)
I0913 21:22:59.721846 24286 net.cpp:141] Setting up relu1
I0913 21:22:59.721860 24286 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:22:59.721866 24286 net.cpp:156] Memory required for data: 29415480
I0913 21:22:59.721871 24286 layer_factory.hpp:77] Creating layer pool1
I0913 21:22:59.721884 24286 net.cpp:91] Creating Layer pool1
I0913 21:22:59.721890 24286 net.cpp:425] pool1 <- conv1
I0913 21:22:59.721899 24286 net.cpp:399] pool1 -> pool1
I0913 21:22:59.721973 24286 net.cpp:141] Setting up pool1
I0913 21:22:59.721984 24286 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:22:59.721989 24286 net.cpp:156] Memory required for data: 32214840
I0913 21:22:59.721994 24286 layer_factory.hpp:77] Creating layer norm1
I0913 21:22:59.722012 24286 net.cpp:91] Creating Layer norm1
I0913 21:22:59.722018 24286 net.cpp:425] norm1 <- pool1
I0913 21:22:59.722024 24286 net.cpp:399] norm1 -> norm1
I0913 21:22:59.722280 24286 net.cpp:141] Setting up norm1
I0913 21:22:59.722291 24286 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:22:59.722296 24286 net.cpp:156] Memory required for data: 35014200
I0913 21:22:59.722301 24286 layer_factory.hpp:77] Creating layer conv2
I0913 21:22:59.722316 24286 net.cpp:91] Creating Layer conv2
I0913 21:22:59.722322 24286 net.cpp:425] conv2 <- norm1
I0913 21:22:59.722329 24286 net.cpp:399] conv2 -> conv2
I0913 21:22:59.726112 24286 net.cpp:141] Setting up conv2
I0913 21:22:59.726140 24286 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:22:59.726146 24286 net.cpp:156] Memory required for data: 42479160
I0913 21:22:59.726161 24286 layer_factory.hpp:77] Creating layer relu2
I0913 21:22:59.726171 24286 net.cpp:91] Creating Layer relu2
I0913 21:22:59.726177 24286 net.cpp:425] relu2 <- conv2
I0913 21:22:59.726184 24286 net.cpp:386] relu2 -> conv2 (in-place)
I0913 21:22:59.726564 24286 net.cpp:141] Setting up relu2
I0913 21:22:59.726578 24286 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:22:59.726583 24286 net.cpp:156] Memory required for data: 49944120
I0913 21:22:59.726589 24286 layer_factory.hpp:77] Creating layer pool2
I0913 21:22:59.726598 24286 net.cpp:91] Creating Layer pool2
I0913 21:22:59.726603 24286 net.cpp:425] pool2 <- conv2
I0913 21:22:59.726611 24286 net.cpp:399] pool2 -> pool2
I0913 21:22:59.726663 24286 net.cpp:141] Setting up pool2
I0913 21:22:59.726671 24286 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:22:59.726676 24286 net.cpp:156] Memory required for data: 51674680
I0913 21:22:59.726681 24286 layer_factory.hpp:77] Creating layer norm2
I0913 21:22:59.726693 24286 net.cpp:91] Creating Layer norm2
I0913 21:22:59.726698 24286 net.cpp:425] norm2 <- pool2
I0913 21:22:59.726704 24286 net.cpp:399] norm2 -> norm2
I0913 21:22:59.726950 24286 net.cpp:141] Setting up norm2
I0913 21:22:59.726963 24286 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:22:59.726968 24286 net.cpp:156] Memory required for data: 53405240
I0913 21:22:59.726971 24286 layer_factory.hpp:77] Creating layer conv3
I0913 21:22:59.726984 24286 net.cpp:91] Creating Layer conv3
I0913 21:22:59.726989 24286 net.cpp:425] conv3 <- norm2
I0913 21:22:59.726995 24286 net.cpp:399] conv3 -> conv3
I0913 21:22:59.730541 24286 net.cpp:141] Setting up conv3
I0913 21:22:59.730564 24286 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:22:59.730571 24286 net.cpp:156] Memory required for data: 56001080
I0913 21:22:59.730583 24286 layer_factory.hpp:77] Creating layer relu3
I0913 21:22:59.730593 24286 net.cpp:91] Creating Layer relu3
I0913 21:22:59.730598 24286 net.cpp:425] relu3 <- conv3
I0913 21:22:59.730605 24286 net.cpp:386] relu3 -> conv3 (in-place)
I0913 21:22:59.730829 24286 net.cpp:141] Setting up relu3
I0913 21:22:59.730840 24286 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:22:59.730845 24286 net.cpp:156] Memory required for data: 58596920
I0913 21:22:59.730850 24286 layer_factory.hpp:77] Creating layer conv4
I0913 21:22:59.730864 24286 net.cpp:91] Creating Layer conv4
I0913 21:22:59.730870 24286 net.cpp:425] conv4 <- conv3
I0913 21:22:59.730876 24286 net.cpp:399] conv4 -> conv4
I0913 21:22:59.734866 24286 net.cpp:141] Setting up conv4
I0913 21:22:59.734889 24286 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:22:59.734897 24286 net.cpp:156] Memory required for data: 61192760
I0913 21:22:59.734907 24286 layer_factory.hpp:77] Creating layer relu4
I0913 21:22:59.734917 24286 net.cpp:91] Creating Layer relu4
I0913 21:22:59.734922 24286 net.cpp:425] relu4 <- conv4
I0913 21:22:59.734930 24286 net.cpp:386] relu4 -> conv4 (in-place)
I0913 21:22:59.735316 24286 net.cpp:141] Setting up relu4
I0913 21:22:59.735329 24286 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:22:59.735335 24286 net.cpp:156] Memory required for data: 63788600
I0913 21:22:59.735340 24286 layer_factory.hpp:77] Creating layer conv5
I0913 21:22:59.735352 24286 net.cpp:91] Creating Layer conv5
I0913 21:22:59.735357 24286 net.cpp:425] conv5 <- conv4
I0913 21:22:59.735366 24286 net.cpp:399] conv5 -> conv5
I0913 21:22:59.738963 24286 net.cpp:141] Setting up conv5
I0913 21:22:59.738982 24286 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:22:59.738988 24286 net.cpp:156] Memory required for data: 65519160
I0913 21:22:59.739001 24286 layer_factory.hpp:77] Creating layer relu5
I0913 21:22:59.739012 24286 net.cpp:91] Creating Layer relu5
I0913 21:22:59.739018 24286 net.cpp:425] relu5 <- conv5
I0913 21:22:59.739024 24286 net.cpp:386] relu5 -> conv5 (in-place)
I0913 21:22:59.739426 24286 net.cpp:141] Setting up relu5
I0913 21:22:59.739441 24286 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:22:59.739446 24286 net.cpp:156] Memory required for data: 67249720
I0913 21:22:59.739451 24286 layer_factory.hpp:77] Creating layer pool5
I0913 21:22:59.739462 24286 net.cpp:91] Creating Layer pool5
I0913 21:22:59.739466 24286 net.cpp:425] pool5 <- conv5
I0913 21:22:59.739473 24286 net.cpp:399] pool5 -> pool5
I0913 21:22:59.739536 24286 net.cpp:141] Setting up pool5
I0913 21:22:59.739545 24286 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0913 21:22:59.739550 24286 net.cpp:156] Memory required for data: 67618360
I0913 21:22:59.739554 24286 layer_factory.hpp:77] Creating layer fc6
I0913 21:22:59.739570 24286 net.cpp:91] Creating Layer fc6
I0913 21:22:59.739575 24286 net.cpp:425] fc6 <- pool5
I0913 21:22:59.739583 24286 net.cpp:399] fc6 -> fc6
I0913 21:22:59.841511 24286 net.cpp:141] Setting up fc6
I0913 21:22:59.841606 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.841619 24286 net.cpp:156] Memory required for data: 67782200
I0913 21:22:59.841651 24286 layer_factory.hpp:77] Creating layer relu6
I0913 21:22:59.841684 24286 net.cpp:91] Creating Layer relu6
I0913 21:22:59.841697 24286 net.cpp:425] relu6 <- fc6
I0913 21:22:59.841714 24286 net.cpp:386] relu6 -> fc6 (in-place)
I0913 21:22:59.844236 24286 net.cpp:141] Setting up relu6
I0913 21:22:59.844302 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.844316 24286 net.cpp:156] Memory required for data: 67946040
I0913 21:22:59.844332 24286 layer_factory.hpp:77] Creating layer drop6
I0913 21:22:59.844388 24286 net.cpp:91] Creating Layer drop6
I0913 21:22:59.844403 24286 net.cpp:425] drop6 <- fc6
I0913 21:22:59.844422 24286 net.cpp:386] drop6 -> fc6 (in-place)
I0913 21:22:59.846428 24286 net.cpp:141] Setting up drop6
I0913 21:22:59.846447 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.846454 24286 net.cpp:156] Memory required for data: 68109880
I0913 21:22:59.846462 24286 layer_factory.hpp:77] Creating layer fc7
I0913 21:22:59.846475 24286 net.cpp:91] Creating Layer fc7
I0913 21:22:59.846482 24286 net.cpp:425] fc7 <- fc6
I0913 21:22:59.846496 24286 net.cpp:399] fc7 -> fc7
I0913 21:22:59.892670 24286 net.cpp:141] Setting up fc7
I0913 21:22:59.892726 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.892734 24286 net.cpp:156] Memory required for data: 68273720
I0913 21:22:59.892750 24286 layer_factory.hpp:77] Creating layer relu7
I0913 21:22:59.892765 24286 net.cpp:91] Creating Layer relu7
I0913 21:22:59.892772 24286 net.cpp:425] relu7 <- fc7
I0913 21:22:59.892783 24286 net.cpp:386] relu7 -> fc7 (in-place)
I0913 21:22:59.893412 24286 net.cpp:141] Setting up relu7
I0913 21:22:59.893425 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.893430 24286 net.cpp:156] Memory required for data: 68437560
I0913 21:22:59.893435 24286 layer_factory.hpp:77] Creating layer drop7
I0913 21:22:59.893455 24286 net.cpp:91] Creating Layer drop7
I0913 21:22:59.893460 24286 net.cpp:425] drop7 <- fc7
I0913 21:22:59.893470 24286 net.cpp:386] drop7 -> fc7 (in-place)
I0913 21:22:59.893506 24286 net.cpp:141] Setting up drop7
I0913 21:22:59.893517 24286 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:22:59.893522 24286 net.cpp:156] Memory required for data: 68601400
I0913 21:22:59.893527 24286 layer_factory.hpp:77] Creating layer fc8
I0913 21:22:59.893535 24286 net.cpp:91] Creating Layer fc8
I0913 21:22:59.893540 24286 net.cpp:425] fc8 <- fc7
I0913 21:22:59.893546 24286 net.cpp:399] fc8 -> fc8
I0913 21:22:59.905066 24286 net.cpp:141] Setting up fc8
I0913 21:22:59.905115 24286 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:22:59.905122 24286 net.cpp:156] Memory required for data: 68641400
I0913 21:22:59.905136 24286 layer_factory.hpp:77] Creating layer prob
I0913 21:22:59.905158 24286 net.cpp:91] Creating Layer prob
I0913 21:22:59.905164 24286 net.cpp:425] prob <- fc8
I0913 21:22:59.905174 24286 net.cpp:399] prob -> prob
I0913 21:22:59.905589 24286 net.cpp:141] Setting up prob
I0913 21:22:59.905601 24286 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:22:59.905606 24286 net.cpp:156] Memory required for data: 68681400
I0913 21:22:59.905612 24286 net.cpp:219] prob does not need backward computation.
I0913 21:22:59.905617 24286 net.cpp:219] fc8 does not need backward computation.
I0913 21:22:59.905622 24286 net.cpp:219] drop7 does not need backward computation.
I0913 21:22:59.905627 24286 net.cpp:219] relu7 does not need backward computation.
I0913 21:22:59.905630 24286 net.cpp:219] fc7 does not need backward computation.
I0913 21:22:59.905634 24286 net.cpp:219] drop6 does not need backward computation.
I0913 21:22:59.905638 24286 net.cpp:219] relu6 does not need backward computation.
I0913 21:22:59.905642 24286 net.cpp:219] fc6 does not need backward computation.
I0913 21:22:59.905647 24286 net.cpp:219] pool5 does not need backward computation.
I0913 21:22:59.905652 24286 net.cpp:219] relu5 does not need backward computation.
I0913 21:22:59.905656 24286 net.cpp:219] conv5 does not need backward computation.
I0913 21:22:59.905660 24286 net.cpp:219] relu4 does not need backward computation.
I0913 21:22:59.905664 24286 net.cpp:219] conv4 does not need backward computation.
I0913 21:22:59.905669 24286 net.cpp:219] relu3 does not need backward computation.
I0913 21:22:59.905673 24286 net.cpp:219] conv3 does not need backward computation.
I0913 21:22:59.905678 24286 net.cpp:219] norm2 does not need backward computation.
I0913 21:22:59.905681 24286 net.cpp:219] pool2 does not need backward computation.
I0913 21:22:59.905685 24286 net.cpp:219] relu2 does not need backward computation.
I0913 21:22:59.905689 24286 net.cpp:219] conv2 does not need backward computation.
I0913 21:22:59.905694 24286 net.cpp:219] norm1 does not need backward computation.
I0913 21:22:59.905699 24286 net.cpp:219] pool1 does not need backward computation.
I0913 21:22:59.905702 24286 net.cpp:219] relu1 does not need backward computation.
I0913 21:22:59.905706 24286 net.cpp:219] conv1 does not need backward computation.
I0913 21:22:59.905710 24286 net.cpp:219] data does not need backward computation.
I0913 21:22:59.905714 24286 net.cpp:261] This network produces output prob
I0913 21:22:59.905750 24286 net.cpp:274] Network initialization done.
I0913 21:22:59.921702 24276 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /home/peifeng/work/run/storm102/data/workers/ea79241a-3689-45ef-924f-6af8359cb04a/tmp/cvld5953182427152014651/s2vt.words_to_preds.prototxt
I0913 21:22:59.921756 24276 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0913 21:22:59.921763 24276 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0913 21:22:59.922071 24276 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0913 21:22:59.922191 24276 layer_factory.hpp:77] Creating layer input
I0913 21:22:59.922214 24276 net.cpp:91] Creating Layer input
I0913 21:22:59.922224 24276 net.cpp:399] input -> frames_fc7
I0913 21:22:59.922241 24276 net.cpp:399] input -> cont_sentence
I0913 21:22:59.922251 24276 net.cpp:399] input -> input_sentence
I0913 21:22:59.922260 24276 net.cpp:399] input -> stage_indicator
I0913 21:22:59.922390 24276 net.cpp:141] Setting up input
I0913 21:22:59.922402 24276 net.cpp:148] Top shape: 1 4096 (4096)
I0913 21:22:59.922410 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:22:59.922415 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:22:59.922422 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:22:59.922426 24276 net.cpp:156] Memory required for data: 16396
I0913 21:22:59.922432 24276 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0913 21:22:59.922448 24276 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0913 21:22:59.922454 24276 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0913 21:22:59.922471 24276 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0913 21:22:59.922487 24276 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0913 21:22:59.922541 24276 net.cpp:141] Setting up cont_sentence_input_1_split
I0913 21:22:59.922552 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:22:59.922559 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:22:59.922567 24276 net.cpp:156] Memory required for data: 16404
I0913 21:22:59.922572 24276 layer_factory.hpp:77] Creating layer embed_encoder
I0913 21:22:59.922590 24276 net.cpp:91] Creating Layer embed_encoder
I0913 21:22:59.922596 24276 net.cpp:425] embed_encoder <- frames_fc7
I0913 21:22:59.922603 24276 net.cpp:399] embed_encoder -> embedded_in_frames
I0913 21:22:59.943743 24276 net.cpp:141] Setting up embed_encoder
I0913 21:22:59.943796 24276 net.cpp:148] Top shape: 1 500 (500)
I0913 21:22:59.943802 24276 net.cpp:156] Memory required for data: 18404
I0913 21:22:59.943825 24276 layer_factory.hpp:77] Creating layer reshape_frames
I0913 21:22:59.943856 24276 net.cpp:91] Creating Layer reshape_frames
I0913 21:22:59.943864 24276 net.cpp:425] reshape_frames <- embedded_in_frames
I0913 21:22:59.943876 24276 net.cpp:399] reshape_frames -> embedded_input_frames
I0913 21:22:59.943934 24276 net.cpp:141] Setting up reshape_frames
I0913 21:22:59.943943 24276 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:22:59.943948 24276 net.cpp:156] Memory required for data: 20404
I0913 21:22:59.943953 24276 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0913 21:22:59.943964 24276 net.cpp:91] Creating Layer reshape_stage_indicator
I0913 21:22:59.943969 24276 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0913 21:22:59.943985 24276 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0913 21:22:59.944022 24276 net.cpp:141] Setting up reshape_stage_indicator
I0913 21:22:59.944031 24276 net.cpp:148] Top shape: 1 1 1 (1)
I0913 21:22:59.944036 24276 net.cpp:156] Memory required for data: 20408
I0913 21:22:59.944041 24276 layer_factory.hpp:77] Creating layer embedding
I0913 21:22:59.944051 24276 net.cpp:91] Creating Layer embedding
I0913 21:22:59.944056 24276 net.cpp:425] embedding <- input_sentence
I0913 21:22:59.944082 24276 net.cpp:399] embedding -> embedded_input_sentence
I0913 21:23:00.133882 24286 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/peifeng/work/run/storm102/data/workers/ea79241a-3689-45ef-924f-6af8359cb04a/tmp/cvld5953182427152014651/bvlc_reference_caffenet.caffemodel
I0913 21:23:00.133924 24286 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0913 21:23:00.133929 24286 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0913 21:23:00.133934 24286 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/peifeng/work/run/storm102/data/workers/ea79241a-3689-45ef-924f-6af8359cb04a/tmp/cvld5953182427152014651/bvlc_reference_caffenet.caffemodel
I0913 21:23:00.162178 24276 net.cpp:141] Setting up embedding
I0913 21:23:00.162243 24276 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:23:00.162250 24276 net.cpp:156] Memory required for data: 22408
I0913 21:23:00.162268 24276 layer_factory.hpp:77] Creating layer lstm1
I0913 21:23:00.162303 24276 net.cpp:91] Creating Layer lstm1
I0913 21:23:00.162312 24276 net.cpp:425] lstm1 <- embedded_input_frames
I0913 21:23:00.162319 24276 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0913 21:23:00.162339 24276 net.cpp:399] lstm1 -> lstm1
I0913 21:23:00.162369 24276 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:23:00.162760 24276 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:23:00.162853 24276 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:23:00.162865 24276 net.cpp:91] Creating Layer lstm1_
I0913 21:23:00.162871 24276 net.cpp:399] lstm1_ -> x
I0913 21:23:00.162883 24276 net.cpp:399] lstm1_ -> cont
I0913 21:23:00.162942 24276 net.cpp:141] Setting up lstm1_
I0913 21:23:00.162952 24276 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:23:00.162958 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.162963 24276 net.cpp:156] Memory required for data: 2004
I0913 21:23:00.162968 24276 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:23:00.162976 24276 net.cpp:91] Creating Layer lstm1_
I0913 21:23:00.162986 24276 net.cpp:399] lstm1_ -> c_0
I0913 21:23:00.162994 24276 net.cpp:399] lstm1_ -> h_0
I0913 21:23:00.163041 24276 net.cpp:141] Setting up lstm1_
I0913 21:23:00.163050 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.163058 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.163061 24276 net.cpp:156] Memory required for data: 10004
I0913 21:23:00.163065 24276 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0913 21:23:00.163076 24276 net.cpp:91] Creating Layer lstm1_cont_slice
I0913 21:23:00.163081 24276 net.cpp:425] lstm1_cont_slice <- cont
I0913 21:23:00.163090 24276 net.cpp:399] lstm1_cont_slice -> cont_1
I0913 21:23:00.163123 24276 net.cpp:141] Setting up lstm1_cont_slice
I0913 21:23:00.163132 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.163137 24276 net.cpp:156] Memory required for data: 10008
I0913 21:23:00.163141 24276 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0913 21:23:00.163151 24276 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0913 21:23:00.163156 24276 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0913 21:23:00.163162 24276 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0913 21:23:00.163172 24276 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0913 21:23:00.163219 24276 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0913 21:23:00.163228 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.163234 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.163239 24276 net.cpp:156] Memory required for data: 10016
I0913 21:23:00.163242 24276 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0913 21:23:00.163252 24276 net.cpp:91] Creating Layer lstm1_x_transform
I0913 21:23:00.163256 24276 net.cpp:425] lstm1_x_transform <- x
I0913 21:23:00.163264 24276 net.cpp:399] lstm1_x_transform -> W_xc_x
I0913 21:23:00.183174 24276 net.cpp:141] Setting up lstm1_x_transform
I0913 21:23:00.183223 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.183229 24276 net.cpp:156] Memory required for data: 26016
I0913 21:23:00.183251 24276 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0913 21:23:00.183269 24276 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0913 21:23:00.183275 24276 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0913 21:23:00.183284 24276 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0913 21:23:00.183327 24276 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0913 21:23:00.183337 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.183342 24276 net.cpp:156] Memory required for data: 42016
I0913 21:23:00.183346 24276 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0913 21:23:00.183359 24276 net.cpp:91] Creating Layer lstm1_h_conted_0
I0913 21:23:00.183364 24276 net.cpp:425] lstm1_h_conted_0 <- h_0
I0913 21:23:00.183370 24276 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0913 21:23:00.183377 24276 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0913 21:23:00.183483 24276 net.cpp:141] Setting up lstm1_h_conted_0
I0913 21:23:00.183493 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.183497 24276 net.cpp:156] Memory required for data: 46016
I0913 21:23:00.183502 24276 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0913 21:23:00.183514 24276 net.cpp:91] Creating Layer lstm1_transform_1
I0913 21:23:00.183519 24276 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0913 21:23:00.183526 24276 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0913 21:23:00.222323 24276 net.cpp:141] Setting up lstm1_transform_1
I0913 21:23:00.222378 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.222384 24276 net.cpp:156] Memory required for data: 62016
I0913 21:23:00.222406 24276 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0913 21:23:00.222430 24276 net.cpp:91] Creating Layer lstm1_gate_input_1
I0913 21:23:00.222437 24276 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0913 21:23:00.222445 24276 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0913 21:23:00.222453 24276 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0913 21:23:00.222512 24276 net.cpp:141] Setting up lstm1_gate_input_1
I0913 21:23:00.222520 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.222525 24276 net.cpp:156] Memory required for data: 78016
I0913 21:23:00.222529 24276 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0913 21:23:00.222538 24276 net.cpp:91] Creating Layer lstm1_unit_1
I0913 21:23:00.222543 24276 net.cpp:425] lstm1_unit_1 <- c_0
I0913 21:23:00.222548 24276 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0913 21:23:00.222553 24276 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0913 21:23:00.222559 24276 net.cpp:399] lstm1_unit_1 -> c_1
I0913 21:23:00.222568 24276 net.cpp:399] lstm1_unit_1 -> h_1
I0913 21:23:00.222627 24276 net.cpp:141] Setting up lstm1_unit_1
I0913 21:23:00.222636 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.222643 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.222647 24276 net.cpp:156] Memory required for data: 86016
I0913 21:23:00.222652 24276 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:23:00.222663 24276 net.cpp:91] Creating Layer lstm1_
I0913 21:23:00.222668 24276 net.cpp:425] lstm1_ <- c_1
I0913 21:23:00.222674 24276 net.cpp:399] lstm1_ -> c_T
I0913 21:23:00.222704 24276 net.cpp:141] Setting up lstm1_
I0913 21:23:00.222712 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.222718 24276 net.cpp:156] Memory required for data: 90016
I0913 21:23:00.222721 24276 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0913 21:23:00.222743 24276 net.cpp:91] Creating Layer lstm1_h_concat
I0913 21:23:00.222748 24276 net.cpp:425] lstm1_h_concat <- h_1
I0913 21:23:00.222759 24276 net.cpp:399] lstm1_h_concat -> h
I0913 21:23:00.222792 24276 net.cpp:141] Setting up lstm1_h_concat
I0913 21:23:00.222800 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.222805 24276 net.cpp:156] Memory required for data: 94016
I0913 21:23:00.222810 24276 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:23:00.222826 24276 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:23:00.222831 24276 net.cpp:425] h_pseudoloss <- h
I0913 21:23:00.222838 24276 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:23:00.222923 24276 net.cpp:141] Setting up h_pseudoloss
I0913 21:23:00.222934 24276 net.cpp:148] Top shape: (1)
I0913 21:23:00.222937 24276 net.cpp:151]     with loss weight 1
I0913 21:23:00.222978 24276 net.cpp:156] Memory required for data: 94020
I0913 21:23:00.222983 24276 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:23:00.222988 24276 net.cpp:217] lstm1_h_concat needs backward computation.
I0913 21:23:00.222992 24276 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:23:00.222997 24276 net.cpp:217] lstm1_unit_1 needs backward computation.
I0913 21:23:00.223002 24276 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0913 21:23:00.223007 24276 net.cpp:217] lstm1_transform_1 needs backward computation.
I0913 21:23:00.223011 24276 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0913 21:23:00.223016 24276 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0913 21:23:00.223024 24276 net.cpp:217] lstm1_x_transform needs backward computation.
I0913 21:23:00.223029 24276 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0913 21:23:00.223034 24276 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0913 21:23:00.223039 24276 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:23:00.223043 24276 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:23:00.223047 24276 net.cpp:261] This network produces output c_T
I0913 21:23:00.223052 24276 net.cpp:261] This network produces output h_pseudoloss
I0913 21:23:00.223065 24276 net.cpp:274] Network initialization done.
I0913 21:23:00.223116 24276 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:23:00.223124 24276 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:23:00.223127 24276 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:23:00.223228 24276 net.cpp:141] Setting up lstm1
I0913 21:23:00.223242 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.223245 24276 net.cpp:156] Memory required for data: 26408
I0913 21:23:00.223258 24276 layer_factory.hpp:77] Creating layer concat
I0913 21:23:00.223268 24276 net.cpp:91] Creating Layer concat
I0913 21:23:00.223273 24276 net.cpp:425] concat <- lstm1
I0913 21:23:00.223279 24276 net.cpp:425] concat <- embedded_input_sentence
I0913 21:23:00.223284 24276 net.cpp:425] concat <- reshaped_stage_indicator
I0913 21:23:00.223290 24276 net.cpp:399] concat -> lstm1_video_sequence
I0913 21:23:00.223322 24276 net.cpp:141] Setting up concat
I0913 21:23:00.223331 24276 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:23:00.223336 24276 net.cpp:156] Memory required for data: 32412
I0913 21:23:00.223340 24276 layer_factory.hpp:77] Creating layer lstm2
I0913 21:23:00.223351 24276 net.cpp:91] Creating Layer lstm2
I0913 21:23:00.223356 24276 net.cpp:425] lstm2 <- lstm1_video_sequence
I0913 21:23:00.223362 24276 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0913 21:23:00.223368 24276 net.cpp:399] lstm2 -> lstm2
I0913 21:23:00.223379 24276 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:23:00.223713 24276 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:23:00.223844 24276 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:23:00.223862 24276 net.cpp:91] Creating Layer lstm2_
I0913 21:23:00.223872 24276 net.cpp:399] lstm2_ -> x
I0913 21:23:00.223889 24276 net.cpp:399] lstm2_ -> cont
I0913 21:23:00.223971 24276 net.cpp:141] Setting up lstm2_
I0913 21:23:00.223987 24276 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:23:00.223999 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.224005 24276 net.cpp:156] Memory required for data: 6008
I0913 21:23:00.224014 24276 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:23:00.224030 24276 net.cpp:91] Creating Layer lstm2_
I0913 21:23:00.224043 24276 net.cpp:399] lstm2_ -> c_0
I0913 21:23:00.224058 24276 net.cpp:399] lstm2_ -> h_0
I0913 21:23:00.224154 24276 net.cpp:141] Setting up lstm2_
I0913 21:23:00.224172 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.224182 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.224191 24276 net.cpp:156] Memory required for data: 14008
I0913 21:23:00.224198 24276 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0913 21:23:00.224208 24276 net.cpp:91] Creating Layer lstm2_cont_slice
I0913 21:23:00.224213 24276 net.cpp:425] lstm2_cont_slice <- cont
I0913 21:23:00.224220 24276 net.cpp:399] lstm2_cont_slice -> cont_1
I0913 21:23:00.224261 24276 net.cpp:141] Setting up lstm2_cont_slice
I0913 21:23:00.224272 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.224278 24276 net.cpp:156] Memory required for data: 14012
I0913 21:23:00.224282 24276 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0913 21:23:00.224289 24276 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0913 21:23:00.224294 24276 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0913 21:23:00.224300 24276 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0913 21:23:00.224308 24276 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0913 21:23:00.224354 24276 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0913 21:23:00.224362 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.224369 24276 net.cpp:148] Top shape: 1 1 (1)
I0913 21:23:00.224373 24276 net.cpp:156] Memory required for data: 14020
I0913 21:23:00.224377 24276 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0913 21:23:00.224390 24276 net.cpp:91] Creating Layer lstm2_x_transform
I0913 21:23:00.224395 24276 net.cpp:425] lstm2_x_transform <- x
I0913 21:23:00.224402 24276 net.cpp:399] lstm2_x_transform -> W_xc_x
I0913 21:23:00.281988 24276 net.cpp:141] Setting up lstm2_x_transform
I0913 21:23:00.282040 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.282047 24276 net.cpp:156] Memory required for data: 30020
I0913 21:23:00.282071 24276 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0913 21:23:00.282088 24276 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0913 21:23:00.282095 24276 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0913 21:23:00.282109 24276 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0913 21:23:00.282153 24276 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0913 21:23:00.282162 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.282167 24276 net.cpp:156] Memory required for data: 46020
I0913 21:23:00.282171 24276 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0913 21:23:00.282181 24276 net.cpp:91] Creating Layer lstm2_h_conted_0
I0913 21:23:00.282186 24276 net.cpp:425] lstm2_h_conted_0 <- h_0
I0913 21:23:00.282192 24276 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0913 21:23:00.282202 24276 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0913 21:23:00.282292 24276 net.cpp:141] Setting up lstm2_h_conted_0
I0913 21:23:00.282302 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.282310 24276 net.cpp:156] Memory required for data: 50020
I0913 21:23:00.282318 24276 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0913 21:23:00.282341 24276 net.cpp:91] Creating Layer lstm2_transform_1
I0913 21:23:00.282347 24276 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0913 21:23:00.282356 24276 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0913 21:23:00.320703 24276 net.cpp:141] Setting up lstm2_transform_1
I0913 21:23:00.320771 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.320777 24276 net.cpp:156] Memory required for data: 66020
I0913 21:23:00.320801 24276 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0913 21:23:00.320827 24276 net.cpp:91] Creating Layer lstm2_gate_input_1
I0913 21:23:00.320834 24276 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0913 21:23:00.320843 24276 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0913 21:23:00.320852 24276 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0913 21:23:00.320904 24276 net.cpp:141] Setting up lstm2_gate_input_1
I0913 21:23:00.320914 24276 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:23:00.320919 24276 net.cpp:156] Memory required for data: 82020
I0913 21:23:00.320922 24276 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0913 21:23:00.320935 24276 net.cpp:91] Creating Layer lstm2_unit_1
I0913 21:23:00.320940 24276 net.cpp:425] lstm2_unit_1 <- c_0
I0913 21:23:00.320945 24276 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0913 21:23:00.320950 24276 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0913 21:23:00.320956 24276 net.cpp:399] lstm2_unit_1 -> c_1
I0913 21:23:00.320966 24276 net.cpp:399] lstm2_unit_1 -> h_1
I0913 21:23:00.321027 24276 net.cpp:141] Setting up lstm2_unit_1
I0913 21:23:00.321036 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.321043 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.321048 24276 net.cpp:156] Memory required for data: 90020
I0913 21:23:00.321051 24276 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:23:00.321059 24276 net.cpp:91] Creating Layer lstm2_
I0913 21:23:00.321064 24276 net.cpp:425] lstm2_ <- c_1
I0913 21:23:00.321070 24276 net.cpp:399] lstm2_ -> c_T
I0913 21:23:00.321104 24276 net.cpp:141] Setting up lstm2_
I0913 21:23:00.321111 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.321116 24276 net.cpp:156] Memory required for data: 94020
I0913 21:23:00.321120 24276 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0913 21:23:00.321130 24276 net.cpp:91] Creating Layer lstm2_h_concat
I0913 21:23:00.321135 24276 net.cpp:425] lstm2_h_concat <- h_1
I0913 21:23:00.321141 24276 net.cpp:399] lstm2_h_concat -> h
I0913 21:23:00.321178 24276 net.cpp:141] Setting up lstm2_h_concat
I0913 21:23:00.321187 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.321192 24276 net.cpp:156] Memory required for data: 98020
I0913 21:23:00.321197 24276 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:23:00.321205 24276 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:23:00.321210 24276 net.cpp:425] h_pseudoloss <- h
I0913 21:23:00.321223 24276 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:23:00.321311 24276 net.cpp:141] Setting up h_pseudoloss
I0913 21:23:00.321321 24276 net.cpp:148] Top shape: (1)
I0913 21:23:00.321326 24276 net.cpp:151]     with loss weight 1
I0913 21:23:00.321349 24276 net.cpp:156] Memory required for data: 98024
I0913 21:23:00.321354 24276 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:23:00.321358 24276 net.cpp:217] lstm2_h_concat needs backward computation.
I0913 21:23:00.321362 24276 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:23:00.321367 24276 net.cpp:217] lstm2_unit_1 needs backward computation.
I0913 21:23:00.321372 24276 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0913 21:23:00.321377 24276 net.cpp:217] lstm2_transform_1 needs backward computation.
I0913 21:23:00.321384 24276 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0913 21:23:00.321390 24276 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0913 21:23:00.321394 24276 net.cpp:217] lstm2_x_transform needs backward computation.
I0913 21:23:00.321399 24276 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0913 21:23:00.321404 24276 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0913 21:23:00.321409 24276 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:23:00.321414 24276 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:23:00.321418 24276 net.cpp:261] This network produces output c_T
I0913 21:23:00.321422 24276 net.cpp:261] This network produces output h_pseudoloss
I0913 21:23:00.321436 24276 net.cpp:274] Network initialization done.
I0913 21:23:00.321486 24276 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:23:00.321492 24276 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:23:00.321496 24276 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:23:00.321595 24276 net.cpp:141] Setting up lstm2
I0913 21:23:00.321607 24276 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:23:00.321611 24276 net.cpp:156] Memory required for data: 36412
I0913 21:23:00.321625 24276 layer_factory.hpp:77] Creating layer predict
I0913 21:23:00.321638 24276 net.cpp:91] Creating Layer predict
I0913 21:23:00.321645 24276 net.cpp:425] predict <- lstm2
I0913 21:23:00.321651 24276 net.cpp:399] predict -> predict
I0913 21:23:00.560982 24286 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0913 21:23:00.608095 24286 net.cpp:752] Ignoring source layer loss
Loading the model + trained: 12060.8ms
Using cv::Size and some other stuff: 0.141ms
I0913 21:23:00.800575 24276 net.cpp:141] Setting up predict
I0913 21:23:00.800660 24276 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:23:00.800685 24276 net.cpp:156] Memory required for data: 221084
I0913 21:23:00.800717 24276 layer_factory.hpp:77] Creating layer probs
I0913 21:23:00.800746 24276 net.cpp:91] Creating Layer probs
I0913 21:23:00.800760 24276 net.cpp:425] probs <- predict
I0913 21:23:00.800773 24276 net.cpp:399] probs -> probs
I0913 21:23:00.802103 24276 net.cpp:141] Setting up probs
I0913 21:23:00.802124 24276 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:23:00.802129 24276 net.cpp:156] Memory required for data: 405756
I0913 21:23:00.802136 24276 net.cpp:219] probs does not need backward computation.
I0913 21:23:00.802141 24276 net.cpp:219] predict does not need backward computation.
I0913 21:23:00.802146 24276 net.cpp:219] lstm2 does not need backward computation.
I0913 21:23:00.802152 24276 net.cpp:219] concat does not need backward computation.
I0913 21:23:00.802158 24276 net.cpp:219] lstm1 does not need backward computation.
I0913 21:23:00.802163 24276 net.cpp:219] embedding does not need backward computation.
I0913 21:23:00.802168 24276 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0913 21:23:00.802173 24276 net.cpp:219] reshape_frames does not need backward computation.
I0913 21:23:00.802178 24276 net.cpp:219] embed_encoder does not need backward computation.
I0913 21:23:00.802182 24276 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0913 21:23:00.802187 24276 net.cpp:219] input does not need backward computation.
I0913 21:23:00.802191 24276 net.cpp:261] This network produces output probs
I0913 21:23:00.802208 24276 net.cpp:274] Network initialization done.
Loading the mean file: 1454.59ms
I0913 21:23:01.126726 24276 net.cpp:752] Ignoring source layer data
I0913 21:23:01.126767 24276 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0913 21:23:01.126775 24276 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0913 21:23:01.197317 24276 net.cpp:752] Ignoring source layer cross_entropy_loss
TIMERTIMER 138777109
TIMERTIMER 64175815
TIMERTIMER 72949411
TIMERTIMER 44382590
TIMERTIMER 48526420
TIMERTIMER 48176297
TIMERTIMER 46439869
TIMERTIMER 50038970
TIMERTIMER 47996880
TIMERTIMER 47944241
TIMERTIMER 43293181
TIMERTIMER 54536135
TIMERTIMER 43548281
TIMERTIMER 48327752
TIMERTIMER 47776478
TIMERTIMER 50475551
TIMERTIMER 50246459
TIMERTIMER 42660752
TIMERTIMER 32406245
TIMERTIMER 37895897
TIMERTIMER 32896953
TIMERTIMER 37705627
TIMERTIMER 31790359
TIMERTIMER 31706312
TIMERTIMER 37675006
TIMERTIMER 32221840
TIMERTIMER 31860750
TIMERTIMER 38864704
TIMERTIMER 32259809
TIMERTIMER 33323526
TIMERTIMER 38361271
TIMERTIMER 32307413
TIMERTIMER 33215435
TIMERTIMER 38109262
TIMERTIMER 38039406
TIMERTIMER 31811751
TIMERTIMER 31849096
TIMERTIMER 32001575
TIMERTIMER 31893533
TIMERTIMER 38419065
TIMERTIMER 37917204
TIMERTIMER 31765702
TIMERTIMER 37956732
TIMERTIMER 33158677
TIMERTIMER 33192974
TIMERTIMER 41866811
TIMERTIMER 32131700
TIMERTIMER 32294053
TIMERTIMER 38963389
TIMERTIMER 36234078
TIMERTIMER 39845942
TIMERTIMER 31529905
TIMERTIMER 31743063
TIMERTIMER 37945843
TIMERTIMER 38082665
TIMERTIMER 31892336
TIMERTIMER 37907627
TIMERTIMER 32839296
TIMERTIMER 37941413
TIMERTIMER 31638706
TIMERTIMER 31680030
TIMERTIMER 32258216
TIMERTIMER 37816499
TIMERTIMER 31899155
TIMERTIMER 32636846
TIMERTIMER 31645872
TIMERTIMER 39045957
TIMERTIMER 37181353
TIMERTIMER 31654720
TIMERTIMER 31729207
TIMERTIMER 31786926
TIMERTIMER 37649140
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007f1e602250a0, pid=24209, tid=139765377414912
#
# JRE version: Java(TM) SE Runtime Environment (8.0_77-b03) (build 1.8.0_77-b03)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.77-b03 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libc.so.6+0x980a0]
#
# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again
#
# An error report file with more information is saved as:
# /home/peifeng/work/run/storm102/data/workers/ea79241a-3689-45ef-924f-6af8359cb04a/hs_err_pid24209.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm102/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/work/run/storm102/data/supervisor/stormdist/captioning-1-1473816139/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/peifeng/work/run/storm102/data/workers/ae650dac-cf3a-440e-b406-b3386e1b37a4/tmp/cvld2640389387629224917/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0913 21:24:00.000484 24432 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0913 21:24:00.000669 24432 layer_factory.hpp:77] Creating layer data
I0913 21:24:00.000699 24432 net.cpp:91] Creating Layer data
I0913 21:24:00.000707 24432 net.cpp:399] data -> data
I0913 21:24:00.504254 24432 net.cpp:141] Setting up data
I0913 21:24:00.504346 24432 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0913 21:24:00.504354 24432 net.cpp:156] Memory required for data: 6183480
I0913 21:24:00.504372 24432 layer_factory.hpp:77] Creating layer conv1
I0913 21:24:00.504401 24432 net.cpp:91] Creating Layer conv1
I0913 21:24:00.504418 24432 net.cpp:425] conv1 <- data
I0913 21:24:00.504431 24432 net.cpp:399] conv1 -> conv1
I0913 21:24:00.684934 24432 net.cpp:141] Setting up conv1
I0913 21:24:00.684975 24432 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:24:00.684983 24432 net.cpp:156] Memory required for data: 17799480
I0913 21:24:00.685008 24432 layer_factory.hpp:77] Creating layer relu1
I0913 21:24:00.685025 24432 net.cpp:91] Creating Layer relu1
I0913 21:24:00.685031 24432 net.cpp:425] relu1 <- conv1
I0913 21:24:00.685039 24432 net.cpp:386] relu1 -> conv1 (in-place)
I0913 21:24:00.685415 24432 net.cpp:141] Setting up relu1
I0913 21:24:00.685427 24432 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:24:00.685432 24432 net.cpp:156] Memory required for data: 29415480
I0913 21:24:00.685437 24432 layer_factory.hpp:77] Creating layer pool1
I0913 21:24:00.685448 24432 net.cpp:91] Creating Layer pool1
I0913 21:24:00.685454 24432 net.cpp:425] pool1 <- conv1
I0913 21:24:00.685462 24432 net.cpp:399] pool1 -> pool1
I0913 21:24:00.685530 24432 net.cpp:141] Setting up pool1
I0913 21:24:00.685540 24432 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:24:00.685545 24432 net.cpp:156] Memory required for data: 32214840
I0913 21:24:00.685550 24432 layer_factory.hpp:77] Creating layer norm1
I0913 21:24:00.685565 24432 net.cpp:91] Creating Layer norm1
I0913 21:24:00.685570 24432 net.cpp:425] norm1 <- pool1
I0913 21:24:00.685577 24432 net.cpp:399] norm1 -> norm1
I0913 21:24:00.685827 24432 net.cpp:141] Setting up norm1
I0913 21:24:00.685839 24432 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:24:00.685843 24432 net.cpp:156] Memory required for data: 35014200
I0913 21:24:00.685848 24432 layer_factory.hpp:77] Creating layer conv2
I0913 21:24:00.685861 24432 net.cpp:91] Creating Layer conv2
I0913 21:24:00.685866 24432 net.cpp:425] conv2 <- norm1
I0913 21:24:00.685874 24432 net.cpp:399] conv2 -> conv2
I0913 21:24:00.689640 24432 net.cpp:141] Setting up conv2
I0913 21:24:00.689661 24432 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:24:00.689666 24432 net.cpp:156] Memory required for data: 42479160
I0913 21:24:00.689682 24432 layer_factory.hpp:77] Creating layer relu2
I0913 21:24:00.689690 24432 net.cpp:91] Creating Layer relu2
I0913 21:24:00.689697 24432 net.cpp:425] relu2 <- conv2
I0913 21:24:00.689702 24432 net.cpp:386] relu2 -> conv2 (in-place)
I0913 21:24:00.690091 24432 net.cpp:141] Setting up relu2
I0913 21:24:00.690105 24432 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:24:00.690110 24432 net.cpp:156] Memory required for data: 49944120
I0913 21:24:00.690115 24432 layer_factory.hpp:77] Creating layer pool2
I0913 21:24:00.690124 24432 net.cpp:91] Creating Layer pool2
I0913 21:24:00.690129 24432 net.cpp:425] pool2 <- conv2
I0913 21:24:00.690135 24432 net.cpp:399] pool2 -> pool2
I0913 21:24:00.690192 24432 net.cpp:141] Setting up pool2
I0913 21:24:00.690201 24432 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:24:00.690206 24432 net.cpp:156] Memory required for data: 51674680
I0913 21:24:00.690209 24432 layer_factory.hpp:77] Creating layer norm2
I0913 21:24:00.690222 24432 net.cpp:91] Creating Layer norm2
I0913 21:24:00.690227 24432 net.cpp:425] norm2 <- pool2
I0913 21:24:00.690234 24432 net.cpp:399] norm2 -> norm2
I0913 21:24:00.690481 24432 net.cpp:141] Setting up norm2
I0913 21:24:00.690492 24432 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:24:00.690496 24432 net.cpp:156] Memory required for data: 53405240
I0913 21:24:00.690501 24432 layer_factory.hpp:77] Creating layer conv3
I0913 21:24:00.690515 24432 net.cpp:91] Creating Layer conv3
I0913 21:24:00.690520 24432 net.cpp:425] conv3 <- norm2
I0913 21:24:00.690528 24432 net.cpp:399] conv3 -> conv3
I0913 21:24:00.694375 24432 net.cpp:141] Setting up conv3
I0913 21:24:00.694401 24432 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:24:00.694406 24432 net.cpp:156] Memory required for data: 56001080
I0913 21:24:00.694420 24432 layer_factory.hpp:77] Creating layer relu3
I0913 21:24:00.694433 24432 net.cpp:91] Creating Layer relu3
I0913 21:24:00.694439 24432 net.cpp:425] relu3 <- conv3
I0913 21:24:00.694447 24432 net.cpp:386] relu3 -> conv3 (in-place)
I0913 21:24:00.694667 24432 net.cpp:141] Setting up relu3
I0913 21:24:00.694677 24432 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:24:00.694682 24432 net.cpp:156] Memory required for data: 58596920
I0913 21:24:00.694686 24432 layer_factory.hpp:77] Creating layer conv4
I0913 21:24:00.694702 24432 net.cpp:91] Creating Layer conv4
I0913 21:24:00.694707 24432 net.cpp:425] conv4 <- conv3
I0913 21:24:00.694715 24432 net.cpp:399] conv4 -> conv4
I0913 21:24:00.698709 24432 net.cpp:141] Setting up conv4
I0913 21:24:00.698734 24432 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:24:00.698740 24432 net.cpp:156] Memory required for data: 61192760
I0913 21:24:00.698748 24432 layer_factory.hpp:77] Creating layer relu4
I0913 21:24:00.698758 24432 net.cpp:91] Creating Layer relu4
I0913 21:24:00.698763 24432 net.cpp:425] relu4 <- conv4
I0913 21:24:00.698773 24432 net.cpp:386] relu4 -> conv4 (in-place)
I0913 21:24:00.699151 24432 net.cpp:141] Setting up relu4
I0913 21:24:00.699162 24432 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:24:00.699167 24432 net.cpp:156] Memory required for data: 63788600
I0913 21:24:00.699170 24432 layer_factory.hpp:77] Creating layer conv5
I0913 21:24:00.699187 24432 net.cpp:91] Creating Layer conv5
I0913 21:24:00.699192 24432 net.cpp:425] conv5 <- conv4
I0913 21:24:00.699198 24432 net.cpp:399] conv5 -> conv5
I0913 21:24:00.702775 24432 net.cpp:141] Setting up conv5
I0913 21:24:00.702793 24432 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:24:00.702798 24432 net.cpp:156] Memory required for data: 65519160
I0913 21:24:00.702816 24432 layer_factory.hpp:77] Creating layer relu5
I0913 21:24:00.702824 24432 net.cpp:91] Creating Layer relu5
I0913 21:24:00.702829 24432 net.cpp:425] relu5 <- conv5
I0913 21:24:00.702837 24432 net.cpp:386] relu5 -> conv5 (in-place)
I0913 21:24:00.703233 24432 net.cpp:141] Setting up relu5
I0913 21:24:00.703245 24432 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:24:00.703250 24432 net.cpp:156] Memory required for data: 67249720
I0913 21:24:00.703254 24432 layer_factory.hpp:77] Creating layer pool5
I0913 21:24:00.703264 24432 net.cpp:91] Creating Layer pool5
I0913 21:24:00.703269 24432 net.cpp:425] pool5 <- conv5
I0913 21:24:00.703279 24432 net.cpp:399] pool5 -> pool5
I0913 21:24:00.703336 24432 net.cpp:141] Setting up pool5
I0913 21:24:00.703346 24432 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0913 21:24:00.703349 24432 net.cpp:156] Memory required for data: 67618360
I0913 21:24:00.703353 24432 layer_factory.hpp:77] Creating layer fc6
I0913 21:24:00.703364 24432 net.cpp:91] Creating Layer fc6
I0913 21:24:00.703369 24432 net.cpp:425] fc6 <- pool5
I0913 21:24:00.703378 24432 net.cpp:399] fc6 -> fc6
I0913 21:24:00.804533 24432 net.cpp:141] Setting up fc6
I0913 21:24:00.804576 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.804582 24432 net.cpp:156] Memory required for data: 67782200
I0913 21:24:00.804595 24432 layer_factory.hpp:77] Creating layer relu6
I0913 21:24:00.804611 24432 net.cpp:91] Creating Layer relu6
I0913 21:24:00.804618 24432 net.cpp:425] relu6 <- fc6
I0913 21:24:00.804626 24432 net.cpp:386] relu6 -> fc6 (in-place)
I0913 21:24:00.804936 24432 net.cpp:141] Setting up relu6
I0913 21:24:00.804947 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.804952 24432 net.cpp:156] Memory required for data: 67946040
I0913 21:24:00.804957 24432 layer_factory.hpp:77] Creating layer drop6
I0913 21:24:00.804976 24432 net.cpp:91] Creating Layer drop6
I0913 21:24:00.804981 24432 net.cpp:425] drop6 <- fc6
I0913 21:24:00.804991 24432 net.cpp:386] drop6 -> fc6 (in-place)
I0913 21:24:00.805034 24432 net.cpp:141] Setting up drop6
I0913 21:24:00.805042 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.805047 24432 net.cpp:156] Memory required for data: 68109880
I0913 21:24:00.805052 24432 layer_factory.hpp:77] Creating layer fc7
I0913 21:24:00.805065 24432 net.cpp:91] Creating Layer fc7
I0913 21:24:00.805069 24432 net.cpp:425] fc7 <- fc6
I0913 21:24:00.805076 24432 net.cpp:399] fc7 -> fc7
I0913 21:24:00.849625 24432 net.cpp:141] Setting up fc7
I0913 21:24:00.849676 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.849683 24432 net.cpp:156] Memory required for data: 68273720
I0913 21:24:00.849694 24432 layer_factory.hpp:77] Creating layer relu7
I0913 21:24:00.849711 24432 net.cpp:91] Creating Layer relu7
I0913 21:24:00.849719 24432 net.cpp:425] relu7 <- fc7
I0913 21:24:00.849725 24432 net.cpp:386] relu7 -> fc7 (in-place)
I0913 21:24:00.850303 24432 net.cpp:141] Setting up relu7
I0913 21:24:00.850318 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.850322 24432 net.cpp:156] Memory required for data: 68437560
I0913 21:24:00.850327 24432 layer_factory.hpp:77] Creating layer drop7
I0913 21:24:00.850337 24432 net.cpp:91] Creating Layer drop7
I0913 21:24:00.850342 24432 net.cpp:425] drop7 <- fc7
I0913 21:24:00.850347 24432 net.cpp:386] drop7 -> fc7 (in-place)
I0913 21:24:00.850389 24432 net.cpp:141] Setting up drop7
I0913 21:24:00.850397 24432 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:24:00.850402 24432 net.cpp:156] Memory required for data: 68601400
I0913 21:24:00.850406 24432 layer_factory.hpp:77] Creating layer fc8
I0913 21:24:00.850420 24432 net.cpp:91] Creating Layer fc8
I0913 21:24:00.850425 24432 net.cpp:425] fc8 <- fc7
I0913 21:24:00.850431 24432 net.cpp:399] fc8 -> fc8
I0913 21:24:00.861380 24432 net.cpp:141] Setting up fc8
I0913 21:24:00.861420 24432 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:24:00.861426 24432 net.cpp:156] Memory required for data: 68641400
I0913 21:24:00.861438 24432 layer_factory.hpp:77] Creating layer prob
I0913 21:24:00.861452 24432 net.cpp:91] Creating Layer prob
I0913 21:24:00.861459 24432 net.cpp:425] prob <- fc8
I0913 21:24:00.861474 24432 net.cpp:399] prob -> prob
I0913 21:24:00.861866 24432 net.cpp:141] Setting up prob
I0913 21:24:00.861877 24432 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:24:00.861881 24432 net.cpp:156] Memory required for data: 68681400
I0913 21:24:00.861887 24432 net.cpp:219] prob does not need backward computation.
I0913 21:24:00.861891 24432 net.cpp:219] fc8 does not need backward computation.
I0913 21:24:00.861896 24432 net.cpp:219] drop7 does not need backward computation.
I0913 21:24:00.861901 24432 net.cpp:219] relu7 does not need backward computation.
I0913 21:24:00.861904 24432 net.cpp:219] fc7 does not need backward computation.
I0913 21:24:00.861908 24432 net.cpp:219] drop6 does not need backward computation.
I0913 21:24:00.861912 24432 net.cpp:219] relu6 does not need backward computation.
I0913 21:24:00.861917 24432 net.cpp:219] fc6 does not need backward computation.
I0913 21:24:00.861920 24432 net.cpp:219] pool5 does not need backward computation.
I0913 21:24:00.861925 24432 net.cpp:219] relu5 does not need backward computation.
I0913 21:24:00.861929 24432 net.cpp:219] conv5 does not need backward computation.
I0913 21:24:00.861933 24432 net.cpp:219] relu4 does not need backward computation.
I0913 21:24:00.861937 24432 net.cpp:219] conv4 does not need backward computation.
I0913 21:24:00.861941 24432 net.cpp:219] relu3 does not need backward computation.
I0913 21:24:00.861945 24432 net.cpp:219] conv3 does not need backward computation.
I0913 21:24:00.861949 24432 net.cpp:219] norm2 does not need backward computation.
I0913 21:24:00.861954 24432 net.cpp:219] pool2 does not need backward computation.
I0913 21:24:00.861958 24432 net.cpp:219] relu2 does not need backward computation.
I0913 21:24:00.861963 24432 net.cpp:219] conv2 does not need backward computation.
I0913 21:24:00.861966 24432 net.cpp:219] norm1 does not need backward computation.
I0913 21:24:00.861970 24432 net.cpp:219] pool1 does not need backward computation.
I0913 21:24:00.861975 24432 net.cpp:219] relu1 does not need backward computation.
I0913 21:24:00.861979 24432 net.cpp:219] conv1 does not need backward computation.
I0913 21:24:00.861984 24432 net.cpp:219] data does not need backward computation.
I0913 21:24:00.861986 24432 net.cpp:261] This network produces output prob
I0913 21:24:00.862020 24432 net.cpp:274] Network initialization done.
I0913 21:24:00.894968 24422 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /home/peifeng/work/run/storm102/data/workers/ae650dac-cf3a-440e-b406-b3386e1b37a4/tmp/cvld2640389387629224917/s2vt.words_to_preds.prototxt
I0913 21:24:00.895025 24422 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0913 21:24:00.895032 24422 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0913 21:24:00.895301 24422 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0913 21:24:00.895402 24422 layer_factory.hpp:77] Creating layer input
I0913 21:24:00.895419 24422 net.cpp:91] Creating Layer input
I0913 21:24:00.895426 24422 net.cpp:399] input -> frames_fc7
I0913 21:24:00.895447 24422 net.cpp:399] input -> cont_sentence
I0913 21:24:00.895457 24422 net.cpp:399] input -> input_sentence
I0913 21:24:00.895467 24422 net.cpp:399] input -> stage_indicator
I0913 21:24:00.895582 24422 net.cpp:141] Setting up input
I0913 21:24:00.895594 24422 net.cpp:148] Top shape: 1 4096 (4096)
I0913 21:24:00.895601 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:00.895606 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:00.895611 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:00.895614 24422 net.cpp:156] Memory required for data: 16396
I0913 21:24:00.895620 24422 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0913 21:24:00.895630 24422 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0913 21:24:00.895635 24422 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0913 21:24:00.895650 24422 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0913 21:24:00.895659 24422 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0913 21:24:00.895705 24422 net.cpp:141] Setting up cont_sentence_input_1_split
I0913 21:24:00.895715 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:00.895721 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:00.895725 24422 net.cpp:156] Memory required for data: 16404
I0913 21:24:00.895730 24422 layer_factory.hpp:77] Creating layer embed_encoder
I0913 21:24:00.895741 24422 net.cpp:91] Creating Layer embed_encoder
I0913 21:24:00.895746 24422 net.cpp:425] embed_encoder <- frames_fc7
I0913 21:24:00.895754 24422 net.cpp:399] embed_encoder -> embedded_in_frames
I0913 21:24:00.916012 24422 net.cpp:141] Setting up embed_encoder
I0913 21:24:00.916077 24422 net.cpp:148] Top shape: 1 500 (500)
I0913 21:24:00.916085 24422 net.cpp:156] Memory required for data: 18404
I0913 21:24:00.916105 24422 layer_factory.hpp:77] Creating layer reshape_frames
I0913 21:24:00.916126 24422 net.cpp:91] Creating Layer reshape_frames
I0913 21:24:00.916133 24422 net.cpp:425] reshape_frames <- embedded_in_frames
I0913 21:24:00.916146 24422 net.cpp:399] reshape_frames -> embedded_input_frames
I0913 21:24:00.916205 24422 net.cpp:141] Setting up reshape_frames
I0913 21:24:00.916214 24422 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:24:00.916218 24422 net.cpp:156] Memory required for data: 20404
I0913 21:24:00.916223 24422 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0913 21:24:00.916232 24422 net.cpp:91] Creating Layer reshape_stage_indicator
I0913 21:24:00.916237 24422 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0913 21:24:00.916245 24422 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0913 21:24:00.916286 24422 net.cpp:141] Setting up reshape_stage_indicator
I0913 21:24:00.916295 24422 net.cpp:148] Top shape: 1 1 1 (1)
I0913 21:24:00.916298 24422 net.cpp:156] Memory required for data: 20408
I0913 21:24:00.916302 24422 layer_factory.hpp:77] Creating layer embedding
I0913 21:24:00.916316 24422 net.cpp:91] Creating Layer embedding
I0913 21:24:00.916319 24422 net.cpp:425] embedding <- input_sentence
I0913 21:24:00.916326 24422 net.cpp:399] embedding -> embedded_input_sentence
I0913 21:24:01.121129 24432 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/peifeng/work/run/storm102/data/workers/ae650dac-cf3a-440e-b406-b3386e1b37a4/tmp/cvld2640389387629224917/bvlc_reference_caffenet.caffemodel
I0913 21:24:01.121179 24432 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0913 21:24:01.121186 24432 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0913 21:24:01.121191 24432 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/peifeng/work/run/storm102/data/workers/ae650dac-cf3a-440e-b406-b3386e1b37a4/tmp/cvld2640389387629224917/bvlc_reference_caffenet.caffemodel
I0913 21:24:01.138043 24422 net.cpp:141] Setting up embedding
I0913 21:24:01.138100 24422 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:24:01.138106 24422 net.cpp:156] Memory required for data: 22408
I0913 21:24:01.138124 24422 layer_factory.hpp:77] Creating layer lstm1
I0913 21:24:01.138159 24422 net.cpp:91] Creating Layer lstm1
I0913 21:24:01.138167 24422 net.cpp:425] lstm1 <- embedded_input_frames
I0913 21:24:01.138175 24422 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0913 21:24:01.138187 24422 net.cpp:399] lstm1 -> lstm1
I0913 21:24:01.138216 24422 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:24:01.138604 24422 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:24:01.138697 24422 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:24:01.138710 24422 net.cpp:91] Creating Layer lstm1_
I0913 21:24:01.138715 24422 net.cpp:399] lstm1_ -> x
I0913 21:24:01.138726 24422 net.cpp:399] lstm1_ -> cont
I0913 21:24:01.138788 24422 net.cpp:141] Setting up lstm1_
I0913 21:24:01.138797 24422 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:24:01.138803 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.138808 24422 net.cpp:156] Memory required for data: 2004
I0913 21:24:01.138811 24422 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:24:01.138819 24422 net.cpp:91] Creating Layer lstm1_
I0913 21:24:01.138828 24422 net.cpp:399] lstm1_ -> c_0
I0913 21:24:01.138837 24422 net.cpp:399] lstm1_ -> h_0
I0913 21:24:01.138885 24422 net.cpp:141] Setting up lstm1_
I0913 21:24:01.138893 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.138900 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.138903 24422 net.cpp:156] Memory required for data: 10004
I0913 21:24:01.138907 24422 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0913 21:24:01.138918 24422 net.cpp:91] Creating Layer lstm1_cont_slice
I0913 21:24:01.138923 24422 net.cpp:425] lstm1_cont_slice <- cont
I0913 21:24:01.138929 24422 net.cpp:399] lstm1_cont_slice -> cont_1
I0913 21:24:01.138965 24422 net.cpp:141] Setting up lstm1_cont_slice
I0913 21:24:01.138974 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.138978 24422 net.cpp:156] Memory required for data: 10008
I0913 21:24:01.138983 24422 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0913 21:24:01.138989 24422 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0913 21:24:01.138993 24422 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0913 21:24:01.139003 24422 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0913 21:24:01.139010 24422 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0913 21:24:01.139056 24422 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0913 21:24:01.139065 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.139070 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.139073 24422 net.cpp:156] Memory required for data: 10016
I0913 21:24:01.139078 24422 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0913 21:24:01.139091 24422 net.cpp:91] Creating Layer lstm1_x_transform
I0913 21:24:01.139094 24422 net.cpp:425] lstm1_x_transform <- x
I0913 21:24:01.139101 24422 net.cpp:399] lstm1_x_transform -> W_xc_x
I0913 21:24:01.158159 24422 net.cpp:141] Setting up lstm1_x_transform
I0913 21:24:01.158207 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.158213 24422 net.cpp:156] Memory required for data: 26016
I0913 21:24:01.158236 24422 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0913 21:24:01.158257 24422 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0913 21:24:01.158263 24422 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0913 21:24:01.158272 24422 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0913 21:24:01.158315 24422 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0913 21:24:01.158324 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.158329 24422 net.cpp:156] Memory required for data: 42016
I0913 21:24:01.158332 24422 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0913 21:24:01.158345 24422 net.cpp:91] Creating Layer lstm1_h_conted_0
I0913 21:24:01.158350 24422 net.cpp:425] lstm1_h_conted_0 <- h_0
I0913 21:24:01.158356 24422 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0913 21:24:01.158363 24422 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0913 21:24:01.158458 24422 net.cpp:141] Setting up lstm1_h_conted_0
I0913 21:24:01.158468 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.158473 24422 net.cpp:156] Memory required for data: 46016
I0913 21:24:01.158476 24422 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0913 21:24:01.158493 24422 net.cpp:91] Creating Layer lstm1_transform_1
I0913 21:24:01.158499 24422 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0913 21:24:01.158506 24422 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0913 21:24:01.196334 24422 net.cpp:141] Setting up lstm1_transform_1
I0913 21:24:01.196389 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.196395 24422 net.cpp:156] Memory required for data: 62016
I0913 21:24:01.196419 24422 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0913 21:24:01.196444 24422 net.cpp:91] Creating Layer lstm1_gate_input_1
I0913 21:24:01.196451 24422 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0913 21:24:01.196460 24422 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0913 21:24:01.196466 24422 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0913 21:24:01.196526 24422 net.cpp:141] Setting up lstm1_gate_input_1
I0913 21:24:01.196533 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.196537 24422 net.cpp:156] Memory required for data: 78016
I0913 21:24:01.196542 24422 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0913 21:24:01.196554 24422 net.cpp:91] Creating Layer lstm1_unit_1
I0913 21:24:01.196559 24422 net.cpp:425] lstm1_unit_1 <- c_0
I0913 21:24:01.196564 24422 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0913 21:24:01.196569 24422 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0913 21:24:01.196576 24422 net.cpp:399] lstm1_unit_1 -> c_1
I0913 21:24:01.196584 24422 net.cpp:399] lstm1_unit_1 -> h_1
I0913 21:24:01.196645 24422 net.cpp:141] Setting up lstm1_unit_1
I0913 21:24:01.196653 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.196660 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.196663 24422 net.cpp:156] Memory required for data: 86016
I0913 21:24:01.196667 24422 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:24:01.196678 24422 net.cpp:91] Creating Layer lstm1_
I0913 21:24:01.196682 24422 net.cpp:425] lstm1_ <- c_1
I0913 21:24:01.196689 24422 net.cpp:399] lstm1_ -> c_T
I0913 21:24:01.196718 24422 net.cpp:141] Setting up lstm1_
I0913 21:24:01.196727 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.196730 24422 net.cpp:156] Memory required for data: 90016
I0913 21:24:01.196734 24422 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0913 21:24:01.196756 24422 net.cpp:91] Creating Layer lstm1_h_concat
I0913 21:24:01.196761 24422 net.cpp:425] lstm1_h_concat <- h_1
I0913 21:24:01.196770 24422 net.cpp:399] lstm1_h_concat -> h
I0913 21:24:01.196805 24422 net.cpp:141] Setting up lstm1_h_concat
I0913 21:24:01.196812 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.196816 24422 net.cpp:156] Memory required for data: 94016
I0913 21:24:01.196820 24422 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:24:01.196837 24422 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:24:01.196841 24422 net.cpp:425] h_pseudoloss <- h
I0913 21:24:01.196847 24422 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:24:01.196940 24422 net.cpp:141] Setting up h_pseudoloss
I0913 21:24:01.196950 24422 net.cpp:148] Top shape: (1)
I0913 21:24:01.196954 24422 net.cpp:151]     with loss weight 1
I0913 21:24:01.196995 24422 net.cpp:156] Memory required for data: 94020
I0913 21:24:01.197000 24422 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:24:01.197005 24422 net.cpp:217] lstm1_h_concat needs backward computation.
I0913 21:24:01.197008 24422 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:24:01.197013 24422 net.cpp:217] lstm1_unit_1 needs backward computation.
I0913 21:24:01.197018 24422 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0913 21:24:01.197023 24422 net.cpp:217] lstm1_transform_1 needs backward computation.
I0913 21:24:01.197027 24422 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0913 21:24:01.197033 24422 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0913 21:24:01.197037 24422 net.cpp:217] lstm1_x_transform needs backward computation.
I0913 21:24:01.197042 24422 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0913 21:24:01.197046 24422 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0913 21:24:01.197052 24422 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:24:01.197055 24422 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:24:01.197058 24422 net.cpp:261] This network produces output c_T
I0913 21:24:01.197062 24422 net.cpp:261] This network produces output h_pseudoloss
I0913 21:24:01.197077 24422 net.cpp:274] Network initialization done.
I0913 21:24:01.197129 24422 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:24:01.197134 24422 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:24:01.197139 24422 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:24:01.197242 24422 net.cpp:141] Setting up lstm1
I0913 21:24:01.197253 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.197257 24422 net.cpp:156] Memory required for data: 26408
I0913 21:24:01.197270 24422 layer_factory.hpp:77] Creating layer concat
I0913 21:24:01.197278 24422 net.cpp:91] Creating Layer concat
I0913 21:24:01.197284 24422 net.cpp:425] concat <- lstm1
I0913 21:24:01.197290 24422 net.cpp:425] concat <- embedded_input_sentence
I0913 21:24:01.197295 24422 net.cpp:425] concat <- reshaped_stage_indicator
I0913 21:24:01.197301 24422 net.cpp:399] concat -> lstm1_video_sequence
I0913 21:24:01.197334 24422 net.cpp:141] Setting up concat
I0913 21:24:01.197341 24422 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:24:01.197345 24422 net.cpp:156] Memory required for data: 32412
I0913 21:24:01.197350 24422 layer_factory.hpp:77] Creating layer lstm2
I0913 21:24:01.197362 24422 net.cpp:91] Creating Layer lstm2
I0913 21:24:01.197367 24422 net.cpp:425] lstm2 <- lstm1_video_sequence
I0913 21:24:01.197372 24422 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0913 21:24:01.197379 24422 net.cpp:399] lstm2 -> lstm2
I0913 21:24:01.197389 24422 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:24:01.197659 24422 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:24:01.197752 24422 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:24:01.197770 24422 net.cpp:91] Creating Layer lstm2_
I0913 21:24:01.197780 24422 net.cpp:399] lstm2_ -> x
I0913 21:24:01.197791 24422 net.cpp:399] lstm2_ -> cont
I0913 21:24:01.197847 24422 net.cpp:141] Setting up lstm2_
I0913 21:24:01.197856 24422 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:24:01.197862 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.197866 24422 net.cpp:156] Memory required for data: 6008
I0913 21:24:01.197870 24422 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:24:01.197878 24422 net.cpp:91] Creating Layer lstm2_
I0913 21:24:01.197886 24422 net.cpp:399] lstm2_ -> c_0
I0913 21:24:01.197896 24422 net.cpp:399] lstm2_ -> h_0
I0913 21:24:01.197944 24422 net.cpp:141] Setting up lstm2_
I0913 21:24:01.197952 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.197958 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.197962 24422 net.cpp:156] Memory required for data: 14008
I0913 21:24:01.197967 24422 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0913 21:24:01.197974 24422 net.cpp:91] Creating Layer lstm2_cont_slice
I0913 21:24:01.197979 24422 net.cpp:425] lstm2_cont_slice <- cont
I0913 21:24:01.197985 24422 net.cpp:399] lstm2_cont_slice -> cont_1
I0913 21:24:01.198019 24422 net.cpp:141] Setting up lstm2_cont_slice
I0913 21:24:01.198029 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.198032 24422 net.cpp:156] Memory required for data: 14012
I0913 21:24:01.198036 24422 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0913 21:24:01.198045 24422 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0913 21:24:01.198050 24422 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0913 21:24:01.198055 24422 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0913 21:24:01.198062 24422 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0913 21:24:01.198107 24422 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0913 21:24:01.198115 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.198120 24422 net.cpp:148] Top shape: 1 1 (1)
I0913 21:24:01.198124 24422 net.cpp:156] Memory required for data: 14020
I0913 21:24:01.198128 24422 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0913 21:24:01.198137 24422 net.cpp:91] Creating Layer lstm2_x_transform
I0913 21:24:01.198143 24422 net.cpp:425] lstm2_x_transform <- x
I0913 21:24:01.198153 24422 net.cpp:399] lstm2_x_transform -> W_xc_x
I0913 21:24:01.255157 24422 net.cpp:141] Setting up lstm2_x_transform
I0913 21:24:01.255223 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.255228 24422 net.cpp:156] Memory required for data: 30020
I0913 21:24:01.255250 24422 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0913 21:24:01.255270 24422 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0913 21:24:01.255276 24422 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0913 21:24:01.255290 24422 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0913 21:24:01.255336 24422 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0913 21:24:01.255344 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.255349 24422 net.cpp:156] Memory required for data: 46020
I0913 21:24:01.255353 24422 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0913 21:24:01.255364 24422 net.cpp:91] Creating Layer lstm2_h_conted_0
I0913 21:24:01.255369 24422 net.cpp:425] lstm2_h_conted_0 <- h_0
I0913 21:24:01.255375 24422 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0913 21:24:01.255383 24422 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0913 21:24:01.255473 24422 net.cpp:141] Setting up lstm2_h_conted_0
I0913 21:24:01.255482 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.255486 24422 net.cpp:156] Memory required for data: 50020
I0913 21:24:01.255491 24422 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0913 21:24:01.255502 24422 net.cpp:91] Creating Layer lstm2_transform_1
I0913 21:24:01.255507 24422 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0913 21:24:01.255517 24422 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0913 21:24:01.298481 24422 net.cpp:141] Setting up lstm2_transform_1
I0913 21:24:01.298535 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.298542 24422 net.cpp:156] Memory required for data: 66020
I0913 21:24:01.298563 24422 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0913 21:24:01.298589 24422 net.cpp:91] Creating Layer lstm2_gate_input_1
I0913 21:24:01.298598 24422 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0913 21:24:01.298605 24422 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0913 21:24:01.298614 24422 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0913 21:24:01.298666 24422 net.cpp:141] Setting up lstm2_gate_input_1
I0913 21:24:01.298674 24422 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:24:01.298678 24422 net.cpp:156] Memory required for data: 82020
I0913 21:24:01.298683 24422 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0913 21:24:01.298691 24422 net.cpp:91] Creating Layer lstm2_unit_1
I0913 21:24:01.298696 24422 net.cpp:425] lstm2_unit_1 <- c_0
I0913 21:24:01.298702 24422 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0913 21:24:01.298707 24422 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0913 21:24:01.298717 24422 net.cpp:399] lstm2_unit_1 -> c_1
I0913 21:24:01.298725 24422 net.cpp:399] lstm2_unit_1 -> h_1
I0913 21:24:01.298786 24422 net.cpp:141] Setting up lstm2_unit_1
I0913 21:24:01.298795 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.298801 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.298805 24422 net.cpp:156] Memory required for data: 90020
I0913 21:24:01.298810 24422 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:24:01.298817 24422 net.cpp:91] Creating Layer lstm2_
I0913 21:24:01.298821 24422 net.cpp:425] lstm2_ <- c_1
I0913 21:24:01.298827 24422 net.cpp:399] lstm2_ -> c_T
I0913 21:24:01.298859 24422 net.cpp:141] Setting up lstm2_
I0913 21:24:01.298868 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.298872 24422 net.cpp:156] Memory required for data: 94020
I0913 21:24:01.298877 24422 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0913 21:24:01.298887 24422 net.cpp:91] Creating Layer lstm2_h_concat
I0913 21:24:01.298892 24422 net.cpp:425] lstm2_h_concat <- h_1
I0913 21:24:01.298898 24422 net.cpp:399] lstm2_h_concat -> h
I0913 21:24:01.298933 24422 net.cpp:141] Setting up lstm2_h_concat
I0913 21:24:01.298941 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.298945 24422 net.cpp:156] Memory required for data: 98020
I0913 21:24:01.298950 24422 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:24:01.298959 24422 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:24:01.298964 24422 net.cpp:425] h_pseudoloss <- h
I0913 21:24:01.298969 24422 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:24:01.299057 24422 net.cpp:141] Setting up h_pseudoloss
I0913 21:24:01.299067 24422 net.cpp:148] Top shape: (1)
I0913 21:24:01.299070 24422 net.cpp:151]     with loss weight 1
I0913 21:24:01.299088 24422 net.cpp:156] Memory required for data: 98024
I0913 21:24:01.299093 24422 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:24:01.299099 24422 net.cpp:217] lstm2_h_concat needs backward computation.
I0913 21:24:01.299103 24422 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:24:01.299108 24422 net.cpp:217] lstm2_unit_1 needs backward computation.
I0913 21:24:01.299113 24422 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0913 21:24:01.299118 24422 net.cpp:217] lstm2_transform_1 needs backward computation.
I0913 21:24:01.299123 24422 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0913 21:24:01.299127 24422 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0913 21:24:01.299131 24422 net.cpp:217] lstm2_x_transform needs backward computation.
I0913 21:24:01.299136 24422 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0913 21:24:01.299140 24422 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0913 21:24:01.299149 24422 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:24:01.299152 24422 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:24:01.299155 24422 net.cpp:261] This network produces output c_T
I0913 21:24:01.299160 24422 net.cpp:261] This network produces output h_pseudoloss
I0913 21:24:01.299173 24422 net.cpp:274] Network initialization done.
I0913 21:24:01.299222 24422 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:24:01.299228 24422 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:24:01.299232 24422 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:24:01.299330 24422 net.cpp:141] Setting up lstm2
I0913 21:24:01.299341 24422 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:24:01.299345 24422 net.cpp:156] Memory required for data: 36412
I0913 21:24:01.299357 24422 layer_factory.hpp:77] Creating layer predict
I0913 21:24:01.299371 24422 net.cpp:91] Creating Layer predict
I0913 21:24:01.299376 24422 net.cpp:425] predict <- lstm2
I0913 21:24:01.299383 24422 net.cpp:399] predict -> predict
I0913 21:24:01.549669 24432 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0913 21:24:01.596670 24432 net.cpp:752] Ignoring source layer loss
Loading the model + trained: 10009.4ms
Using cv::Size and some other stuff: 0.147ms
I0913 21:24:01.754622 24422 net.cpp:141] Setting up predict
I0913 21:24:01.754673 24422 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:24:01.754679 24422 net.cpp:156] Memory required for data: 221084
I0913 21:24:01.754693 24422 layer_factory.hpp:77] Creating layer probs
I0913 21:24:01.754714 24422 net.cpp:91] Creating Layer probs
I0913 21:24:01.754720 24422 net.cpp:425] probs <- predict
I0913 21:24:01.754730 24422 net.cpp:399] probs -> probs
I0913 21:24:01.762074 24422 net.cpp:141] Setting up probs
I0913 21:24:01.762135 24422 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:24:01.762140 24422 net.cpp:156] Memory required for data: 405756
I0913 21:24:01.762151 24422 net.cpp:219] probs does not need backward computation.
I0913 21:24:01.762157 24422 net.cpp:219] predict does not need backward computation.
I0913 21:24:01.762163 24422 net.cpp:219] lstm2 does not need backward computation.
I0913 21:24:01.762168 24422 net.cpp:219] concat does not need backward computation.
I0913 21:24:01.762174 24422 net.cpp:219] lstm1 does not need backward computation.
I0913 21:24:01.762181 24422 net.cpp:219] embedding does not need backward computation.
I0913 21:24:01.762186 24422 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0913 21:24:01.762190 24422 net.cpp:219] reshape_frames does not need backward computation.
I0913 21:24:01.762194 24422 net.cpp:219] embed_encoder does not need backward computation.
I0913 21:24:01.762199 24422 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0913 21:24:01.762204 24422 net.cpp:219] input does not need backward computation.
I0913 21:24:01.762207 24422 net.cpp:261] This network produces output probs
I0913 21:24:01.762272 24422 net.cpp:274] Network initialization done.
Loading the mean file: 1546.38ms
I0913 21:24:02.097903 24422 net.cpp:752] Ignoring source layer data
I0913 21:24:02.097941 24422 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0913 21:24:02.097946 24422 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0913 21:24:02.163920 24422 net.cpp:752] Ignoring source layer cross_entropy_loss
TIMERTIMER 121448409
TIMERTIMER 62274972
TIMERTIMER 67385412
TIMERTIMER 41291433
TIMERTIMER 48501240
TIMERTIMER 48601064
TIMERTIMER 42903570
TIMERTIMER 42268105
TIMERTIMER 48127692
TIMERTIMER 47533869
TIMERTIMER 49703160
TIMERTIMER 48278032
TIMERTIMER 48990954
TIMERTIMER 48255831
TIMERTIMER 47345701
TIMERTIMER 45568588
TIMERTIMER 47720434
TIMERTIMER 43864440
TIMERTIMER 31660542
TIMERTIMER 37885452
TIMERTIMER 31495518
TIMERTIMER 31853677
TIMERTIMER 31643959
TIMERTIMER 31599754
TIMERTIMER 31523425
TIMERTIMER 34905063
TIMERTIMER 31788249
TIMERTIMER 37523319
TIMERTIMER 32254595
TIMERTIMER 32136215
TIMERTIMER 33647129
TIMERTIMER 38656434
TIMERTIMER 31391201
TIMERTIMER 31360742
TIMERTIMER 31367649
TIMERTIMER 31404071
TIMERTIMER 31335781
TIMERTIMER 37628593
TIMERTIMER 31390247
TIMERTIMER 33135655
TIMERTIMER 31474870
TIMERTIMER 31348884
TIMERTIMER 37451611
TIMERTIMER 31370692
TIMERTIMER 31311895
TIMERTIMER 37931490
TIMERTIMER 37360756
TIMERTIMER 31276116
TIMERTIMER 37374060
TIMERTIMER 32535237
TIMERTIMER 38285871
TIMERTIMER 37413233
TIMERTIMER 37004117
TIMERTIMER 31144028
TIMERTIMER 31264426
TIMERTIMER 37718544
TIMERTIMER 31718073
TIMERTIMER 37758789
TIMERTIMER 34505195
TIMERTIMER 38054578
TIMERTIMER 32223186
TIMERTIMER 37383287
TIMERTIMER 31337493
TIMERTIMER 37493939
TIMERTIMER 38381410
TIMERTIMER 37161381
TIMERTIMER 32030511
TIMERTIMER 46458992
TIMERTIMER 31356679
TIMERTIMER 32490752
TIMERTIMER 31140912
TIMERTIMER 31326157
TIMERTIMER 31787294
TIMERTIMER 31482032
TIMERTIMER 38127838
TIMERTIMER 39101739
TIMERTIMER 33378596
TIMERTIMER 31634450
TIMERTIMER 33484220
TIMERTIMER 38325240
TIMERTIMER 32585987
TIMERTIMER 33023291
TIMERTIMER 31969683
TIMERTIMER 39080879
TIMERTIMER 31673599
TIMERTIMER 39455290
TIMERTIMER 33768161
TIMERTIMER 39564139
TIMERTIMER 38899072
TIMERTIMER 38871308
TIMERTIMER 31461484
TIMERTIMER 31529537
