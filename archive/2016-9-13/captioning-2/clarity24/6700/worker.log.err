SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm102/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/work/run/storm102/data/supervisor/stormdist/captioning-1-1473814855/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/peifeng/work/run/storm102/data/workers/a927c850-2619-4aed-baaf-4e60244d38a4/tmp/cvld3058852401212334555/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0913 21:01:35.388700 11876 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0913 21:01:35.388895 11876 layer_factory.hpp:77] Creating layer data
I0913 21:01:35.388921 11876 net.cpp:91] Creating Layer data
I0913 21:01:35.388931 11876 net.cpp:399] data -> data
I0913 21:01:35.915678 11876 net.cpp:141] Setting up data
I0913 21:01:35.915781 11876 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0913 21:01:35.915789 11876 net.cpp:156] Memory required for data: 6183480
I0913 21:01:35.915810 11876 layer_factory.hpp:77] Creating layer conv1
I0913 21:01:35.915843 11876 net.cpp:91] Creating Layer conv1
I0913 21:01:35.915854 11876 net.cpp:425] conv1 <- data
I0913 21:01:35.915870 11876 net.cpp:399] conv1 -> conv1
I0913 21:01:36.104758 11876 net.cpp:141] Setting up conv1
I0913 21:01:36.104802 11876 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:01:36.104809 11876 net.cpp:156] Memory required for data: 17799480
I0913 21:01:36.104858 11876 layer_factory.hpp:77] Creating layer relu1
I0913 21:01:36.104890 11876 net.cpp:91] Creating Layer relu1
I0913 21:01:36.104897 11876 net.cpp:425] relu1 <- conv1
I0913 21:01:36.104907 11876 net.cpp:386] relu1 -> conv1 (in-place)
I0913 21:01:36.105307 11876 net.cpp:141] Setting up relu1
I0913 21:01:36.105321 11876 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:01:36.105326 11876 net.cpp:156] Memory required for data: 29415480
I0913 21:01:36.105331 11876 layer_factory.hpp:77] Creating layer pool1
I0913 21:01:36.105347 11876 net.cpp:91] Creating Layer pool1
I0913 21:01:36.105352 11876 net.cpp:425] pool1 <- conv1
I0913 21:01:36.105361 11876 net.cpp:399] pool1 -> pool1
I0913 21:01:36.105437 11876 net.cpp:141] Setting up pool1
I0913 21:01:36.105448 11876 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:01:36.105453 11876 net.cpp:156] Memory required for data: 32214840
I0913 21:01:36.105456 11876 layer_factory.hpp:77] Creating layer norm1
I0913 21:01:36.105473 11876 net.cpp:91] Creating Layer norm1
I0913 21:01:36.105478 11876 net.cpp:425] norm1 <- pool1
I0913 21:01:36.105484 11876 net.cpp:399] norm1 -> norm1
I0913 21:01:36.105748 11876 net.cpp:141] Setting up norm1
I0913 21:01:36.105761 11876 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:01:36.105765 11876 net.cpp:156] Memory required for data: 35014200
I0913 21:01:36.105770 11876 layer_factory.hpp:77] Creating layer conv2
I0913 21:01:36.105787 11876 net.cpp:91] Creating Layer conv2
I0913 21:01:36.105792 11876 net.cpp:425] conv2 <- norm1
I0913 21:01:36.105800 11876 net.cpp:399] conv2 -> conv2
I0913 21:01:36.109535 11876 net.cpp:141] Setting up conv2
I0913 21:01:36.109556 11876 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:01:36.109561 11876 net.cpp:156] Memory required for data: 42479160
I0913 21:01:36.109575 11876 layer_factory.hpp:77] Creating layer relu2
I0913 21:01:36.109606 11876 net.cpp:91] Creating Layer relu2
I0913 21:01:36.109611 11876 net.cpp:425] relu2 <- conv2
I0913 21:01:36.109618 11876 net.cpp:386] relu2 -> conv2 (in-place)
I0913 21:01:36.110005 11876 net.cpp:141] Setting up relu2
I0913 21:01:36.110018 11876 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:01:36.110023 11876 net.cpp:156] Memory required for data: 49944120
I0913 21:01:36.110029 11876 layer_factory.hpp:77] Creating layer pool2
I0913 21:01:36.110051 11876 net.cpp:91] Creating Layer pool2
I0913 21:01:36.110057 11876 net.cpp:425] pool2 <- conv2
I0913 21:01:36.110065 11876 net.cpp:399] pool2 -> pool2
I0913 21:01:36.110117 11876 net.cpp:141] Setting up pool2
I0913 21:01:36.110126 11876 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:01:36.110131 11876 net.cpp:156] Memory required for data: 51674680
I0913 21:01:36.110136 11876 layer_factory.hpp:77] Creating layer norm2
I0913 21:01:36.110146 11876 net.cpp:91] Creating Layer norm2
I0913 21:01:36.110152 11876 net.cpp:425] norm2 <- pool2
I0913 21:01:36.110159 11876 net.cpp:399] norm2 -> norm2
I0913 21:01:36.110411 11876 net.cpp:141] Setting up norm2
I0913 21:01:36.110435 11876 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:01:36.110441 11876 net.cpp:156] Memory required for data: 53405240
I0913 21:01:36.110445 11876 layer_factory.hpp:77] Creating layer conv3
I0913 21:01:36.110456 11876 net.cpp:91] Creating Layer conv3
I0913 21:01:36.110461 11876 net.cpp:425] conv3 <- norm2
I0913 21:01:36.110469 11876 net.cpp:399] conv3 -> conv3
I0913 21:01:36.113884 11876 net.cpp:141] Setting up conv3
I0913 21:01:36.113898 11876 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:01:36.113903 11876 net.cpp:156] Memory required for data: 56001080
I0913 21:01:36.113915 11876 layer_factory.hpp:77] Creating layer relu3
I0913 21:01:36.113924 11876 net.cpp:91] Creating Layer relu3
I0913 21:01:36.113929 11876 net.cpp:425] relu3 <- conv3
I0913 21:01:36.113935 11876 net.cpp:386] relu3 -> conv3 (in-place)
I0913 21:01:36.114156 11876 net.cpp:141] Setting up relu3
I0913 21:01:36.114167 11876 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:01:36.114174 11876 net.cpp:156] Memory required for data: 58596920
I0913 21:01:36.114190 11876 layer_factory.hpp:77] Creating layer conv4
I0913 21:01:36.114202 11876 net.cpp:91] Creating Layer conv4
I0913 21:01:36.114207 11876 net.cpp:425] conv4 <- conv3
I0913 21:01:36.114215 11876 net.cpp:399] conv4 -> conv4
I0913 21:01:36.119421 11876 net.cpp:141] Setting up conv4
I0913 21:01:36.119482 11876 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:01:36.119493 11876 net.cpp:156] Memory required for data: 61192760
I0913 21:01:36.119515 11876 layer_factory.hpp:77] Creating layer relu4
I0913 21:01:36.119537 11876 net.cpp:91] Creating Layer relu4
I0913 21:01:36.119549 11876 net.cpp:425] relu4 <- conv4
I0913 21:01:36.119562 11876 net.cpp:386] relu4 -> conv4 (in-place)
I0913 21:01:36.120230 11876 net.cpp:141] Setting up relu4
I0913 21:01:36.120252 11876 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:01:36.120260 11876 net.cpp:156] Memory required for data: 63788600
I0913 21:01:36.120270 11876 layer_factory.hpp:77] Creating layer conv5
I0913 21:01:36.120296 11876 net.cpp:91] Creating Layer conv5
I0913 21:01:36.120307 11876 net.cpp:425] conv5 <- conv4
I0913 21:01:36.120321 11876 net.cpp:399] conv5 -> conv5
I0913 21:01:36.124956 11876 net.cpp:141] Setting up conv5
I0913 21:01:36.124981 11876 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:01:36.124989 11876 net.cpp:156] Memory required for data: 65519160
I0913 21:01:36.125011 11876 layer_factory.hpp:77] Creating layer relu5
I0913 21:01:36.125022 11876 net.cpp:91] Creating Layer relu5
I0913 21:01:36.125030 11876 net.cpp:425] relu5 <- conv5
I0913 21:01:36.125039 11876 net.cpp:386] relu5 -> conv5 (in-place)
I0913 21:01:36.125494 11876 net.cpp:141] Setting up relu5
I0913 21:01:36.125507 11876 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:01:36.125512 11876 net.cpp:156] Memory required for data: 67249720
I0913 21:01:36.125516 11876 layer_factory.hpp:77] Creating layer pool5
I0913 21:01:36.125526 11876 net.cpp:91] Creating Layer pool5
I0913 21:01:36.125531 11876 net.cpp:425] pool5 <- conv5
I0913 21:01:36.125541 11876 net.cpp:399] pool5 -> pool5
I0913 21:01:36.125599 11876 net.cpp:141] Setting up pool5
I0913 21:01:36.125608 11876 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0913 21:01:36.125612 11876 net.cpp:156] Memory required for data: 67618360
I0913 21:01:36.125617 11876 layer_factory.hpp:77] Creating layer fc6
I0913 21:01:36.125641 11876 net.cpp:91] Creating Layer fc6
I0913 21:01:36.125646 11876 net.cpp:425] fc6 <- pool5
I0913 21:01:36.125653 11876 net.cpp:399] fc6 -> fc6
I0913 21:01:36.227877 11876 net.cpp:141] Setting up fc6
I0913 21:01:36.227936 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.227941 11876 net.cpp:156] Memory required for data: 67782200
I0913 21:01:36.227954 11876 layer_factory.hpp:77] Creating layer relu6
I0913 21:01:36.227982 11876 net.cpp:91] Creating Layer relu6
I0913 21:01:36.227988 11876 net.cpp:425] relu6 <- fc6
I0913 21:01:36.228000 11876 net.cpp:386] relu6 -> fc6 (in-place)
I0913 21:01:36.228330 11876 net.cpp:141] Setting up relu6
I0913 21:01:36.228344 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.228349 11876 net.cpp:156] Memory required for data: 67946040
I0913 21:01:36.228365 11876 layer_factory.hpp:77] Creating layer drop6
I0913 21:01:36.228375 11876 net.cpp:91] Creating Layer drop6
I0913 21:01:36.228380 11876 net.cpp:425] drop6 <- fc6
I0913 21:01:36.228386 11876 net.cpp:386] drop6 -> fc6 (in-place)
I0913 21:01:36.228438 11876 net.cpp:141] Setting up drop6
I0913 21:01:36.228447 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.228451 11876 net.cpp:156] Memory required for data: 68109880
I0913 21:01:36.228466 11876 layer_factory.hpp:77] Creating layer fc7
I0913 21:01:36.228478 11876 net.cpp:91] Creating Layer fc7
I0913 21:01:36.228483 11876 net.cpp:425] fc7 <- fc6
I0913 21:01:36.228490 11876 net.cpp:399] fc7 -> fc7
I0913 21:01:36.267601 11866 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /home/peifeng/work/run/storm102/data/workers/a927c850-2619-4aed-baaf-4e60244d38a4/tmp/cvld3058852401212334555/s2vt.words_to_preds.prototxt
I0913 21:01:36.267653 11866 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0913 21:01:36.267662 11866 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0913 21:01:36.267959 11866 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0913 21:01:36.268054 11866 layer_factory.hpp:77] Creating layer input
I0913 21:01:36.268086 11866 net.cpp:91] Creating Layer input
I0913 21:01:36.268095 11866 net.cpp:399] input -> frames_fc7
I0913 21:01:36.268115 11866 net.cpp:399] input -> cont_sentence
I0913 21:01:36.268126 11866 net.cpp:399] input -> input_sentence
I0913 21:01:36.268134 11866 net.cpp:399] input -> stage_indicator
I0913 21:01:36.268282 11866 net.cpp:141] Setting up input
I0913 21:01:36.268295 11866 net.cpp:148] Top shape: 1 4096 (4096)
I0913 21:01:36.268301 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.268306 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.268311 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.268314 11866 net.cpp:156] Memory required for data: 16396
I0913 21:01:36.268321 11866 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0913 21:01:36.268340 11866 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0913 21:01:36.268345 11866 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0913 21:01:36.268376 11866 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0913 21:01:36.268386 11866 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0913 21:01:36.268434 11866 net.cpp:141] Setting up cont_sentence_input_1_split
I0913 21:01:36.268442 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.268448 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.268452 11866 net.cpp:156] Memory required for data: 16404
I0913 21:01:36.268457 11866 layer_factory.hpp:77] Creating layer embed_encoder
I0913 21:01:36.268468 11866 net.cpp:91] Creating Layer embed_encoder
I0913 21:01:36.268473 11866 net.cpp:425] embed_encoder <- frames_fc7
I0913 21:01:36.268481 11866 net.cpp:399] embed_encoder -> embedded_in_frames
I0913 21:01:36.275076 11876 net.cpp:141] Setting up fc7
I0913 21:01:36.275112 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.275118 11876 net.cpp:156] Memory required for data: 68273720
I0913 21:01:36.275131 11876 layer_factory.hpp:77] Creating layer relu7
I0913 21:01:36.275163 11876 net.cpp:91] Creating Layer relu7
I0913 21:01:36.275171 11876 net.cpp:425] relu7 <- fc7
I0913 21:01:36.275183 11876 net.cpp:386] relu7 -> fc7 (in-place)
I0913 21:01:36.275775 11876 net.cpp:141] Setting up relu7
I0913 21:01:36.275787 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.275792 11876 net.cpp:156] Memory required for data: 68437560
I0913 21:01:36.275797 11876 layer_factory.hpp:77] Creating layer drop7
I0913 21:01:36.275807 11876 net.cpp:91] Creating Layer drop7
I0913 21:01:36.275812 11876 net.cpp:425] drop7 <- fc7
I0913 21:01:36.275822 11876 net.cpp:386] drop7 -> fc7 (in-place)
I0913 21:01:36.275861 11876 net.cpp:141] Setting up drop7
I0913 21:01:36.275869 11876 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:01:36.275873 11876 net.cpp:156] Memory required for data: 68601400
I0913 21:01:36.275878 11876 layer_factory.hpp:77] Creating layer fc8
I0913 21:01:36.275887 11876 net.cpp:91] Creating Layer fc8
I0913 21:01:36.275892 11876 net.cpp:425] fc8 <- fc7
I0913 21:01:36.275902 11876 net.cpp:399] fc8 -> fc8
I0913 21:01:36.287402 11876 net.cpp:141] Setting up fc8
I0913 21:01:36.287441 11876 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:01:36.287446 11876 net.cpp:156] Memory required for data: 68641400
I0913 21:01:36.287459 11876 layer_factory.hpp:77] Creating layer prob
I0913 21:01:36.287473 11876 net.cpp:91] Creating Layer prob
I0913 21:01:36.287482 11876 net.cpp:425] prob <- fc8
I0913 21:01:36.287490 11876 net.cpp:399] prob -> prob
I0913 21:01:36.287902 11876 net.cpp:141] Setting up prob
I0913 21:01:36.287914 11876 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:01:36.287919 11876 net.cpp:156] Memory required for data: 68681400
I0913 21:01:36.287924 11876 net.cpp:219] prob does not need backward computation.
I0913 21:01:36.287928 11876 net.cpp:219] fc8 does not need backward computation.
I0913 21:01:36.287933 11876 net.cpp:219] drop7 does not need backward computation.
I0913 21:01:36.287937 11876 net.cpp:219] relu7 does not need backward computation.
I0913 21:01:36.287941 11876 net.cpp:219] fc7 does not need backward computation.
I0913 21:01:36.287945 11876 net.cpp:219] drop6 does not need backward computation.
I0913 21:01:36.287950 11876 net.cpp:219] relu6 does not need backward computation.
I0913 21:01:36.287955 11876 net.cpp:219] fc6 does not need backward computation.
I0913 21:01:36.287958 11876 net.cpp:219] pool5 does not need backward computation.
I0913 21:01:36.287963 11876 net.cpp:219] relu5 does not need backward computation.
I0913 21:01:36.287967 11876 net.cpp:219] conv5 does not need backward computation.
I0913 21:01:36.287972 11876 net.cpp:219] relu4 does not need backward computation.
I0913 21:01:36.287976 11876 net.cpp:219] conv4 does not need backward computation.
I0913 21:01:36.287981 11876 net.cpp:219] relu3 does not need backward computation.
I0913 21:01:36.287986 11876 net.cpp:219] conv3 does not need backward computation.
I0913 21:01:36.287991 11876 net.cpp:219] norm2 does not need backward computation.
I0913 21:01:36.287994 11876 net.cpp:219] pool2 does not need backward computation.
I0913 21:01:36.287999 11876 net.cpp:219] relu2 does not need backward computation.
I0913 21:01:36.288003 11876 net.cpp:219] conv2 does not need backward computation.
I0913 21:01:36.288008 11876 net.cpp:219] norm1 does not need backward computation.
I0913 21:01:36.288012 11876 net.cpp:219] pool1 does not need backward computation.
I0913 21:01:36.288017 11876 net.cpp:219] relu1 does not need backward computation.
I0913 21:01:36.288022 11876 net.cpp:219] conv1 does not need backward computation.
I0913 21:01:36.288025 11876 net.cpp:219] data does not need backward computation.
I0913 21:01:36.288029 11876 net.cpp:261] This network produces output prob
I0913 21:01:36.288053 11876 net.cpp:274] Network initialization done.
I0913 21:01:36.289122 11866 net.cpp:141] Setting up embed_encoder
I0913 21:01:36.289139 11866 net.cpp:148] Top shape: 1 500 (500)
I0913 21:01:36.289144 11866 net.cpp:156] Memory required for data: 18404
I0913 21:01:36.289158 11866 layer_factory.hpp:77] Creating layer reshape_frames
I0913 21:01:36.289176 11866 net.cpp:91] Creating Layer reshape_frames
I0913 21:01:36.289183 11866 net.cpp:425] reshape_frames <- embedded_in_frames
I0913 21:01:36.289192 11866 net.cpp:399] reshape_frames -> embedded_input_frames
I0913 21:01:36.289237 11866 net.cpp:141] Setting up reshape_frames
I0913 21:01:36.289247 11866 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:01:36.289250 11866 net.cpp:156] Memory required for data: 20404
I0913 21:01:36.289255 11866 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0913 21:01:36.289264 11866 net.cpp:91] Creating Layer reshape_stage_indicator
I0913 21:01:36.289269 11866 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0913 21:01:36.289278 11866 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0913 21:01:36.289315 11866 net.cpp:141] Setting up reshape_stage_indicator
I0913 21:01:36.289324 11866 net.cpp:148] Top shape: 1 1 1 (1)
I0913 21:01:36.289329 11866 net.cpp:156] Memory required for data: 20408
I0913 21:01:36.289332 11866 layer_factory.hpp:77] Creating layer embedding
I0913 21:01:36.289342 11866 net.cpp:91] Creating Layer embedding
I0913 21:01:36.289347 11866 net.cpp:425] embedding <- input_sentence
I0913 21:01:36.289355 11866 net.cpp:399] embedding -> embedded_input_sentence
I0913 21:01:36.506274 11866 net.cpp:141] Setting up embedding
I0913 21:01:36.506325 11866 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:01:36.506330 11866 net.cpp:156] Memory required for data: 22408
I0913 21:01:36.506345 11866 layer_factory.hpp:77] Creating layer lstm1
I0913 21:01:36.506368 11866 net.cpp:91] Creating Layer lstm1
I0913 21:01:36.506376 11866 net.cpp:425] lstm1 <- embedded_input_frames
I0913 21:01:36.506383 11866 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0913 21:01:36.506392 11866 net.cpp:399] lstm1 -> lstm1
I0913 21:01:36.506419 11866 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:01:36.506809 11866 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:01:36.506901 11866 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:01:36.506912 11866 net.cpp:91] Creating Layer lstm1_
I0913 21:01:36.506918 11866 net.cpp:399] lstm1_ -> x
I0913 21:01:36.506929 11866 net.cpp:399] lstm1_ -> cont
I0913 21:01:36.506991 11866 net.cpp:141] Setting up lstm1_
I0913 21:01:36.507004 11866 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:01:36.507009 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.507014 11866 net.cpp:156] Memory required for data: 2004
I0913 21:01:36.507019 11866 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:01:36.507026 11866 net.cpp:91] Creating Layer lstm1_
I0913 21:01:36.507032 11866 net.cpp:399] lstm1_ -> c_0
I0913 21:01:36.507043 11866 net.cpp:399] lstm1_ -> h_0
I0913 21:01:36.507091 11866 net.cpp:141] Setting up lstm1_
I0913 21:01:36.507100 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.507107 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.507110 11866 net.cpp:156] Memory required for data: 10004
I0913 21:01:36.507114 11866 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0913 21:01:36.507125 11866 net.cpp:91] Creating Layer lstm1_cont_slice
I0913 21:01:36.507129 11866 net.cpp:425] lstm1_cont_slice <- cont
I0913 21:01:36.507136 11866 net.cpp:399] lstm1_cont_slice -> cont_1
I0913 21:01:36.507172 11866 net.cpp:141] Setting up lstm1_cont_slice
I0913 21:01:36.507180 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.507185 11866 net.cpp:156] Memory required for data: 10008
I0913 21:01:36.507189 11866 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0913 21:01:36.507196 11866 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0913 21:01:36.507201 11866 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0913 21:01:36.507210 11866 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0913 21:01:36.507217 11866 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0913 21:01:36.507263 11866 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0913 21:01:36.507272 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.507277 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.507280 11866 net.cpp:156] Memory required for data: 10016
I0913 21:01:36.507285 11866 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0913 21:01:36.507297 11866 net.cpp:91] Creating Layer lstm1_x_transform
I0913 21:01:36.507302 11866 net.cpp:425] lstm1_x_transform <- x
I0913 21:01:36.507309 11866 net.cpp:399] lstm1_x_transform -> W_xc_x
I0913 21:01:36.527866 11866 net.cpp:141] Setting up lstm1_x_transform
I0913 21:01:36.527907 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.527914 11866 net.cpp:156] Memory required for data: 26016
I0913 21:01:36.527931 11866 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0913 21:01:36.527948 11866 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0913 21:01:36.527954 11866 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0913 21:01:36.527963 11866 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0913 21:01:36.528004 11866 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0913 21:01:36.528014 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.528018 11866 net.cpp:156] Memory required for data: 42016
I0913 21:01:36.528023 11866 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0913 21:01:36.528033 11866 net.cpp:91] Creating Layer lstm1_h_conted_0
I0913 21:01:36.528038 11866 net.cpp:425] lstm1_h_conted_0 <- h_0
I0913 21:01:36.528043 11866 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0913 21:01:36.528053 11866 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0913 21:01:36.528158 11866 net.cpp:141] Setting up lstm1_h_conted_0
I0913 21:01:36.528168 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.528172 11866 net.cpp:156] Memory required for data: 46016
I0913 21:01:36.528177 11866 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0913 21:01:36.528192 11866 net.cpp:91] Creating Layer lstm1_transform_1
I0913 21:01:36.528198 11866 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0913 21:01:36.528205 11866 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0913 21:01:36.550036 11876 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/peifeng/work/run/storm102/data/workers/a927c850-2619-4aed-baaf-4e60244d38a4/tmp/cvld3058852401212334555/bvlc_reference_caffenet.caffemodel
I0913 21:01:36.550073 11876 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0913 21:01:36.550079 11876 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0913 21:01:36.550084 11876 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/peifeng/work/run/storm102/data/workers/a927c850-2619-4aed-baaf-4e60244d38a4/tmp/cvld3058852401212334555/bvlc_reference_caffenet.caffemodel
I0913 21:01:36.566052 11866 net.cpp:141] Setting up lstm1_transform_1
I0913 21:01:36.566097 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.566102 11866 net.cpp:156] Memory required for data: 62016
I0913 21:01:36.566120 11866 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0913 21:01:36.566140 11866 net.cpp:91] Creating Layer lstm1_gate_input_1
I0913 21:01:36.566148 11866 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0913 21:01:36.566155 11866 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0913 21:01:36.566164 11866 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0913 21:01:36.566215 11866 net.cpp:141] Setting up lstm1_gate_input_1
I0913 21:01:36.566223 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.566228 11866 net.cpp:156] Memory required for data: 78016
I0913 21:01:36.566232 11866 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0913 21:01:36.566243 11866 net.cpp:91] Creating Layer lstm1_unit_1
I0913 21:01:36.566248 11866 net.cpp:425] lstm1_unit_1 <- c_0
I0913 21:01:36.566254 11866 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0913 21:01:36.566259 11866 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0913 21:01:36.566265 11866 net.cpp:399] lstm1_unit_1 -> c_1
I0913 21:01:36.566274 11866 net.cpp:399] lstm1_unit_1 -> h_1
I0913 21:01:36.566334 11866 net.cpp:141] Setting up lstm1_unit_1
I0913 21:01:36.566344 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.566349 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.566354 11866 net.cpp:156] Memory required for data: 86016
I0913 21:01:36.566357 11866 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:01:36.566365 11866 net.cpp:91] Creating Layer lstm1_
I0913 21:01:36.566370 11866 net.cpp:425] lstm1_ <- c_1
I0913 21:01:36.566378 11866 net.cpp:399] lstm1_ -> c_T
I0913 21:01:36.566406 11866 net.cpp:141] Setting up lstm1_
I0913 21:01:36.566414 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.566418 11866 net.cpp:156] Memory required for data: 90016
I0913 21:01:36.566422 11866 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0913 21:01:36.566442 11866 net.cpp:91] Creating Layer lstm1_h_concat
I0913 21:01:36.566447 11866 net.cpp:425] lstm1_h_concat <- h_1
I0913 21:01:36.566452 11866 net.cpp:399] lstm1_h_concat -> h
I0913 21:01:36.566486 11866 net.cpp:141] Setting up lstm1_h_concat
I0913 21:01:36.566495 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.566499 11866 net.cpp:156] Memory required for data: 94016
I0913 21:01:36.566504 11866 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:01:36.566517 11866 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:01:36.566522 11866 net.cpp:425] h_pseudoloss <- h
I0913 21:01:36.566529 11866 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:01:36.566612 11866 net.cpp:141] Setting up h_pseudoloss
I0913 21:01:36.566622 11866 net.cpp:148] Top shape: (1)
I0913 21:01:36.566627 11866 net.cpp:151]     with loss weight 1
I0913 21:01:36.566661 11866 net.cpp:156] Memory required for data: 94020
I0913 21:01:36.566666 11866 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:01:36.566671 11866 net.cpp:217] lstm1_h_concat needs backward computation.
I0913 21:01:36.566675 11866 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:01:36.566680 11866 net.cpp:217] lstm1_unit_1 needs backward computation.
I0913 21:01:36.566685 11866 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0913 21:01:36.566690 11866 net.cpp:217] lstm1_transform_1 needs backward computation.
I0913 21:01:36.566694 11866 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0913 21:01:36.566700 11866 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0913 21:01:36.566704 11866 net.cpp:217] lstm1_x_transform needs backward computation.
I0913 21:01:36.566709 11866 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0913 21:01:36.566715 11866 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0913 21:01:36.566720 11866 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:01:36.566723 11866 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:01:36.566726 11866 net.cpp:261] This network produces output c_T
I0913 21:01:36.566730 11866 net.cpp:261] This network produces output h_pseudoloss
I0913 21:01:36.566745 11866 net.cpp:274] Network initialization done.
I0913 21:01:36.566792 11866 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:01:36.566798 11866 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:01:36.566802 11866 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:01:36.566907 11866 net.cpp:141] Setting up lstm1
I0913 21:01:36.566920 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.566925 11866 net.cpp:156] Memory required for data: 26408
I0913 21:01:36.566936 11866 layer_factory.hpp:77] Creating layer concat
I0913 21:01:36.566944 11866 net.cpp:91] Creating Layer concat
I0913 21:01:36.566951 11866 net.cpp:425] concat <- lstm1
I0913 21:01:36.566956 11866 net.cpp:425] concat <- embedded_input_sentence
I0913 21:01:36.566962 11866 net.cpp:425] concat <- reshaped_stage_indicator
I0913 21:01:36.566967 11866 net.cpp:399] concat -> lstm1_video_sequence
I0913 21:01:36.566999 11866 net.cpp:141] Setting up concat
I0913 21:01:36.567008 11866 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:01:36.567011 11866 net.cpp:156] Memory required for data: 32412
I0913 21:01:36.567016 11866 layer_factory.hpp:77] Creating layer lstm2
I0913 21:01:36.567028 11866 net.cpp:91] Creating Layer lstm2
I0913 21:01:36.567033 11866 net.cpp:425] lstm2 <- lstm1_video_sequence
I0913 21:01:36.567039 11866 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0913 21:01:36.567044 11866 net.cpp:399] lstm2 -> lstm2
I0913 21:01:36.567054 11866 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:01:36.567291 11866 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:01:36.567370 11866 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:01:36.567381 11866 net.cpp:91] Creating Layer lstm2_
I0913 21:01:36.567387 11866 net.cpp:399] lstm2_ -> x
I0913 21:01:36.567397 11866 net.cpp:399] lstm2_ -> cont
I0913 21:01:36.567450 11866 net.cpp:141] Setting up lstm2_
I0913 21:01:36.567458 11866 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:01:36.567464 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.567468 11866 net.cpp:156] Memory required for data: 6008
I0913 21:01:36.567472 11866 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:01:36.567483 11866 net.cpp:91] Creating Layer lstm2_
I0913 21:01:36.567489 11866 net.cpp:399] lstm2_ -> c_0
I0913 21:01:36.567498 11866 net.cpp:399] lstm2_ -> h_0
I0913 21:01:36.567545 11866 net.cpp:141] Setting up lstm2_
I0913 21:01:36.567553 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.567559 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.567564 11866 net.cpp:156] Memory required for data: 14008
I0913 21:01:36.567567 11866 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0913 21:01:36.567575 11866 net.cpp:91] Creating Layer lstm2_cont_slice
I0913 21:01:36.567580 11866 net.cpp:425] lstm2_cont_slice <- cont
I0913 21:01:36.567586 11866 net.cpp:399] lstm2_cont_slice -> cont_1
I0913 21:01:36.567620 11866 net.cpp:141] Setting up lstm2_cont_slice
I0913 21:01:36.567628 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.567632 11866 net.cpp:156] Memory required for data: 14012
I0913 21:01:36.567637 11866 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0913 21:01:36.567643 11866 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0913 21:01:36.567647 11866 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0913 21:01:36.567656 11866 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0913 21:01:36.567663 11866 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0913 21:01:36.567708 11866 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0913 21:01:36.567718 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.567723 11866 net.cpp:148] Top shape: 1 1 (1)
I0913 21:01:36.567728 11866 net.cpp:156] Memory required for data: 14020
I0913 21:01:36.567731 11866 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0913 21:01:36.567740 11866 net.cpp:91] Creating Layer lstm2_x_transform
I0913 21:01:36.567744 11866 net.cpp:425] lstm2_x_transform <- x
I0913 21:01:36.567754 11866 net.cpp:399] lstm2_x_transform -> W_xc_x
I0913 21:01:36.624256 11866 net.cpp:141] Setting up lstm2_x_transform
I0913 21:01:36.624302 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.624308 11866 net.cpp:156] Memory required for data: 30020
I0913 21:01:36.624327 11866 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0913 21:01:36.624342 11866 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0913 21:01:36.624348 11866 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0913 21:01:36.624357 11866 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0913 21:01:36.624404 11866 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0913 21:01:36.624414 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.624418 11866 net.cpp:156] Memory required for data: 46020
I0913 21:01:36.624423 11866 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0913 21:01:36.624433 11866 net.cpp:91] Creating Layer lstm2_h_conted_0
I0913 21:01:36.624438 11866 net.cpp:425] lstm2_h_conted_0 <- h_0
I0913 21:01:36.624442 11866 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0913 21:01:36.624449 11866 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0913 21:01:36.624538 11866 net.cpp:141] Setting up lstm2_h_conted_0
I0913 21:01:36.624547 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.624552 11866 net.cpp:156] Memory required for data: 50020
I0913 21:01:36.624555 11866 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0913 21:01:36.624567 11866 net.cpp:91] Creating Layer lstm2_transform_1
I0913 21:01:36.624572 11866 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0913 21:01:36.624584 11866 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0913 21:01:36.663092 11866 net.cpp:141] Setting up lstm2_transform_1
I0913 21:01:36.663156 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.663166 11866 net.cpp:156] Memory required for data: 66020
I0913 21:01:36.663192 11866 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0913 21:01:36.663218 11866 net.cpp:91] Creating Layer lstm2_gate_input_1
I0913 21:01:36.663229 11866 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0913 21:01:36.663242 11866 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0913 21:01:36.663260 11866 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0913 21:01:36.663334 11866 net.cpp:141] Setting up lstm2_gate_input_1
I0913 21:01:36.663350 11866 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:01:36.663358 11866 net.cpp:156] Memory required for data: 82020
I0913 21:01:36.663367 11866 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0913 21:01:36.663381 11866 net.cpp:91] Creating Layer lstm2_unit_1
I0913 21:01:36.663390 11866 net.cpp:425] lstm2_unit_1 <- c_0
I0913 21:01:36.663401 11866 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0913 21:01:36.663411 11866 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0913 21:01:36.663426 11866 net.cpp:399] lstm2_unit_1 -> c_1
I0913 21:01:36.663442 11866 net.cpp:399] lstm2_unit_1 -> h_1
I0913 21:01:36.663555 11866 net.cpp:141] Setting up lstm2_unit_1
I0913 21:01:36.663571 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.663583 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.663590 11866 net.cpp:156] Memory required for data: 90020
I0913 21:01:36.663599 11866 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:01:36.663614 11866 net.cpp:91] Creating Layer lstm2_
I0913 21:01:36.663622 11866 net.cpp:425] lstm2_ <- c_1
I0913 21:01:36.663633 11866 net.cpp:399] lstm2_ -> c_T
I0913 21:01:36.663693 11866 net.cpp:141] Setting up lstm2_
I0913 21:01:36.663709 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.663717 11866 net.cpp:156] Memory required for data: 94020
I0913 21:01:36.663727 11866 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0913 21:01:36.663743 11866 net.cpp:91] Creating Layer lstm2_h_concat
I0913 21:01:36.663751 11866 net.cpp:425] lstm2_h_concat <- h_1
I0913 21:01:36.663767 11866 net.cpp:399] lstm2_h_concat -> h
I0913 21:01:36.663825 11866 net.cpp:141] Setting up lstm2_h_concat
I0913 21:01:36.663841 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.663847 11866 net.cpp:156] Memory required for data: 98020
I0913 21:01:36.663856 11866 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:01:36.663875 11866 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:01:36.663885 11866 net.cpp:425] h_pseudoloss <- h
I0913 21:01:36.663897 11866 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:01:36.664047 11866 net.cpp:141] Setting up h_pseudoloss
I0913 21:01:36.664085 11866 net.cpp:148] Top shape: (1)
I0913 21:01:36.664094 11866 net.cpp:151]     with loss weight 1
I0913 21:01:36.664119 11866 net.cpp:156] Memory required for data: 98024
I0913 21:01:36.664129 11866 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:01:36.664137 11866 net.cpp:217] lstm2_h_concat needs backward computation.
I0913 21:01:36.664146 11866 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:01:36.664155 11866 net.cpp:217] lstm2_unit_1 needs backward computation.
I0913 21:01:36.664165 11866 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0913 21:01:36.664175 11866 net.cpp:217] lstm2_transform_1 needs backward computation.
I0913 21:01:36.664183 11866 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0913 21:01:36.664193 11866 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0913 21:01:36.664202 11866 net.cpp:217] lstm2_x_transform needs backward computation.
I0913 21:01:36.664212 11866 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0913 21:01:36.664222 11866 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0913 21:01:36.664232 11866 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:01:36.664240 11866 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:01:36.664247 11866 net.cpp:261] This network produces output c_T
I0913 21:01:36.664255 11866 net.cpp:261] This network produces output h_pseudoloss
I0913 21:01:36.664281 11866 net.cpp:274] Network initialization done.
I0913 21:01:36.664356 11866 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:01:36.664368 11866 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:01:36.664376 11866 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:01:36.664554 11866 net.cpp:141] Setting up lstm2
I0913 21:01:36.664572 11866 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:01:36.664580 11866 net.cpp:156] Memory required for data: 36412
I0913 21:01:36.664604 11866 layer_factory.hpp:77] Creating layer predict
I0913 21:01:36.664623 11866 net.cpp:91] Creating Layer predict
I0913 21:01:36.664634 11866 net.cpp:425] predict <- lstm2
I0913 21:01:36.664647 11866 net.cpp:399] predict -> predict
I0913 21:01:36.981336 11876 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0913 21:01:37.027853 11876 net.cpp:752] Ignoring source layer loss
Loading the model + trained: 10954.3ms
Using cv::Size and some other stuff: 0.185ms
I0913 21:01:37.106187 11866 net.cpp:141] Setting up predict
I0913 21:01:37.106232 11866 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:01:37.106240 11866 net.cpp:156] Memory required for data: 221084
I0913 21:01:37.106253 11866 layer_factory.hpp:77] Creating layer probs
I0913 21:01:37.106271 11866 net.cpp:91] Creating Layer probs
I0913 21:01:37.106277 11866 net.cpp:425] probs <- predict
I0913 21:01:37.106287 11866 net.cpp:399] probs -> probs
I0913 21:01:37.107795 11866 net.cpp:141] Setting up probs
I0913 21:01:37.107848 11866 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:01:37.107854 11866 net.cpp:156] Memory required for data: 405756
I0913 21:01:37.107862 11866 net.cpp:219] probs does not need backward computation.
I0913 21:01:37.107868 11866 net.cpp:219] predict does not need backward computation.
I0913 21:01:37.107874 11866 net.cpp:219] lstm2 does not need backward computation.
I0913 21:01:37.107879 11866 net.cpp:219] concat does not need backward computation.
I0913 21:01:37.107885 11866 net.cpp:219] lstm1 does not need backward computation.
I0913 21:01:37.107892 11866 net.cpp:219] embedding does not need backward computation.
I0913 21:01:37.107897 11866 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0913 21:01:37.107902 11866 net.cpp:219] reshape_frames does not need backward computation.
I0913 21:01:37.107905 11866 net.cpp:219] embed_encoder does not need backward computation.
I0913 21:01:37.107910 11866 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0913 21:01:37.107915 11866 net.cpp:219] input does not need backward computation.
I0913 21:01:37.107920 11866 net.cpp:261] This network produces output probs
I0913 21:01:37.107939 11866 net.cpp:274] Network initialization done.
Loading the mean file: 1697.6ms
I0913 21:01:37.494068 11866 net.cpp:752] Ignoring source layer data
I0913 21:01:37.494107 11866 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0913 21:01:37.494119 11866 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0913 21:01:37.569610 11866 net.cpp:752] Ignoring source layer cross_entropy_loss
TIMERTIMER 131369787
TIMERTIMER 67455142
TIMERTIMER 66511574
TIMERTIMER 50437834
TIMERTIMER 50726595
TIMERTIMER 47711087
TIMERTIMER 47454022
TIMERTIMER 48655546
TIMERTIMER 48500126
TIMERTIMER 48576121
TIMERTIMER 47708688
TIMERTIMER 50034270
TIMERTIMER 48203074
TIMERTIMER 49131056
TIMERTIMER 48953978
TIMERTIMER 49397578
TIMERTIMER 49483900
TIMERTIMER 48900161
TIMERTIMER 37259838
TIMERTIMER 37613686
TIMERTIMER 31241408
TIMERTIMER 32861331
TIMERTIMER 33618826
TIMERTIMER 37375679
TIMERTIMER 31091966
TIMERTIMER 31765428
TIMERTIMER 37431012
TIMERTIMER 31241083
TIMERTIMER 31601399
TIMERTIMER 32407116
TIMERTIMER 32089695
TIMERTIMER 37374619
TIMERTIMER 31187283
TIMERTIMER 38864285
TIMERTIMER 32603870
TIMERTIMER 37668525
TIMERTIMER 31494385
TIMERTIMER 37752850
TIMERTIMER 31618074
TIMERTIMER 32066061
TIMERTIMER 31514582
TIMERTIMER 38195480
TIMERTIMER 37625710
TIMERTIMER 37723131
TIMERTIMER 31643576
TIMERTIMER 31609186
TIMERTIMER 44058210
TIMERTIMER 31630254
TIMERTIMER 31549160
TIMERTIMER 40430264
TIMERTIMER 32307821
TIMERTIMER 38288872
TIMERTIMER 37670150
TIMERTIMER 31572376
TIMERTIMER 37852771
TIMERTIMER 37832378
TIMERTIMER 37156800
TIMERTIMER 31541664
TIMERTIMER 31626933
TIMERTIMER 38997311
TIMERTIMER 31759854
TIMERTIMER 31529567
TIMERTIMER 37653165
TIMERTIMER 31763968
TIMERTIMER 31601342
TIMERTIMER 37833804
TIMERTIMER 32404013
TIMERTIMER 37726194
TIMERTIMER 47858234
TIMERTIMER 31635090
TIMERTIMER 31585324
TIMERTIMER 37863079
TIMERTIMER 31496562
TIMERTIMER 33346834
TIMERTIMER 37831928
TIMERTIMER 37779124
TIMERTIMER 31762309
TIMERTIMER 36216792
TIMERTIMER 40792602
TIMERTIMER 37648772
TIMERTIMER 31525947
TIMERTIMER 44029763
TIMERTIMER 31719371
TIMERTIMER 31734809
TIMERTIMER 31705449
TIMERTIMER 37651491
TIMERTIMER 31688093
TIMERTIMER 37827212
TIMERTIMER 31609403
TIMERTIMER 45486628
TIMERTIMER 32110026
TIMERTIMER 38158764
TIMERTIMER 31458576
TIMERTIMER 31623031
TIMERTIMER 34071602
TIMERTIMER 37905032
TIMERTIMER 33153888
TIMERTIMER 32380059
TIMERTIMER 32565503
TIMERTIMER 33799554
TIMERTIMER 33068623
TIMERTIMER 32977446
TIMERTIMER 37804389
TIMERTIMER 39116201
TIMERTIMER 34862281
TIMERTIMER 31602151
TIMERTIMER 31602354
TIMERTIMER 32268820
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007efceb83ede3, pid=11799, tid=139621831083776
#
# JRE version: Java(TM) SE Runtime Environment (8.0_77-b03) (build 1.8.0_77-b03)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.77-b03 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libc.so.6+0x7fde3][thread 139621812135680 also had an error]
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm102/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/work/run/storm102/data/supervisor/stormdist/captioning-1-1473814855/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /home/peifeng/work/run/storm102/data/workers/0d94b8c0-9cca-42bd-b1e6-549ebb919ff0/tmp/cvld6029129470286192933/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0913 21:03:20.215169 12026 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0913 21:03:20.215342 12026 layer_factory.hpp:77] Creating layer data
I0913 21:03:20.215368 12026 net.cpp:91] Creating Layer data
I0913 21:03:20.215376 12026 net.cpp:399] data -> data
I0913 21:03:20.778139 12026 net.cpp:141] Setting up data
I0913 21:03:20.778326 12026 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0913 21:03:20.778334 12026 net.cpp:156] Memory required for data: 6183480
I0913 21:03:20.778352 12026 layer_factory.hpp:77] Creating layer conv1
I0913 21:03:20.778381 12026 net.cpp:91] Creating Layer conv1
I0913 21:03:20.778389 12026 net.cpp:425] conv1 <- data
I0913 21:03:20.778403 12026 net.cpp:399] conv1 -> conv1
I0913 21:03:20.970439 12026 net.cpp:141] Setting up conv1
I0913 21:03:20.970485 12026 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:03:20.970495 12026 net.cpp:156] Memory required for data: 17799480
I0913 21:03:20.970530 12026 layer_factory.hpp:77] Creating layer relu1
I0913 21:03:20.970554 12026 net.cpp:91] Creating Layer relu1
I0913 21:03:20.970566 12026 net.cpp:425] relu1 <- conv1
I0913 21:03:20.970579 12026 net.cpp:386] relu1 -> conv1 (in-place)
I0913 21:03:20.971153 12026 net.cpp:141] Setting up relu1
I0913 21:03:20.971174 12026 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0913 21:03:20.971184 12026 net.cpp:156] Memory required for data: 29415480
I0913 21:03:20.971194 12026 layer_factory.hpp:77] Creating layer pool1
I0913 21:03:20.971215 12026 net.cpp:91] Creating Layer pool1
I0913 21:03:20.971226 12026 net.cpp:425] pool1 <- conv1
I0913 21:03:20.971243 12026 net.cpp:399] pool1 -> pool1
I0913 21:03:20.971349 12026 net.cpp:141] Setting up pool1
I0913 21:03:20.971369 12026 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:03:20.971379 12026 net.cpp:156] Memory required for data: 32214840
I0913 21:03:20.971390 12026 layer_factory.hpp:77] Creating layer norm1
I0913 21:03:20.971416 12026 net.cpp:91] Creating Layer norm1
I0913 21:03:20.971429 12026 net.cpp:425] norm1 <- pool1
I0913 21:03:20.971444 12026 net.cpp:399] norm1 -> norm1
I0913 21:03:20.971920 12026 net.cpp:141] Setting up norm1
I0913 21:03:20.971940 12026 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0913 21:03:20.971951 12026 net.cpp:156] Memory required for data: 35014200
I0913 21:03:20.971961 12026 layer_factory.hpp:77] Creating layer conv2
I0913 21:03:20.971983 12026 net.cpp:91] Creating Layer conv2
I0913 21:03:20.971995 12026 net.cpp:425] conv2 <- norm1
I0913 21:03:20.972010 12026 net.cpp:399] conv2 -> conv2
I0913 21:03:20.977314 12026 net.cpp:141] Setting up conv2
I0913 21:03:20.977344 12026 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:03:20.977350 12026 net.cpp:156] Memory required for data: 42479160
I0913 21:03:20.977366 12026 layer_factory.hpp:77] Creating layer relu2
I0913 21:03:20.977377 12026 net.cpp:91] Creating Layer relu2
I0913 21:03:20.977385 12026 net.cpp:425] relu2 <- conv2
I0913 21:03:20.977392 12026 net.cpp:386] relu2 -> conv2 (in-place)
I0913 21:03:20.977776 12026 net.cpp:141] Setting up relu2
I0913 21:03:20.977788 12026 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0913 21:03:20.977794 12026 net.cpp:156] Memory required for data: 49944120
I0913 21:03:20.977799 12026 layer_factory.hpp:77] Creating layer pool2
I0913 21:03:20.977810 12026 net.cpp:91] Creating Layer pool2
I0913 21:03:20.977815 12026 net.cpp:425] pool2 <- conv2
I0913 21:03:20.977823 12026 net.cpp:399] pool2 -> pool2
I0913 21:03:20.977876 12026 net.cpp:141] Setting up pool2
I0913 21:03:20.977885 12026 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:03:20.977890 12026 net.cpp:156] Memory required for data: 51674680
I0913 21:03:20.977895 12026 layer_factory.hpp:77] Creating layer norm2
I0913 21:03:20.977907 12026 net.cpp:91] Creating Layer norm2
I0913 21:03:20.977912 12026 net.cpp:425] norm2 <- pool2
I0913 21:03:20.977921 12026 net.cpp:399] norm2 -> norm2
I0913 21:03:20.978162 12026 net.cpp:141] Setting up norm2
I0913 21:03:20.978178 12026 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:03:20.978188 12026 net.cpp:156] Memory required for data: 53405240
I0913 21:03:20.978195 12026 layer_factory.hpp:77] Creating layer conv3
I0913 21:03:20.978210 12026 net.cpp:91] Creating Layer conv3
I0913 21:03:20.978216 12026 net.cpp:425] conv3 <- norm2
I0913 21:03:20.978225 12026 net.cpp:399] conv3 -> conv3
I0913 21:03:20.981871 12026 net.cpp:141] Setting up conv3
I0913 21:03:20.981897 12026 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:03:20.981904 12026 net.cpp:156] Memory required for data: 56001080
I0913 21:03:20.981921 12026 layer_factory.hpp:77] Creating layer relu3
I0913 21:03:20.981932 12026 net.cpp:91] Creating Layer relu3
I0913 21:03:20.981938 12026 net.cpp:425] relu3 <- conv3
I0913 21:03:20.981945 12026 net.cpp:386] relu3 -> conv3 (in-place)
I0913 21:03:20.982167 12026 net.cpp:141] Setting up relu3
I0913 21:03:20.982178 12026 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:03:20.982183 12026 net.cpp:156] Memory required for data: 58596920
I0913 21:03:20.982188 12026 layer_factory.hpp:77] Creating layer conv4
I0913 21:03:20.982201 12026 net.cpp:91] Creating Layer conv4
I0913 21:03:20.982208 12026 net.cpp:425] conv4 <- conv3
I0913 21:03:20.982214 12026 net.cpp:399] conv4 -> conv4
I0913 21:03:20.986172 12026 net.cpp:141] Setting up conv4
I0913 21:03:20.986194 12026 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:03:20.986201 12026 net.cpp:156] Memory required for data: 61192760
I0913 21:03:20.986209 12026 layer_factory.hpp:77] Creating layer relu4
I0913 21:03:20.986222 12026 net.cpp:91] Creating Layer relu4
I0913 21:03:20.986228 12026 net.cpp:425] relu4 <- conv4
I0913 21:03:20.986234 12026 net.cpp:386] relu4 -> conv4 (in-place)
I0913 21:03:20.986620 12026 net.cpp:141] Setting up relu4
I0913 21:03:20.986634 12026 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0913 21:03:20.986640 12026 net.cpp:156] Memory required for data: 63788600
I0913 21:03:20.986646 12026 layer_factory.hpp:77] Creating layer conv5
I0913 21:03:20.986656 12026 net.cpp:91] Creating Layer conv5
I0913 21:03:20.986661 12026 net.cpp:425] conv5 <- conv4
I0913 21:03:20.986672 12026 net.cpp:399] conv5 -> conv5
I0913 21:03:20.990299 12026 net.cpp:141] Setting up conv5
I0913 21:03:20.990324 12026 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:03:20.990329 12026 net.cpp:156] Memory required for data: 65519160
I0913 21:03:20.990345 12026 layer_factory.hpp:77] Creating layer relu5
I0913 21:03:20.990360 12026 net.cpp:91] Creating Layer relu5
I0913 21:03:20.990366 12026 net.cpp:425] relu5 <- conv5
I0913 21:03:20.990373 12026 net.cpp:386] relu5 -> conv5 (in-place)
I0913 21:03:20.990762 12026 net.cpp:141] Setting up relu5
I0913 21:03:20.990775 12026 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0913 21:03:20.990780 12026 net.cpp:156] Memory required for data: 67249720
I0913 21:03:20.990787 12026 layer_factory.hpp:77] Creating layer pool5
I0913 21:03:20.990799 12026 net.cpp:91] Creating Layer pool5
I0913 21:03:20.990804 12026 net.cpp:425] pool5 <- conv5
I0913 21:03:20.990811 12026 net.cpp:399] pool5 -> pool5
I0913 21:03:20.990874 12026 net.cpp:141] Setting up pool5
I0913 21:03:20.990882 12026 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0913 21:03:20.990887 12026 net.cpp:156] Memory required for data: 67618360
I0913 21:03:20.990892 12026 layer_factory.hpp:77] Creating layer fc6
I0913 21:03:20.990914 12026 net.cpp:91] Creating Layer fc6
I0913 21:03:20.990919 12026 net.cpp:425] fc6 <- pool5
I0913 21:03:20.990929 12026 net.cpp:399] fc6 -> fc6
I0913 21:03:21.092267 12026 net.cpp:141] Setting up fc6
I0913 21:03:21.092303 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.092309 12026 net.cpp:156] Memory required for data: 67782200
I0913 21:03:21.092322 12026 layer_factory.hpp:77] Creating layer relu6
I0913 21:03:21.092339 12026 net.cpp:91] Creating Layer relu6
I0913 21:03:21.092344 12026 net.cpp:425] relu6 <- fc6
I0913 21:03:21.092353 12026 net.cpp:386] relu6 -> fc6 (in-place)
I0913 21:03:21.092664 12026 net.cpp:141] Setting up relu6
I0913 21:03:21.092675 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.092680 12026 net.cpp:156] Memory required for data: 67946040
I0913 21:03:21.092685 12026 layer_factory.hpp:77] Creating layer drop6
I0913 21:03:21.092697 12026 net.cpp:91] Creating Layer drop6
I0913 21:03:21.092702 12026 net.cpp:425] drop6 <- fc6
I0913 21:03:21.092710 12026 net.cpp:386] drop6 -> fc6 (in-place)
I0913 21:03:21.092752 12026 net.cpp:141] Setting up drop6
I0913 21:03:21.092761 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.092767 12026 net.cpp:156] Memory required for data: 68109880
I0913 21:03:21.092770 12026 layer_factory.hpp:77] Creating layer fc7
I0913 21:03:21.092784 12026 net.cpp:91] Creating Layer fc7
I0913 21:03:21.092789 12026 net.cpp:425] fc7 <- fc6
I0913 21:03:21.092798 12026 net.cpp:399] fc7 -> fc7
I0913 21:03:21.138079 12026 net.cpp:141] Setting up fc7
I0913 21:03:21.138129 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.138135 12026 net.cpp:156] Memory required for data: 68273720
I0913 21:03:21.138149 12026 layer_factory.hpp:77] Creating layer relu7
I0913 21:03:21.138164 12026 net.cpp:91] Creating Layer relu7
I0913 21:03:21.138170 12026 net.cpp:425] relu7 <- fc7
I0913 21:03:21.138178 12026 net.cpp:386] relu7 -> fc7 (in-place)
I0913 21:03:21.138758 12026 net.cpp:141] Setting up relu7
I0913 21:03:21.138772 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.138777 12026 net.cpp:156] Memory required for data: 68437560
I0913 21:03:21.138782 12026 layer_factory.hpp:77] Creating layer drop7
I0913 21:03:21.138792 12026 net.cpp:91] Creating Layer drop7
I0913 21:03:21.138797 12026 net.cpp:425] drop7 <- fc7
I0913 21:03:21.138806 12026 net.cpp:386] drop7 -> fc7 (in-place)
I0913 21:03:21.138842 12026 net.cpp:141] Setting up drop7
I0913 21:03:21.138854 12026 net.cpp:148] Top shape: 10 4096 (40960)
I0913 21:03:21.138859 12026 net.cpp:156] Memory required for data: 68601400
I0913 21:03:21.138864 12026 layer_factory.hpp:77] Creating layer fc8
I0913 21:03:21.138872 12026 net.cpp:91] Creating Layer fc8
I0913 21:03:21.138877 12026 net.cpp:425] fc8 <- fc7
I0913 21:03:21.138883 12026 net.cpp:399] fc8 -> fc8
I0913 21:03:21.150104 12026 net.cpp:141] Setting up fc8
I0913 21:03:21.150142 12026 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:03:21.150147 12026 net.cpp:156] Memory required for data: 68641400
I0913 21:03:21.150161 12026 layer_factory.hpp:77] Creating layer prob
I0913 21:03:21.150180 12026 net.cpp:91] Creating Layer prob
I0913 21:03:21.150187 12026 net.cpp:425] prob <- fc8
I0913 21:03:21.150197 12026 net.cpp:399] prob -> prob
I0913 21:03:21.150598 12026 net.cpp:141] Setting up prob
I0913 21:03:21.150611 12026 net.cpp:148] Top shape: 10 1000 (10000)
I0913 21:03:21.150616 12026 net.cpp:156] Memory required for data: 68681400
I0913 21:03:21.150622 12026 net.cpp:219] prob does not need backward computation.
I0913 21:03:21.150627 12026 net.cpp:219] fc8 does not need backward computation.
I0913 21:03:21.150632 12026 net.cpp:219] drop7 does not need backward computation.
I0913 21:03:21.150636 12026 net.cpp:219] relu7 does not need backward computation.
I0913 21:03:21.150640 12026 net.cpp:219] fc7 does not need backward computation.
I0913 21:03:21.150645 12026 net.cpp:219] drop6 does not need backward computation.
I0913 21:03:21.150650 12026 net.cpp:219] relu6 does not need backward computation.
I0913 21:03:21.150655 12026 net.cpp:219] fc6 does not need backward computation.
I0913 21:03:21.150658 12026 net.cpp:219] pool5 does not need backward computation.
I0913 21:03:21.150663 12026 net.cpp:219] relu5 does not need backward computation.
I0913 21:03:21.150668 12026 net.cpp:219] conv5 does not need backward computation.
I0913 21:03:21.150673 12026 net.cpp:219] relu4 does not need backward computation.
I0913 21:03:21.150677 12026 net.cpp:219] conv4 does not need backward computation.
I0913 21:03:21.150681 12026 net.cpp:219] relu3 does not need backward computation.
I0913 21:03:21.150686 12026 net.cpp:219] conv3 does not need backward computation.
I0913 21:03:21.150691 12026 net.cpp:219] norm2 does not need backward computation.
I0913 21:03:21.150696 12026 net.cpp:219] pool2 does not need backward computation.
I0913 21:03:21.150701 12026 net.cpp:219] relu2 does not need backward computation.
I0913 21:03:21.150707 12026 net.cpp:219] conv2 does not need backward computation.
I0913 21:03:21.150710 12026 net.cpp:219] norm1 does not need backward computation.
I0913 21:03:21.150715 12026 net.cpp:219] pool1 does not need backward computation.
I0913 21:03:21.150720 12026 net.cpp:219] relu1 does not need backward computation.
I0913 21:03:21.150725 12026 net.cpp:219] conv1 does not need backward computation.
I0913 21:03:21.150729 12026 net.cpp:219] data does not need backward computation.
I0913 21:03:21.150733 12026 net.cpp:261] This network produces output prob
I0913 21:03:21.150764 12026 net.cpp:274] Network initialization done.
I0913 21:03:21.184696 12016 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /home/peifeng/work/run/storm102/data/workers/0d94b8c0-9cca-42bd-b1e6-549ebb919ff0/tmp/cvld6029129470286192933/s2vt.words_to_preds.prototxt
I0913 21:03:21.184743 12016 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0913 21:03:21.184752 12016 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0913 21:03:21.184991 12016 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0913 21:03:21.185083 12016 layer_factory.hpp:77] Creating layer input
I0913 21:03:21.185098 12016 net.cpp:91] Creating Layer input
I0913 21:03:21.185106 12016 net.cpp:399] input -> frames_fc7
I0913 21:03:21.185122 12016 net.cpp:399] input -> cont_sentence
I0913 21:03:21.185132 12016 net.cpp:399] input -> input_sentence
I0913 21:03:21.185142 12016 net.cpp:399] input -> stage_indicator
I0913 21:03:21.185250 12016 net.cpp:141] Setting up input
I0913 21:03:21.185262 12016 net.cpp:148] Top shape: 1 4096 (4096)
I0913 21:03:21.185269 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.185276 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.185281 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.185286 12016 net.cpp:156] Memory required for data: 16396
I0913 21:03:21.185291 12016 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0913 21:03:21.185308 12016 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0913 21:03:21.185313 12016 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0913 21:03:21.185328 12016 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0913 21:03:21.185338 12016 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0913 21:03:21.185385 12016 net.cpp:141] Setting up cont_sentence_input_1_split
I0913 21:03:21.185395 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.185401 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.185406 12016 net.cpp:156] Memory required for data: 16404
I0913 21:03:21.185410 12016 layer_factory.hpp:77] Creating layer embed_encoder
I0913 21:03:21.185422 12016 net.cpp:91] Creating Layer embed_encoder
I0913 21:03:21.185427 12016 net.cpp:425] embed_encoder <- frames_fc7
I0913 21:03:21.185436 12016 net.cpp:399] embed_encoder -> embedded_in_frames
I0913 21:03:21.206128 12016 net.cpp:141] Setting up embed_encoder
I0913 21:03:21.206171 12016 net.cpp:148] Top shape: 1 500 (500)
I0913 21:03:21.206176 12016 net.cpp:156] Memory required for data: 18404
I0913 21:03:21.206194 12016 layer_factory.hpp:77] Creating layer reshape_frames
I0913 21:03:21.206223 12016 net.cpp:91] Creating Layer reshape_frames
I0913 21:03:21.206231 12016 net.cpp:425] reshape_frames <- embedded_in_frames
I0913 21:03:21.206241 12016 net.cpp:399] reshape_frames -> embedded_input_frames
I0913 21:03:21.206297 12016 net.cpp:141] Setting up reshape_frames
I0913 21:03:21.206306 12016 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:03:21.206311 12016 net.cpp:156] Memory required for data: 20404
I0913 21:03:21.206316 12016 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0913 21:03:21.206326 12016 net.cpp:91] Creating Layer reshape_stage_indicator
I0913 21:03:21.206331 12016 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0913 21:03:21.206339 12016 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0913 21:03:21.206374 12016 net.cpp:141] Setting up reshape_stage_indicator
I0913 21:03:21.206383 12016 net.cpp:148] Top shape: 1 1 1 (1)
I0913 21:03:21.206388 12016 net.cpp:156] Memory required for data: 20408
I0913 21:03:21.206393 12016 layer_factory.hpp:77] Creating layer embedding
I0913 21:03:21.206406 12016 net.cpp:91] Creating Layer embedding
I0913 21:03:21.206411 12016 net.cpp:425] embedding <- input_sentence
I0913 21:03:21.206419 12016 net.cpp:399] embedding -> embedded_input_sentence
I0913 21:03:21.401907 12026 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/peifeng/work/run/storm102/data/workers/0d94b8c0-9cca-42bd-b1e6-549ebb919ff0/tmp/cvld6029129470286192933/bvlc_reference_caffenet.caffemodel
I0913 21:03:21.401947 12026 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0913 21:03:21.401952 12026 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0913 21:03:21.401957 12026 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/peifeng/work/run/storm102/data/workers/0d94b8c0-9cca-42bd-b1e6-549ebb919ff0/tmp/cvld6029129470286192933/bvlc_reference_caffenet.caffemodel
I0913 21:03:21.429075 12016 net.cpp:141] Setting up embedding
I0913 21:03:21.429117 12016 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:03:21.429123 12016 net.cpp:156] Memory required for data: 22408
I0913 21:03:21.429139 12016 layer_factory.hpp:77] Creating layer lstm1
I0913 21:03:21.429162 12016 net.cpp:91] Creating Layer lstm1
I0913 21:03:21.429169 12016 net.cpp:425] lstm1 <- embedded_input_frames
I0913 21:03:21.429178 12016 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0913 21:03:21.429188 12016 net.cpp:399] lstm1 -> lstm1
I0913 21:03:21.429210 12016 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:03:21.429551 12016 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:03:21.429638 12016 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:03:21.429651 12016 net.cpp:91] Creating Layer lstm1_
I0913 21:03:21.429657 12016 net.cpp:399] lstm1_ -> x
I0913 21:03:21.429668 12016 net.cpp:399] lstm1_ -> cont
I0913 21:03:21.429731 12016 net.cpp:141] Setting up lstm1_
I0913 21:03:21.429741 12016 net.cpp:148] Top shape: 1 1 500 (500)
I0913 21:03:21.429747 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.429751 12016 net.cpp:156] Memory required for data: 2004
I0913 21:03:21.429765 12016 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:03:21.429774 12016 net.cpp:91] Creating Layer lstm1_
I0913 21:03:21.429782 12016 net.cpp:399] lstm1_ -> c_0
I0913 21:03:21.429792 12016 net.cpp:399] lstm1_ -> h_0
I0913 21:03:21.429847 12016 net.cpp:141] Setting up lstm1_
I0913 21:03:21.429857 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.429862 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.429867 12016 net.cpp:156] Memory required for data: 10004
I0913 21:03:21.429872 12016 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0913 21:03:21.429879 12016 net.cpp:91] Creating Layer lstm1_cont_slice
I0913 21:03:21.429884 12016 net.cpp:425] lstm1_cont_slice <- cont
I0913 21:03:21.429891 12016 net.cpp:399] lstm1_cont_slice -> cont_1
I0913 21:03:21.429927 12016 net.cpp:141] Setting up lstm1_cont_slice
I0913 21:03:21.429936 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.429941 12016 net.cpp:156] Memory required for data: 10008
I0913 21:03:21.429946 12016 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0913 21:03:21.429955 12016 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0913 21:03:21.429960 12016 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0913 21:03:21.429966 12016 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0913 21:03:21.429975 12016 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0913 21:03:21.430022 12016 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0913 21:03:21.430029 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.430035 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.430040 12016 net.cpp:156] Memory required for data: 10016
I0913 21:03:21.430044 12016 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0913 21:03:21.430057 12016 net.cpp:91] Creating Layer lstm1_x_transform
I0913 21:03:21.430061 12016 net.cpp:425] lstm1_x_transform <- x
I0913 21:03:21.430069 12016 net.cpp:399] lstm1_x_transform -> W_xc_x
I0913 21:03:21.450821 12016 net.cpp:141] Setting up lstm1_x_transform
I0913 21:03:21.450863 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.450870 12016 net.cpp:156] Memory required for data: 26016
I0913 21:03:21.450889 12016 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0913 21:03:21.450903 12016 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0913 21:03:21.450911 12016 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0913 21:03:21.450918 12016 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0913 21:03:21.450963 12016 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0913 21:03:21.450973 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.450978 12016 net.cpp:156] Memory required for data: 42016
I0913 21:03:21.450981 12016 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0913 21:03:21.450991 12016 net.cpp:91] Creating Layer lstm1_h_conted_0
I0913 21:03:21.450996 12016 net.cpp:425] lstm1_h_conted_0 <- h_0
I0913 21:03:21.451002 12016 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0913 21:03:21.451009 12016 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0913 21:03:21.451102 12016 net.cpp:141] Setting up lstm1_h_conted_0
I0913 21:03:21.451112 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.451117 12016 net.cpp:156] Memory required for data: 46016
I0913 21:03:21.451120 12016 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0913 21:03:21.451133 12016 net.cpp:91] Creating Layer lstm1_transform_1
I0913 21:03:21.451145 12016 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0913 21:03:21.451155 12016 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0913 21:03:21.489938 12016 net.cpp:141] Setting up lstm1_transform_1
I0913 21:03:21.489989 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.489995 12016 net.cpp:156] Memory required for data: 62016
I0913 21:03:21.490013 12016 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0913 21:03:21.490033 12016 net.cpp:91] Creating Layer lstm1_gate_input_1
I0913 21:03:21.490041 12016 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0913 21:03:21.490048 12016 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0913 21:03:21.490056 12016 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0913 21:03:21.490110 12016 net.cpp:141] Setting up lstm1_gate_input_1
I0913 21:03:21.490120 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.490124 12016 net.cpp:156] Memory required for data: 78016
I0913 21:03:21.490129 12016 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0913 21:03:21.490139 12016 net.cpp:91] Creating Layer lstm1_unit_1
I0913 21:03:21.490144 12016 net.cpp:425] lstm1_unit_1 <- c_0
I0913 21:03:21.490149 12016 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0913 21:03:21.490154 12016 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0913 21:03:21.490164 12016 net.cpp:399] lstm1_unit_1 -> c_1
I0913 21:03:21.490172 12016 net.cpp:399] lstm1_unit_1 -> h_1
I0913 21:03:21.490231 12016 net.cpp:141] Setting up lstm1_unit_1
I0913 21:03:21.490239 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.490245 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.490250 12016 net.cpp:156] Memory required for data: 86016
I0913 21:03:21.490254 12016 layer_factory.hpp:77] Creating layer lstm1_
I0913 21:03:21.490262 12016 net.cpp:91] Creating Layer lstm1_
I0913 21:03:21.490267 12016 net.cpp:425] lstm1_ <- c_1
I0913 21:03:21.490273 12016 net.cpp:399] lstm1_ -> c_T
I0913 21:03:21.490305 12016 net.cpp:141] Setting up lstm1_
I0913 21:03:21.490314 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.490319 12016 net.cpp:156] Memory required for data: 90016
I0913 21:03:21.490324 12016 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0913 21:03:21.490344 12016 net.cpp:91] Creating Layer lstm1_h_concat
I0913 21:03:21.490350 12016 net.cpp:425] lstm1_h_concat <- h_1
I0913 21:03:21.490357 12016 net.cpp:399] lstm1_h_concat -> h
I0913 21:03:21.490389 12016 net.cpp:141] Setting up lstm1_h_concat
I0913 21:03:21.490397 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.490402 12016 net.cpp:156] Memory required for data: 94016
I0913 21:03:21.490406 12016 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:03:21.490427 12016 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:03:21.490432 12016 net.cpp:425] h_pseudoloss <- h
I0913 21:03:21.490438 12016 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:03:21.490525 12016 net.cpp:141] Setting up h_pseudoloss
I0913 21:03:21.490535 12016 net.cpp:148] Top shape: (1)
I0913 21:03:21.490538 12016 net.cpp:151]     with loss weight 1
I0913 21:03:21.490574 12016 net.cpp:156] Memory required for data: 94020
I0913 21:03:21.490581 12016 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:03:21.490584 12016 net.cpp:217] lstm1_h_concat needs backward computation.
I0913 21:03:21.490589 12016 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:03:21.490594 12016 net.cpp:217] lstm1_unit_1 needs backward computation.
I0913 21:03:21.490600 12016 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0913 21:03:21.490604 12016 net.cpp:217] lstm1_transform_1 needs backward computation.
I0913 21:03:21.490609 12016 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0913 21:03:21.490615 12016 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0913 21:03:21.490620 12016 net.cpp:217] lstm1_x_transform needs backward computation.
I0913 21:03:21.490625 12016 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0913 21:03:21.490630 12016 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0913 21:03:21.490635 12016 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:03:21.490640 12016 net.cpp:219] lstm1_ does not need backward computation.
I0913 21:03:21.490643 12016 net.cpp:261] This network produces output c_T
I0913 21:03:21.490648 12016 net.cpp:261] This network produces output h_pseudoloss
I0913 21:03:21.490665 12016 net.cpp:274] Network initialization done.
I0913 21:03:21.490715 12016 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:03:21.490721 12016 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:03:21.490725 12016 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:03:21.490828 12016 net.cpp:141] Setting up lstm1
I0913 21:03:21.490839 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.490844 12016 net.cpp:156] Memory required for data: 26408
I0913 21:03:21.490857 12016 layer_factory.hpp:77] Creating layer concat
I0913 21:03:21.490866 12016 net.cpp:91] Creating Layer concat
I0913 21:03:21.490872 12016 net.cpp:425] concat <- lstm1
I0913 21:03:21.490878 12016 net.cpp:425] concat <- embedded_input_sentence
I0913 21:03:21.490885 12016 net.cpp:425] concat <- reshaped_stage_indicator
I0913 21:03:21.490890 12016 net.cpp:399] concat -> lstm1_video_sequence
I0913 21:03:21.490922 12016 net.cpp:141] Setting up concat
I0913 21:03:21.490931 12016 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:03:21.490936 12016 net.cpp:156] Memory required for data: 32412
I0913 21:03:21.490942 12016 layer_factory.hpp:77] Creating layer lstm2
I0913 21:03:21.490953 12016 net.cpp:91] Creating Layer lstm2
I0913 21:03:21.490958 12016 net.cpp:425] lstm2 <- lstm1_video_sequence
I0913 21:03:21.490964 12016 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0913 21:03:21.490972 12016 net.cpp:399] lstm2 -> lstm2
I0913 21:03:21.490981 12016 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0913 21:03:21.491212 12016 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0913 21:03:21.491294 12016 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:03:21.491307 12016 net.cpp:91] Creating Layer lstm2_
I0913 21:03:21.491313 12016 net.cpp:399] lstm2_ -> x
I0913 21:03:21.491323 12016 net.cpp:399] lstm2_ -> cont
I0913 21:03:21.491375 12016 net.cpp:141] Setting up lstm2_
I0913 21:03:21.491384 12016 net.cpp:148] Top shape: 1 1 1501 (1501)
I0913 21:03:21.491391 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.491395 12016 net.cpp:156] Memory required for data: 6008
I0913 21:03:21.491400 12016 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:03:21.491408 12016 net.cpp:91] Creating Layer lstm2_
I0913 21:03:21.491420 12016 net.cpp:399] lstm2_ -> c_0
I0913 21:03:21.491430 12016 net.cpp:399] lstm2_ -> h_0
I0913 21:03:21.491475 12016 net.cpp:141] Setting up lstm2_
I0913 21:03:21.491483 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.491489 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.491493 12016 net.cpp:156] Memory required for data: 14008
I0913 21:03:21.491498 12016 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0913 21:03:21.491509 12016 net.cpp:91] Creating Layer lstm2_cont_slice
I0913 21:03:21.491514 12016 net.cpp:425] lstm2_cont_slice <- cont
I0913 21:03:21.491521 12016 net.cpp:399] lstm2_cont_slice -> cont_1
I0913 21:03:21.491551 12016 net.cpp:141] Setting up lstm2_cont_slice
I0913 21:03:21.491560 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.491565 12016 net.cpp:156] Memory required for data: 14012
I0913 21:03:21.491570 12016 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0913 21:03:21.491580 12016 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0913 21:03:21.491585 12016 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0913 21:03:21.491591 12016 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0913 21:03:21.491600 12016 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0913 21:03:21.491644 12016 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0913 21:03:21.491652 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.491658 12016 net.cpp:148] Top shape: 1 1 (1)
I0913 21:03:21.491662 12016 net.cpp:156] Memory required for data: 14020
I0913 21:03:21.491667 12016 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0913 21:03:21.491679 12016 net.cpp:91] Creating Layer lstm2_x_transform
I0913 21:03:21.491684 12016 net.cpp:425] lstm2_x_transform <- x
I0913 21:03:21.491691 12016 net.cpp:399] lstm2_x_transform -> W_xc_x
I0913 21:03:21.550202 12016 net.cpp:141] Setting up lstm2_x_transform
I0913 21:03:21.550246 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.550251 12016 net.cpp:156] Memory required for data: 30020
I0913 21:03:21.550269 12016 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0913 21:03:21.550282 12016 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0913 21:03:21.550288 12016 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0913 21:03:21.550297 12016 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0913 21:03:21.550341 12016 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0913 21:03:21.550351 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.550356 12016 net.cpp:156] Memory required for data: 46020
I0913 21:03:21.550360 12016 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0913 21:03:21.550370 12016 net.cpp:91] Creating Layer lstm2_h_conted_0
I0913 21:03:21.550375 12016 net.cpp:425] lstm2_h_conted_0 <- h_0
I0913 21:03:21.550381 12016 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0913 21:03:21.550389 12016 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0913 21:03:21.550475 12016 net.cpp:141] Setting up lstm2_h_conted_0
I0913 21:03:21.550485 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.550489 12016 net.cpp:156] Memory required for data: 50020
I0913 21:03:21.550494 12016 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0913 21:03:21.550504 12016 net.cpp:91] Creating Layer lstm2_transform_1
I0913 21:03:21.550509 12016 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0913 21:03:21.550518 12016 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0913 21:03:21.589614 12016 net.cpp:141] Setting up lstm2_transform_1
I0913 21:03:21.589663 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.589669 12016 net.cpp:156] Memory required for data: 66020
I0913 21:03:21.589689 12016 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0913 21:03:21.589706 12016 net.cpp:91] Creating Layer lstm2_gate_input_1
I0913 21:03:21.589714 12016 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0913 21:03:21.589721 12016 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0913 21:03:21.589728 12016 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0913 21:03:21.589776 12016 net.cpp:141] Setting up lstm2_gate_input_1
I0913 21:03:21.589787 12016 net.cpp:148] Top shape: 1 1 4000 (4000)
I0913 21:03:21.589790 12016 net.cpp:156] Memory required for data: 82020
I0913 21:03:21.589795 12016 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0913 21:03:21.589807 12016 net.cpp:91] Creating Layer lstm2_unit_1
I0913 21:03:21.589812 12016 net.cpp:425] lstm2_unit_1 <- c_0
I0913 21:03:21.589818 12016 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0913 21:03:21.589823 12016 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0913 21:03:21.589828 12016 net.cpp:399] lstm2_unit_1 -> c_1
I0913 21:03:21.589838 12016 net.cpp:399] lstm2_unit_1 -> h_1
I0913 21:03:21.589897 12016 net.cpp:141] Setting up lstm2_unit_1
I0913 21:03:21.589915 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.589921 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.589926 12016 net.cpp:156] Memory required for data: 90020
I0913 21:03:21.589931 12016 layer_factory.hpp:77] Creating layer lstm2_
I0913 21:03:21.589938 12016 net.cpp:91] Creating Layer lstm2_
I0913 21:03:21.589943 12016 net.cpp:425] lstm2_ <- c_1
I0913 21:03:21.589949 12016 net.cpp:399] lstm2_ -> c_T
I0913 21:03:21.589979 12016 net.cpp:141] Setting up lstm2_
I0913 21:03:21.589987 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.589993 12016 net.cpp:156] Memory required for data: 94020
I0913 21:03:21.589998 12016 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0913 21:03:21.590009 12016 net.cpp:91] Creating Layer lstm2_h_concat
I0913 21:03:21.590014 12016 net.cpp:425] lstm2_h_concat <- h_1
I0913 21:03:21.590021 12016 net.cpp:399] lstm2_h_concat -> h
I0913 21:03:21.590056 12016 net.cpp:141] Setting up lstm2_h_concat
I0913 21:03:21.590065 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.590070 12016 net.cpp:156] Memory required for data: 98020
I0913 21:03:21.590073 12016 layer_factory.hpp:77] Creating layer h_pseudoloss
I0913 21:03:21.590082 12016 net.cpp:91] Creating Layer h_pseudoloss
I0913 21:03:21.590087 12016 net.cpp:425] h_pseudoloss <- h
I0913 21:03:21.590096 12016 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0913 21:03:21.590183 12016 net.cpp:141] Setting up h_pseudoloss
I0913 21:03:21.590195 12016 net.cpp:148] Top shape: (1)
I0913 21:03:21.590200 12016 net.cpp:151]     with loss weight 1
I0913 21:03:21.590216 12016 net.cpp:156] Memory required for data: 98024
I0913 21:03:21.590221 12016 net.cpp:217] h_pseudoloss needs backward computation.
I0913 21:03:21.590226 12016 net.cpp:217] lstm2_h_concat needs backward computation.
I0913 21:03:21.590231 12016 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:03:21.590236 12016 net.cpp:217] lstm2_unit_1 needs backward computation.
I0913 21:03:21.590241 12016 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0913 21:03:21.590246 12016 net.cpp:217] lstm2_transform_1 needs backward computation.
I0913 21:03:21.590252 12016 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0913 21:03:21.590257 12016 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0913 21:03:21.590262 12016 net.cpp:217] lstm2_x_transform needs backward computation.
I0913 21:03:21.590267 12016 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0913 21:03:21.590272 12016 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0913 21:03:21.590277 12016 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:03:21.590281 12016 net.cpp:219] lstm2_ does not need backward computation.
I0913 21:03:21.590286 12016 net.cpp:261] This network produces output c_T
I0913 21:03:21.590291 12016 net.cpp:261] This network produces output h_pseudoloss
I0913 21:03:21.590306 12016 net.cpp:274] Network initialization done.
I0913 21:03:21.590353 12016 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0913 21:03:21.590358 12016 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0913 21:03:21.590363 12016 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0913 21:03:21.590456 12016 net.cpp:141] Setting up lstm2
I0913 21:03:21.590467 12016 net.cpp:148] Top shape: 1 1 1000 (1000)
I0913 21:03:21.590472 12016 net.cpp:156] Memory required for data: 36412
I0913 21:03:21.590487 12016 layer_factory.hpp:77] Creating layer predict
I0913 21:03:21.590498 12016 net.cpp:91] Creating Layer predict
I0913 21:03:21.590505 12016 net.cpp:425] predict <- lstm2
I0913 21:03:21.590512 12016 net.cpp:399] predict -> predict
I0913 21:03:21.822252 12026 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0913 21:03:21.869598 12026 net.cpp:752] Ignoring source layer loss
Loading the model + trained: 9815.5ms
Using cv::Size and some other stuff: 0.125ms
I0913 21:03:22.085104 12016 net.cpp:141] Setting up predict
Loading the mean file: 1346.43ms
I0913 21:03:22.085146 12016 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:03:22.085152 12016 net.cpp:156] Memory required for data: 221084
I0913 21:03:22.085166 12016 layer_factory.hpp:77] Creating layer probs
I0913 21:03:22.085181 12016 net.cpp:91] Creating Layer probs
I0913 21:03:22.085188 12016 net.cpp:425] probs <- predict
I0913 21:03:22.085197 12016 net.cpp:399] probs -> probs
I0913 21:03:22.090577 12016 net.cpp:141] Setting up probs
I0913 21:03:22.090620 12016 net.cpp:148] Top shape: 1 1 46168 (46168)
I0913 21:03:22.090626 12016 net.cpp:156] Memory required for data: 405756
I0913 21:03:22.090633 12016 net.cpp:219] probs does not need backward computation.
I0913 21:03:22.090641 12016 net.cpp:219] predict does not need backward computation.
I0913 21:03:22.090646 12016 net.cpp:219] lstm2 does not need backward computation.
I0913 21:03:22.090651 12016 net.cpp:219] concat does not need backward computation.
I0913 21:03:22.090657 12016 net.cpp:219] lstm1 does not need backward computation.
I0913 21:03:22.090663 12016 net.cpp:219] embedding does not need backward computation.
I0913 21:03:22.090668 12016 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0913 21:03:22.090673 12016 net.cpp:219] reshape_frames does not need backward computation.
I0913 21:03:22.090678 12016 net.cpp:219] embed_encoder does not need backward computation.
I0913 21:03:22.090683 12016 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0913 21:03:22.090688 12016 net.cpp:219] input does not need backward computation.
I0913 21:03:22.090692 12016 net.cpp:261] This network produces output probs
I0913 21:03:22.090708 12016 net.cpp:274] Network initialization done.
I0913 21:03:22.781793 12016 net.cpp:752] Ignoring source layer data
I0913 21:03:22.781826 12016 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0913 21:03:22.781834 12016 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0913 21:03:22.851495 12016 net.cpp:752] Ignoring source layer cross_entropy_loss
TIMERTIMER 137327603
TIMERTIMER 65647313
TIMERTIMER 68814370
TIMERTIMER 46945073
TIMERTIMER 47171077
TIMERTIMER 47653093
TIMERTIMER 46902275
TIMERTIMER 48533491
TIMERTIMER 43828261
TIMERTIMER 49130713
TIMERTIMER 47229654
TIMERTIMER 49532620
TIMERTIMER 49316921
TIMERTIMER 52274101
TIMERTIMER 50356977
TIMERTIMER 43858362
