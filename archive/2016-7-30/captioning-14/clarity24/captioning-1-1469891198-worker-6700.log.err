SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1469891198/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-07-30 11:07:01,229 ERROR Logger contains an invalid element or attribute "appender"
2016-07-30 11:07:04,391 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld337845440816689899/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0730 11:07:10.868759 32218 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0730 11:07:10.868964 32218 layer_factory.hpp:77] Creating layer data
I0730 11:07:10.868990 32218 net.cpp:91] Creating Layer data
I0730 11:07:10.869001 32218 net.cpp:399] data -> data
I0730 11:07:11.459197 32218 net.cpp:141] Setting up data
I0730 11:07:11.459306 32218 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0730 11:07:11.459316 32218 net.cpp:156] Memory required for data: 6183480
I0730 11:07:11.459337 32218 layer_factory.hpp:77] Creating layer conv1
I0730 11:07:11.459377 32218 net.cpp:91] Creating Layer conv1
I0730 11:07:11.459388 32218 net.cpp:425] conv1 <- data
I0730 11:07:11.459403 32218 net.cpp:399] conv1 -> conv1
I0730 11:07:11.459529 32208 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld337845440816689899/s2vt.words_to_preds.prototxt
I0730 11:07:11.459569 32208 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0730 11:07:11.459578 32208 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0730 11:07:11.459888 32208 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0730 11:07:11.460000 32208 layer_factory.hpp:77] Creating layer input
I0730 11:07:11.460016 32208 net.cpp:91] Creating Layer input
I0730 11:07:11.460023 32208 net.cpp:399] input -> frames_fc7
I0730 11:07:11.460039 32208 net.cpp:399] input -> cont_sentence
I0730 11:07:11.460052 32208 net.cpp:399] input -> input_sentence
I0730 11:07:11.460062 32208 net.cpp:399] input -> stage_indicator
I0730 11:07:11.461488 32208 net.cpp:141] Setting up input
I0730 11:07:11.461508 32208 net.cpp:148] Top shape: 1 4096 (4096)
I0730 11:07:11.461515 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.461521 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.461529 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.461532 32208 net.cpp:156] Memory required for data: 16396
I0730 11:07:11.461539 32208 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0730 11:07:11.461555 32208 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0730 11:07:11.461561 32208 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0730 11:07:11.461585 32208 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0730 11:07:11.461597 32208 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0730 11:07:11.461650 32208 net.cpp:141] Setting up cont_sentence_input_1_split
I0730 11:07:11.461663 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.461669 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.461673 32208 net.cpp:156] Memory required for data: 16404
I0730 11:07:11.461678 32208 layer_factory.hpp:77] Creating layer embed_encoder
I0730 11:07:11.461710 32208 net.cpp:91] Creating Layer embed_encoder
I0730 11:07:11.461719 32208 net.cpp:425] embed_encoder <- frames_fc7
I0730 11:07:11.461729 32208 net.cpp:399] embed_encoder -> embedded_in_frames
I0730 11:07:11.486577 32208 net.cpp:141] Setting up embed_encoder
I0730 11:07:11.486632 32208 net.cpp:148] Top shape: 1 500 (500)
I0730 11:07:11.486639 32208 net.cpp:156] Memory required for data: 18404
I0730 11:07:11.486672 32208 layer_factory.hpp:77] Creating layer reshape_frames
I0730 11:07:11.486716 32208 net.cpp:91] Creating Layer reshape_frames
I0730 11:07:11.486726 32208 net.cpp:425] reshape_frames <- embedded_in_frames
I0730 11:07:11.486739 32208 net.cpp:399] reshape_frames -> embedded_input_frames
I0730 11:07:11.486940 32208 net.cpp:141] Setting up reshape_frames
I0730 11:07:11.486953 32208 net.cpp:148] Top shape: 1 1 500 (500)
I0730 11:07:11.486956 32208 net.cpp:156] Memory required for data: 20404
I0730 11:07:11.486961 32208 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0730 11:07:11.486974 32208 net.cpp:91] Creating Layer reshape_stage_indicator
I0730 11:07:11.486980 32208 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0730 11:07:11.486994 32208 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0730 11:07:11.487694 32208 net.cpp:141] Setting up reshape_stage_indicator
I0730 11:07:11.487714 32208 net.cpp:148] Top shape: 1 1 1 (1)
I0730 11:07:11.487718 32208 net.cpp:156] Memory required for data: 20408
I0730 11:07:11.487725 32208 layer_factory.hpp:77] Creating layer embedding
I0730 11:07:11.487740 32208 net.cpp:91] Creating Layer embedding
I0730 11:07:11.487746 32208 net.cpp:425] embedding <- input_sentence
I0730 11:07:11.487756 32208 net.cpp:399] embedding -> embedded_input_sentence
I0730 11:07:11.739641 32208 net.cpp:141] Setting up embedding
I0730 11:07:11.739701 32208 net.cpp:148] Top shape: 1 1 500 (500)
I0730 11:07:11.739707 32208 net.cpp:156] Memory required for data: 22408
I0730 11:07:11.739729 32208 layer_factory.hpp:77] Creating layer lstm1
I0730 11:07:11.739756 32208 net.cpp:91] Creating Layer lstm1
I0730 11:07:11.739765 32208 net.cpp:425] lstm1 <- embedded_input_frames
I0730 11:07:11.739775 32208 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0730 11:07:11.739789 32208 net.cpp:399] lstm1 -> lstm1
I0730 11:07:11.739828 32208 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0730 11:07:11.740269 32208 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0730 11:07:11.740376 32208 layer_factory.hpp:77] Creating layer lstm1_
I0730 11:07:11.740391 32208 net.cpp:91] Creating Layer lstm1_
I0730 11:07:11.740398 32208 net.cpp:399] lstm1_ -> x
I0730 11:07:11.740412 32208 net.cpp:399] lstm1_ -> cont
I0730 11:07:11.750340 32208 net.cpp:141] Setting up lstm1_
I0730 11:07:11.750360 32208 net.cpp:148] Top shape: 1 1 500 (500)
I0730 11:07:11.750368 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.750372 32208 net.cpp:156] Memory required for data: 2004
I0730 11:07:11.750378 32208 layer_factory.hpp:77] Creating layer lstm1_
I0730 11:07:11.750391 32208 net.cpp:91] Creating Layer lstm1_
I0730 11:07:11.750402 32208 net.cpp:399] lstm1_ -> c_0
I0730 11:07:11.750416 32208 net.cpp:399] lstm1_ -> h_0
I0730 11:07:11.750476 32208 net.cpp:141] Setting up lstm1_
I0730 11:07:11.750488 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.750494 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.750497 32208 net.cpp:156] Memory required for data: 10004
I0730 11:07:11.750502 32208 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0730 11:07:11.750515 32208 net.cpp:91] Creating Layer lstm1_cont_slice
I0730 11:07:11.750520 32208 net.cpp:425] lstm1_cont_slice <- cont
I0730 11:07:11.750531 32208 net.cpp:399] lstm1_cont_slice -> cont_1
I0730 11:07:11.750571 32208 net.cpp:141] Setting up lstm1_cont_slice
I0730 11:07:11.750581 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.750586 32208 net.cpp:156] Memory required for data: 10008
I0730 11:07:11.750591 32208 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0730 11:07:11.750599 32208 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0730 11:07:11.750604 32208 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0730 11:07:11.750614 32208 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0730 11:07:11.750623 32208 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0730 11:07:11.754366 32208 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0730 11:07:11.754386 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.754393 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.754397 32208 net.cpp:156] Memory required for data: 10016
I0730 11:07:11.754403 32208 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0730 11:07:11.754416 32208 net.cpp:91] Creating Layer lstm1_x_transform
I0730 11:07:11.754422 32208 net.cpp:425] lstm1_x_transform <- x
I0730 11:07:11.754431 32208 net.cpp:399] lstm1_x_transform -> W_xc_x
I0730 11:07:11.775136 32218 net.cpp:141] Setting up conv1
I0730 11:07:11.775189 32218 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0730 11:07:11.775197 32218 net.cpp:156] Memory required for data: 17799480
I0730 11:07:11.775223 32218 layer_factory.hpp:77] Creating layer relu1
I0730 11:07:11.775241 32218 net.cpp:91] Creating Layer relu1
I0730 11:07:11.775249 32218 net.cpp:425] relu1 <- conv1
I0730 11:07:11.775256 32218 net.cpp:386] relu1 -> conv1 (in-place)
I0730 11:07:11.776011 32218 net.cpp:141] Setting up relu1
I0730 11:07:11.776026 32218 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0730 11:07:11.776032 32218 net.cpp:156] Memory required for data: 29415480
I0730 11:07:11.776038 32218 layer_factory.hpp:77] Creating layer pool1
I0730 11:07:11.776051 32218 net.cpp:91] Creating Layer pool1
I0730 11:07:11.776056 32218 net.cpp:425] pool1 <- conv1
I0730 11:07:11.776064 32218 net.cpp:399] pool1 -> pool1
I0730 11:07:11.776135 32218 net.cpp:141] Setting up pool1
I0730 11:07:11.776147 32218 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0730 11:07:11.776152 32218 net.cpp:156] Memory required for data: 32214840
I0730 11:07:11.776157 32218 layer_factory.hpp:77] Creating layer norm1
I0730 11:07:11.776175 32218 net.cpp:91] Creating Layer norm1
I0730 11:07:11.776180 32218 net.cpp:425] norm1 <- pool1
I0730 11:07:11.776187 32218 net.cpp:399] norm1 -> norm1
I0730 11:07:11.777206 32208 net.cpp:141] Setting up lstm1_x_transform
I0730 11:07:11.777248 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.777254 32208 net.cpp:156] Memory required for data: 26016
I0730 11:07:11.777276 32208 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0730 11:07:11.777283 32218 net.cpp:141] Setting up norm1
I0730 11:07:11.777294 32208 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0730 11:07:11.777300 32218 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0730 11:07:11.777302 32208 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0730 11:07:11.777308 32218 net.cpp:156] Memory required for data: 35014200
I0730 11:07:11.777315 32208 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0730 11:07:11.777315 32218 layer_factory.hpp:77] Creating layer conv2
I0730 11:07:11.777346 32218 net.cpp:91] Creating Layer conv2
I0730 11:07:11.777354 32218 net.cpp:425] conv2 <- norm1
I0730 11:07:11.777361 32218 net.cpp:399] conv2 -> conv2
I0730 11:07:11.777384 32208 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0730 11:07:11.777396 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.777401 32208 net.cpp:156] Memory required for data: 42016
I0730 11:07:11.777406 32208 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0730 11:07:11.777417 32208 net.cpp:91] Creating Layer lstm1_h_conted_0
I0730 11:07:11.777423 32208 net.cpp:425] lstm1_h_conted_0 <- h_0
I0730 11:07:11.777431 32208 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0730 11:07:11.777437 32208 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0730 11:07:11.777719 32208 net.cpp:141] Setting up lstm1_h_conted_0
I0730 11:07:11.777731 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.777736 32208 net.cpp:156] Memory required for data: 46016
I0730 11:07:11.777742 32208 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0730 11:07:11.777757 32208 net.cpp:91] Creating Layer lstm1_transform_1
I0730 11:07:11.777762 32208 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0730 11:07:11.777771 32208 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0730 11:07:11.790820 32218 net.cpp:141] Setting up conv2
I0730 11:07:11.790844 32218 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0730 11:07:11.790850 32218 net.cpp:156] Memory required for data: 42479160
I0730 11:07:11.790869 32218 layer_factory.hpp:77] Creating layer relu2
I0730 11:07:11.790880 32218 net.cpp:91] Creating Layer relu2
I0730 11:07:11.790886 32218 net.cpp:425] relu2 <- conv2
I0730 11:07:11.790896 32218 net.cpp:386] relu2 -> conv2 (in-place)
I0730 11:07:11.791682 32218 net.cpp:141] Setting up relu2
I0730 11:07:11.791697 32218 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0730 11:07:11.791702 32218 net.cpp:156] Memory required for data: 49944120
I0730 11:07:11.791710 32218 layer_factory.hpp:77] Creating layer pool2
I0730 11:07:11.791723 32218 net.cpp:91] Creating Layer pool2
I0730 11:07:11.791728 32218 net.cpp:425] pool2 <- conv2
I0730 11:07:11.791736 32218 net.cpp:399] pool2 -> pool2
I0730 11:07:11.791803 32218 net.cpp:141] Setting up pool2
I0730 11:07:11.791815 32218 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 11:07:11.791818 32218 net.cpp:156] Memory required for data: 51674680
I0730 11:07:11.791823 32218 layer_factory.hpp:77] Creating layer norm2
I0730 11:07:11.791834 32218 net.cpp:91] Creating Layer norm2
I0730 11:07:11.791839 32218 net.cpp:425] norm2 <- pool2
I0730 11:07:11.791851 32218 net.cpp:399] norm2 -> norm2
I0730 11:07:11.792135 32218 net.cpp:141] Setting up norm2
I0730 11:07:11.792146 32218 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 11:07:11.792151 32218 net.cpp:156] Memory required for data: 53405240
I0730 11:07:11.792157 32218 layer_factory.hpp:77] Creating layer conv3
I0730 11:07:11.792168 32218 net.cpp:91] Creating Layer conv3
I0730 11:07:11.792174 32218 net.cpp:425] conv3 <- norm2
I0730 11:07:11.792186 32218 net.cpp:399] conv3 -> conv3
I0730 11:07:11.797639 32218 net.cpp:141] Setting up conv3
I0730 11:07:11.797667 32218 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 11:07:11.797673 32218 net.cpp:156] Memory required for data: 56001080
I0730 11:07:11.797693 32218 layer_factory.hpp:77] Creating layer relu3
I0730 11:07:11.797704 32218 net.cpp:91] Creating Layer relu3
I0730 11:07:11.797710 32218 net.cpp:425] relu3 <- conv3
I0730 11:07:11.797720 32218 net.cpp:386] relu3 -> conv3 (in-place)
I0730 11:07:11.798785 32218 net.cpp:141] Setting up relu3
I0730 11:07:11.798809 32218 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 11:07:11.798817 32218 net.cpp:156] Memory required for data: 58596920
I0730 11:07:11.798826 32218 layer_factory.hpp:77] Creating layer conv4
I0730 11:07:11.798854 32218 net.cpp:91] Creating Layer conv4
I0730 11:07:11.798864 32218 net.cpp:425] conv4 <- conv3
I0730 11:07:11.798877 32218 net.cpp:399] conv4 -> conv4
I0730 11:07:11.804891 32218 net.cpp:141] Setting up conv4
I0730 11:07:11.804919 32218 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 11:07:11.804924 32218 net.cpp:156] Memory required for data: 61192760
I0730 11:07:11.804936 32218 layer_factory.hpp:77] Creating layer relu4
I0730 11:07:11.804950 32218 net.cpp:91] Creating Layer relu4
I0730 11:07:11.804956 32218 net.cpp:425] relu4 <- conv4
I0730 11:07:11.804968 32218 net.cpp:386] relu4 -> conv4 (in-place)
I0730 11:07:11.805763 32218 net.cpp:141] Setting up relu4
I0730 11:07:11.805778 32218 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 11:07:11.805783 32218 net.cpp:156] Memory required for data: 63788600
I0730 11:07:11.805788 32218 layer_factory.hpp:77] Creating layer conv5
I0730 11:07:11.805809 32218 net.cpp:91] Creating Layer conv5
I0730 11:07:11.805815 32218 net.cpp:425] conv5 <- conv4
I0730 11:07:11.805826 32218 net.cpp:399] conv5 -> conv5
I0730 11:07:11.812008 32218 net.cpp:141] Setting up conv5
I0730 11:07:11.812036 32218 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 11:07:11.812042 32218 net.cpp:156] Memory required for data: 65519160
I0730 11:07:11.812059 32218 layer_factory.hpp:77] Creating layer relu5
I0730 11:07:11.812070 32218 net.cpp:91] Creating Layer relu5
I0730 11:07:11.812077 32218 net.cpp:425] relu5 <- conv5
I0730 11:07:11.812088 32218 net.cpp:386] relu5 -> conv5 (in-place)
I0730 11:07:11.812899 32218 net.cpp:141] Setting up relu5
I0730 11:07:11.812917 32218 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 11:07:11.812922 32218 net.cpp:156] Memory required for data: 67249720
I0730 11:07:11.812928 32218 layer_factory.hpp:77] Creating layer pool5
I0730 11:07:11.812942 32218 net.cpp:91] Creating Layer pool5
I0730 11:07:11.812948 32218 net.cpp:425] pool5 <- conv5
I0730 11:07:11.812957 32218 net.cpp:399] pool5 -> pool5
I0730 11:07:11.813029 32218 net.cpp:141] Setting up pool5
I0730 11:07:11.813045 32218 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0730 11:07:11.813055 32218 net.cpp:156] Memory required for data: 67618360
I0730 11:07:11.813065 32218 layer_factory.hpp:77] Creating layer fc6
I0730 11:07:11.813081 32218 net.cpp:91] Creating Layer fc6
I0730 11:07:11.813086 32218 net.cpp:425] fc6 <- pool5
I0730 11:07:11.813093 32218 net.cpp:399] fc6 -> fc6
I0730 11:07:11.882766 32208 net.cpp:141] Setting up lstm1_transform_1
I0730 11:07:11.882830 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.882838 32208 net.cpp:156] Memory required for data: 62016
I0730 11:07:11.882866 32208 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0730 11:07:11.882905 32208 net.cpp:91] Creating Layer lstm1_gate_input_1
I0730 11:07:11.882915 32208 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0730 11:07:11.882925 32208 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0730 11:07:11.882935 32208 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0730 11:07:11.883015 32208 net.cpp:141] Setting up lstm1_gate_input_1
I0730 11:07:11.883026 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.883031 32208 net.cpp:156] Memory required for data: 78016
I0730 11:07:11.883036 32208 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0730 11:07:11.883046 32208 net.cpp:91] Creating Layer lstm1_unit_1
I0730 11:07:11.883051 32208 net.cpp:425] lstm1_unit_1 <- c_0
I0730 11:07:11.883059 32208 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0730 11:07:11.883064 32208 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0730 11:07:11.883072 32208 net.cpp:399] lstm1_unit_1 -> c_1
I0730 11:07:11.883082 32208 net.cpp:399] lstm1_unit_1 -> h_1
I0730 11:07:11.883152 32208 net.cpp:141] Setting up lstm1_unit_1
I0730 11:07:11.883162 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.883168 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.883172 32208 net.cpp:156] Memory required for data: 86016
I0730 11:07:11.883177 32208 layer_factory.hpp:77] Creating layer lstm1_
I0730 11:07:11.883189 32208 net.cpp:91] Creating Layer lstm1_
I0730 11:07:11.883194 32208 net.cpp:425] lstm1_ <- c_1
I0730 11:07:11.883201 32208 net.cpp:399] lstm1_ -> c_T
I0730 11:07:11.883235 32208 net.cpp:141] Setting up lstm1_
I0730 11:07:11.883244 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.883249 32208 net.cpp:156] Memory required for data: 90016
I0730 11:07:11.883255 32208 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0730 11:07:11.883268 32208 net.cpp:91] Creating Layer lstm1_h_concat
I0730 11:07:11.883275 32208 net.cpp:425] lstm1_h_concat <- h_1
I0730 11:07:11.883281 32208 net.cpp:399] lstm1_h_concat -> h
I0730 11:07:11.883333 32208 net.cpp:141] Setting up lstm1_h_concat
I0730 11:07:11.883343 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.883347 32208 net.cpp:156] Memory required for data: 94016
I0730 11:07:11.883352 32208 layer_factory.hpp:77] Creating layer h_pseudoloss
I0730 11:07:11.883368 32208 net.cpp:91] Creating Layer h_pseudoloss
I0730 11:07:11.883373 32208 net.cpp:425] h_pseudoloss <- h
I0730 11:07:11.883383 32208 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0730 11:07:11.883476 32208 net.cpp:141] Setting up h_pseudoloss
I0730 11:07:11.883487 32208 net.cpp:148] Top shape: (1)
I0730 11:07:11.883492 32208 net.cpp:151]     with loss weight 1
I0730 11:07:11.883543 32208 net.cpp:156] Memory required for data: 94020
I0730 11:07:11.883549 32208 net.cpp:217] h_pseudoloss needs backward computation.
I0730 11:07:11.883555 32208 net.cpp:217] lstm1_h_concat needs backward computation.
I0730 11:07:11.883560 32208 net.cpp:219] lstm1_ does not need backward computation.
I0730 11:07:11.883565 32208 net.cpp:217] lstm1_unit_1 needs backward computation.
I0730 11:07:11.883571 32208 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0730 11:07:11.883576 32208 net.cpp:217] lstm1_transform_1 needs backward computation.
I0730 11:07:11.883581 32208 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0730 11:07:11.883587 32208 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0730 11:07:11.883592 32208 net.cpp:217] lstm1_x_transform needs backward computation.
I0730 11:07:11.883599 32208 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0730 11:07:11.883606 32208 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0730 11:07:11.883612 32208 net.cpp:219] lstm1_ does not need backward computation.
I0730 11:07:11.883617 32208 net.cpp:219] lstm1_ does not need backward computation.
I0730 11:07:11.883620 32208 net.cpp:261] This network produces output c_T
I0730 11:07:11.883625 32208 net.cpp:261] This network produces output h_pseudoloss
I0730 11:07:11.883643 32208 net.cpp:274] Network initialization done.
I0730 11:07:11.883711 32208 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0730 11:07:11.883718 32208 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0730 11:07:11.883723 32208 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0730 11:07:11.883849 32208 net.cpp:141] Setting up lstm1
I0730 11:07:11.883862 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.883867 32208 net.cpp:156] Memory required for data: 26408
I0730 11:07:11.883882 32208 layer_factory.hpp:77] Creating layer concat
I0730 11:07:11.883893 32208 net.cpp:91] Creating Layer concat
I0730 11:07:11.883898 32208 net.cpp:425] concat <- lstm1
I0730 11:07:11.883906 32208 net.cpp:425] concat <- embedded_input_sentence
I0730 11:07:11.883913 32208 net.cpp:425] concat <- reshaped_stage_indicator
I0730 11:07:11.883919 32208 net.cpp:399] concat -> lstm1_video_sequence
I0730 11:07:11.883955 32208 net.cpp:141] Setting up concat
I0730 11:07:11.883965 32208 net.cpp:148] Top shape: 1 1 1501 (1501)
I0730 11:07:11.883970 32208 net.cpp:156] Memory required for data: 32412
I0730 11:07:11.883975 32208 layer_factory.hpp:77] Creating layer lstm2
I0730 11:07:11.883990 32208 net.cpp:91] Creating Layer lstm2
I0730 11:07:11.883994 32208 net.cpp:425] lstm2 <- lstm1_video_sequence
I0730 11:07:11.884001 32208 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0730 11:07:11.884009 32208 net.cpp:399] lstm2 -> lstm2
I0730 11:07:11.884021 32208 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0730 11:07:11.884325 32208 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0730 11:07:11.884426 32208 layer_factory.hpp:77] Creating layer lstm2_
I0730 11:07:11.884440 32208 net.cpp:91] Creating Layer lstm2_
I0730 11:07:11.884448 32208 net.cpp:399] lstm2_ -> x
I0730 11:07:11.884459 32208 net.cpp:399] lstm2_ -> cont
I0730 11:07:11.884526 32208 net.cpp:141] Setting up lstm2_
I0730 11:07:11.884536 32208 net.cpp:148] Top shape: 1 1 1501 (1501)
I0730 11:07:11.884543 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.884547 32208 net.cpp:156] Memory required for data: 6008
I0730 11:07:11.884553 32208 layer_factory.hpp:77] Creating layer lstm2_
I0730 11:07:11.884562 32208 net.cpp:91] Creating Layer lstm2_
I0730 11:07:11.884568 32208 net.cpp:399] lstm2_ -> c_0
I0730 11:07:11.884579 32208 net.cpp:399] lstm2_ -> h_0
I0730 11:07:11.884632 32208 net.cpp:141] Setting up lstm2_
I0730 11:07:11.884641 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.884649 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.884652 32208 net.cpp:156] Memory required for data: 14008
I0730 11:07:11.884656 32208 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0730 11:07:11.884665 32208 net.cpp:91] Creating Layer lstm2_cont_slice
I0730 11:07:11.884670 32208 net.cpp:425] lstm2_cont_slice <- cont
I0730 11:07:11.884678 32208 net.cpp:399] lstm2_cont_slice -> cont_1
I0730 11:07:11.884716 32208 net.cpp:141] Setting up lstm2_cont_slice
I0730 11:07:11.884727 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.884732 32208 net.cpp:156] Memory required for data: 14012
I0730 11:07:11.884737 32208 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0730 11:07:11.884747 32208 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0730 11:07:11.884752 32208 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0730 11:07:11.884758 32208 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0730 11:07:11.884768 32208 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0730 11:07:11.884820 32208 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0730 11:07:11.884829 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.884835 32208 net.cpp:148] Top shape: 1 1 (1)
I0730 11:07:11.884840 32208 net.cpp:156] Memory required for data: 14020
I0730 11:07:11.884845 32208 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0730 11:07:11.884855 32208 net.cpp:91] Creating Layer lstm2_x_transform
I0730 11:07:11.884860 32208 net.cpp:425] lstm2_x_transform <- x
I0730 11:07:11.884871 32208 net.cpp:399] lstm2_x_transform -> W_xc_x
I0730 11:07:11.924343 32218 net.cpp:141] Setting up fc6
I0730 11:07:11.924391 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.924397 32218 net.cpp:156] Memory required for data: 67782200
I0730 11:07:11.924412 32218 layer_factory.hpp:77] Creating layer relu6
I0730 11:07:11.924437 32218 net.cpp:91] Creating Layer relu6
I0730 11:07:11.924445 32218 net.cpp:425] relu6 <- fc6
I0730 11:07:11.924455 32218 net.cpp:386] relu6 -> fc6 (in-place)
I0730 11:07:11.924805 32218 net.cpp:141] Setting up relu6
I0730 11:07:11.924818 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.924823 32218 net.cpp:156] Memory required for data: 67946040
I0730 11:07:11.924829 32218 layer_factory.hpp:77] Creating layer drop6
I0730 11:07:11.924840 32218 net.cpp:91] Creating Layer drop6
I0730 11:07:11.924845 32218 net.cpp:425] drop6 <- fc6
I0730 11:07:11.924860 32218 net.cpp:386] drop6 -> fc6 (in-place)
I0730 11:07:11.924916 32218 net.cpp:141] Setting up drop6
I0730 11:07:11.924926 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.924931 32218 net.cpp:156] Memory required for data: 68109880
I0730 11:07:11.924935 32218 layer_factory.hpp:77] Creating layer fc7
I0730 11:07:11.924947 32218 net.cpp:91] Creating Layer fc7
I0730 11:07:11.924952 32218 net.cpp:425] fc7 <- fc6
I0730 11:07:11.924958 32218 net.cpp:399] fc7 -> fc7
I0730 11:07:11.956710 32208 net.cpp:141] Setting up lstm2_x_transform
I0730 11:07:11.956774 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.956781 32208 net.cpp:156] Memory required for data: 30020
I0730 11:07:11.956809 32208 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0730 11:07:11.956828 32208 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0730 11:07:11.956836 32208 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0730 11:07:11.956848 32208 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0730 11:07:11.956903 32208 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0730 11:07:11.956915 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:11.956920 32208 net.cpp:156] Memory required for data: 46020
I0730 11:07:11.956925 32208 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0730 11:07:11.956936 32208 net.cpp:91] Creating Layer lstm2_h_conted_0
I0730 11:07:11.956943 32208 net.cpp:425] lstm2_h_conted_0 <- h_0
I0730 11:07:11.956949 32208 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0730 11:07:11.956957 32208 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0730 11:07:11.957062 32208 net.cpp:141] Setting up lstm2_h_conted_0
I0730 11:07:11.957072 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:11.957077 32208 net.cpp:156] Memory required for data: 50020
I0730 11:07:11.957082 32208 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0730 11:07:11.957096 32208 net.cpp:91] Creating Layer lstm2_transform_1
I0730 11:07:11.957103 32208 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0730 11:07:11.957110 32208 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0730 11:07:11.976307 32218 net.cpp:141] Setting up fc7
I0730 11:07:11.976358 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.976366 32218 net.cpp:156] Memory required for data: 68273720
I0730 11:07:11.976382 32218 layer_factory.hpp:77] Creating layer relu7
I0730 11:07:11.976405 32218 net.cpp:91] Creating Layer relu7
I0730 11:07:11.976413 32218 net.cpp:425] relu7 <- fc7
I0730 11:07:11.976423 32218 net.cpp:386] relu7 -> fc7 (in-place)
I0730 11:07:11.977990 32218 net.cpp:141] Setting up relu7
I0730 11:07:11.978009 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.978015 32218 net.cpp:156] Memory required for data: 68437560
I0730 11:07:11.978020 32218 layer_factory.hpp:77] Creating layer drop7
I0730 11:07:11.978037 32218 net.cpp:91] Creating Layer drop7
I0730 11:07:11.978044 32218 net.cpp:425] drop7 <- fc7
I0730 11:07:11.978051 32218 net.cpp:386] drop7 -> fc7 (in-place)
I0730 11:07:11.978101 32218 net.cpp:141] Setting up drop7
I0730 11:07:11.978111 32218 net.cpp:148] Top shape: 10 4096 (40960)
I0730 11:07:11.978116 32218 net.cpp:156] Memory required for data: 68601400
I0730 11:07:11.978119 32218 layer_factory.hpp:77] Creating layer fc8
I0730 11:07:11.978130 32218 net.cpp:91] Creating Layer fc8
I0730 11:07:11.978135 32218 net.cpp:425] fc8 <- fc7
I0730 11:07:11.978150 32218 net.cpp:399] fc8 -> fc8
I0730 11:07:11.991492 32218 net.cpp:141] Setting up fc8
I0730 11:07:11.991539 32218 net.cpp:148] Top shape: 10 1000 (10000)
I0730 11:07:11.991545 32218 net.cpp:156] Memory required for data: 68641400
I0730 11:07:11.991560 32218 layer_factory.hpp:77] Creating layer prob
I0730 11:07:11.991585 32218 net.cpp:91] Creating Layer prob
I0730 11:07:11.991592 32218 net.cpp:425] prob <- fc8
I0730 11:07:11.991603 32218 net.cpp:399] prob -> prob
I0730 11:07:11.992054 32218 net.cpp:141] Setting up prob
I0730 11:07:11.992068 32218 net.cpp:148] Top shape: 10 1000 (10000)
I0730 11:07:11.992072 32218 net.cpp:156] Memory required for data: 68681400
I0730 11:07:11.992079 32218 net.cpp:219] prob does not need backward computation.
I0730 11:07:11.992084 32218 net.cpp:219] fc8 does not need backward computation.
I0730 11:07:11.992089 32218 net.cpp:219] drop7 does not need backward computation.
I0730 11:07:11.992094 32218 net.cpp:219] relu7 does not need backward computation.
I0730 11:07:11.992099 32218 net.cpp:219] fc7 does not need backward computation.
I0730 11:07:11.992103 32218 net.cpp:219] drop6 does not need backward computation.
I0730 11:07:11.992107 32218 net.cpp:219] relu6 does not need backward computation.
I0730 11:07:11.992112 32218 net.cpp:219] fc6 does not need backward computation.
I0730 11:07:11.992116 32218 net.cpp:219] pool5 does not need backward computation.
I0730 11:07:11.992121 32218 net.cpp:219] relu5 does not need backward computation.
I0730 11:07:11.992126 32218 net.cpp:219] conv5 does not need backward computation.
I0730 11:07:11.992131 32218 net.cpp:219] relu4 does not need backward computation.
I0730 11:07:11.992136 32218 net.cpp:219] conv4 does not need backward computation.
I0730 11:07:11.992139 32218 net.cpp:219] relu3 does not need backward computation.
I0730 11:07:11.992144 32218 net.cpp:219] conv3 does not need backward computation.
I0730 11:07:11.992149 32218 net.cpp:219] norm2 does not need backward computation.
I0730 11:07:11.992154 32218 net.cpp:219] pool2 does not need backward computation.
I0730 11:07:11.992159 32218 net.cpp:219] relu2 does not need backward computation.
I0730 11:07:11.992163 32218 net.cpp:219] conv2 does not need backward computation.
I0730 11:07:11.992168 32218 net.cpp:219] norm1 does not need backward computation.
I0730 11:07:11.992173 32218 net.cpp:219] pool1 does not need backward computation.
I0730 11:07:11.992178 32218 net.cpp:219] relu1 does not need backward computation.
I0730 11:07:11.992182 32218 net.cpp:219] conv1 does not need backward computation.
I0730 11:07:11.992187 32218 net.cpp:219] data does not need backward computation.
I0730 11:07:11.992192 32218 net.cpp:261] This network produces output prob
I0730 11:07:11.992211 32218 net.cpp:274] Network initialization done.
I0730 11:07:12.000516 32208 net.cpp:141] Setting up lstm2_transform_1
I0730 11:07:12.000579 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:12.000586 32208 net.cpp:156] Memory required for data: 66020
I0730 11:07:12.000610 32208 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0730 11:07:12.000633 32208 net.cpp:91] Creating Layer lstm2_gate_input_1
I0730 11:07:12.000641 32208 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0730 11:07:12.000651 32208 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0730 11:07:12.000660 32208 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0730 11:07:12.000718 32208 net.cpp:141] Setting up lstm2_gate_input_1
I0730 11:07:12.000728 32208 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 11:07:12.000732 32208 net.cpp:156] Memory required for data: 82020
I0730 11:07:12.000737 32208 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0730 11:07:12.000749 32208 net.cpp:91] Creating Layer lstm2_unit_1
I0730 11:07:12.000756 32208 net.cpp:425] lstm2_unit_1 <- c_0
I0730 11:07:12.000761 32208 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0730 11:07:12.000767 32208 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0730 11:07:12.000776 32208 net.cpp:399] lstm2_unit_1 -> c_1
I0730 11:07:12.000784 32208 net.cpp:399] lstm2_unit_1 -> h_1
I0730 11:07:12.000854 32208 net.cpp:141] Setting up lstm2_unit_1
I0730 11:07:12.000865 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:12.000871 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:12.000876 32208 net.cpp:156] Memory required for data: 90020
I0730 11:07:12.000880 32208 layer_factory.hpp:77] Creating layer lstm2_
I0730 11:07:12.000890 32208 net.cpp:91] Creating Layer lstm2_
I0730 11:07:12.000895 32208 net.cpp:425] lstm2_ <- c_1
I0730 11:07:12.000903 32208 net.cpp:399] lstm2_ -> c_T
I0730 11:07:12.000936 32208 net.cpp:141] Setting up lstm2_
I0730 11:07:12.000944 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:12.000949 32208 net.cpp:156] Memory required for data: 94020
I0730 11:07:12.000953 32208 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0730 11:07:12.000967 32208 net.cpp:91] Creating Layer lstm2_h_concat
I0730 11:07:12.000973 32208 net.cpp:425] lstm2_h_concat <- h_1
I0730 11:07:12.000982 32208 net.cpp:399] lstm2_h_concat -> h
I0730 11:07:12.001021 32208 net.cpp:141] Setting up lstm2_h_concat
I0730 11:07:12.001030 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:12.001035 32208 net.cpp:156] Memory required for data: 98020
I0730 11:07:12.001040 32208 layer_factory.hpp:77] Creating layer h_pseudoloss
I0730 11:07:12.001049 32208 net.cpp:91] Creating Layer h_pseudoloss
I0730 11:07:12.001055 32208 net.cpp:425] h_pseudoloss <- h
I0730 11:07:12.001065 32208 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0730 11:07:12.001164 32208 net.cpp:141] Setting up h_pseudoloss
I0730 11:07:12.001178 32208 net.cpp:148] Top shape: (1)
I0730 11:07:12.001181 32208 net.cpp:151]     with loss weight 1
I0730 11:07:12.001205 32208 net.cpp:156] Memory required for data: 98024
I0730 11:07:12.001211 32208 net.cpp:217] h_pseudoloss needs backward computation.
I0730 11:07:12.001216 32208 net.cpp:217] lstm2_h_concat needs backward computation.
I0730 11:07:12.001221 32208 net.cpp:219] lstm2_ does not need backward computation.
I0730 11:07:12.001226 32208 net.cpp:217] lstm2_unit_1 needs backward computation.
I0730 11:07:12.001232 32208 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0730 11:07:12.001237 32208 net.cpp:217] lstm2_transform_1 needs backward computation.
I0730 11:07:12.001242 32208 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0730 11:07:12.001248 32208 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0730 11:07:12.001252 32208 net.cpp:217] lstm2_x_transform needs backward computation.
I0730 11:07:12.001257 32208 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0730 11:07:12.001263 32208 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0730 11:07:12.001268 32208 net.cpp:219] lstm2_ does not need backward computation.
I0730 11:07:12.001273 32208 net.cpp:219] lstm2_ does not need backward computation.
I0730 11:07:12.001276 32208 net.cpp:261] This network produces output c_T
I0730 11:07:12.001281 32208 net.cpp:261] This network produces output h_pseudoloss
I0730 11:07:12.001299 32208 net.cpp:274] Network initialization done.
I0730 11:07:12.001353 32208 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0730 11:07:12.001360 32208 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0730 11:07:12.001365 32208 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0730 11:07:12.001479 32208 net.cpp:141] Setting up lstm2
I0730 11:07:12.001492 32208 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 11:07:12.001497 32208 net.cpp:156] Memory required for data: 36412
I0730 11:07:12.001513 32208 layer_factory.hpp:77] Creating layer predict
I0730 11:07:12.001528 32208 net.cpp:91] Creating Layer predict
I0730 11:07:12.001534 32208 net.cpp:425] predict <- lstm2
I0730 11:07:12.001543 32208 net.cpp:399] predict -> predict
I0730 11:07:12.323310 32218 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld337845440816689899/bvlc_reference_caffenet.caffemodel
I0730 11:07:12.323359 32218 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0730 11:07:12.323366 32218 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0730 11:07:12.323371 32218 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld337845440816689899/bvlc_reference_caffenet.caffemodel
I0730 11:07:12.486249 32208 net.cpp:141] Setting up predict
I0730 11:07:12.486312 32208 net.cpp:148] Top shape: 1 1 46168 (46168)
I0730 11:07:12.486320 32208 net.cpp:156] Memory required for data: 221084
I0730 11:07:12.486337 32208 layer_factory.hpp:77] Creating layer probs
I0730 11:07:12.486367 32208 net.cpp:91] Creating Layer probs
I0730 11:07:12.486378 32208 net.cpp:425] probs <- predict
I0730 11:07:12.486392 32208 net.cpp:399] probs -> probs
I0730 11:07:12.488515 32208 net.cpp:141] Setting up probs
I0730 11:07:12.488534 32208 net.cpp:148] Top shape: 1 1 46168 (46168)
I0730 11:07:12.488539 32208 net.cpp:156] Memory required for data: 405756
I0730 11:07:12.488545 32208 net.cpp:219] probs does not need backward computation.
I0730 11:07:12.488551 32208 net.cpp:219] predict does not need backward computation.
I0730 11:07:12.488559 32208 net.cpp:219] lstm2 does not need backward computation.
I0730 11:07:12.488566 32208 net.cpp:219] concat does not need backward computation.
I0730 11:07:12.488574 32208 net.cpp:219] lstm1 does not need backward computation.
I0730 11:07:12.488581 32208 net.cpp:219] embedding does not need backward computation.
I0730 11:07:12.488587 32208 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0730 11:07:12.488593 32208 net.cpp:219] reshape_frames does not need backward computation.
I0730 11:07:12.488598 32208 net.cpp:219] embed_encoder does not need backward computation.
I0730 11:07:12.488605 32208 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0730 11:07:12.488610 32208 net.cpp:219] input does not need backward computation.
I0730 11:07:12.488615 32208 net.cpp:261] This network produces output probs
I0730 11:07:12.488632 32208 net.cpp:274] Network initialization done.
I0730 11:07:12.757694 32218 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0730 11:07:12.813729 32218 net.cpp:752] Ignoring source layer loss
I0730 11:07:12.821818 32208 net.cpp:752] Ignoring source layer data
I0730 11:07:12.821853 32208 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0730 11:07:12.821858 32208 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0730 11:07:12.888177 32208 net.cpp:752] Ignoring source layer cross_entropy_loss
