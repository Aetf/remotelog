SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1469888218/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-07-30 10:17:26,603 ERROR Logger contains an invalid element or attribute "appender"
2016-07-30 10:17:41,130 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld8902634416604720027/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0730 10:17:47.091116 24894 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0730 10:17:47.091287 24894 layer_factory.hpp:77] Creating layer data
I0730 10:17:47.091313 24894 net.cpp:91] Creating Layer data
I0730 10:17:47.091322 24894 net.cpp:399] data -> data
I0730 10:17:47.627459 24894 net.cpp:141] Setting up data
I0730 10:17:47.627581 24894 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0730 10:17:47.627590 24894 net.cpp:156] Memory required for data: 6183480
I0730 10:17:47.627614 24894 layer_factory.hpp:77] Creating layer conv1
I0730 10:17:47.627655 24894 net.cpp:91] Creating Layer conv1
I0730 10:17:47.627665 24894 net.cpp:425] conv1 <- data
I0730 10:17:47.627682 24894 net.cpp:399] conv1 -> conv1
I0730 10:17:47.636579 24881 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld8902634416604720027/s2vt.words_to_preds.prototxt
I0730 10:17:47.636632 24881 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0730 10:17:47.636641 24881 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0730 10:17:47.636937 24881 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0730 10:17:47.637048 24881 layer_factory.hpp:77] Creating layer input
I0730 10:17:47.637066 24881 net.cpp:91] Creating Layer input
I0730 10:17:47.637074 24881 net.cpp:399] input -> frames_fc7
I0730 10:17:47.637094 24881 net.cpp:399] input -> cont_sentence
I0730 10:17:47.637104 24881 net.cpp:399] input -> input_sentence
I0730 10:17:47.637115 24881 net.cpp:399] input -> stage_indicator
I0730 10:17:47.637991 24881 net.cpp:141] Setting up input
I0730 10:17:47.638013 24881 net.cpp:148] Top shape: 1 4096 (4096)
I0730 10:17:47.638020 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.638026 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.638032 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.638036 24881 net.cpp:156] Memory required for data: 16396
I0730 10:17:47.638042 24881 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0730 10:17:47.638061 24881 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0730 10:17:47.638067 24881 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0730 10:17:47.638088 24881 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0730 10:17:47.638103 24881 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0730 10:17:47.638279 24881 net.cpp:141] Setting up cont_sentence_input_1_split
I0730 10:17:47.638291 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.638298 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.638303 24881 net.cpp:156] Memory required for data: 16404
I0730 10:17:47.638308 24881 layer_factory.hpp:77] Creating layer embed_encoder
I0730 10:17:47.638324 24881 net.cpp:91] Creating Layer embed_encoder
I0730 10:17:47.638330 24881 net.cpp:425] embed_encoder <- frames_fc7
I0730 10:17:47.638340 24881 net.cpp:399] embed_encoder -> embedded_in_frames
I0730 10:17:47.666528 24881 net.cpp:141] Setting up embed_encoder
I0730 10:17:47.666584 24881 net.cpp:148] Top shape: 1 500 (500)
I0730 10:17:47.666591 24881 net.cpp:156] Memory required for data: 18404
I0730 10:17:47.666625 24881 layer_factory.hpp:77] Creating layer reshape_frames
I0730 10:17:47.666658 24881 net.cpp:91] Creating Layer reshape_frames
I0730 10:17:47.666667 24881 net.cpp:425] reshape_frames <- embedded_in_frames
I0730 10:17:47.666679 24881 net.cpp:399] reshape_frames -> embedded_input_frames
I0730 10:17:47.683962 24881 net.cpp:141] Setting up reshape_frames
I0730 10:17:47.683984 24881 net.cpp:148] Top shape: 1 1 500 (500)
I0730 10:17:47.683990 24881 net.cpp:156] Memory required for data: 20404
I0730 10:17:47.683995 24881 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0730 10:17:47.684010 24881 net.cpp:91] Creating Layer reshape_stage_indicator
I0730 10:17:47.684015 24881 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0730 10:17:47.684031 24881 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0730 10:17:47.686357 24881 net.cpp:141] Setting up reshape_stage_indicator
I0730 10:17:47.686378 24881 net.cpp:148] Top shape: 1 1 1 (1)
I0730 10:17:47.686383 24881 net.cpp:156] Memory required for data: 20408
I0730 10:17:47.686389 24881 layer_factory.hpp:77] Creating layer embedding
I0730 10:17:47.686404 24881 net.cpp:91] Creating Layer embedding
I0730 10:17:47.686410 24881 net.cpp:425] embedding <- input_sentence
I0730 10:17:47.686424 24881 net.cpp:399] embedding -> embedded_input_sentence
I0730 10:17:47.912747 24894 net.cpp:141] Setting up conv1
I0730 10:17:47.912806 24894 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0730 10:17:47.912812 24894 net.cpp:156] Memory required for data: 17799480
I0730 10:17:47.912832 24894 layer_factory.hpp:77] Creating layer relu1
I0730 10:17:47.912853 24894 net.cpp:91] Creating Layer relu1
I0730 10:17:47.912858 24894 net.cpp:425] relu1 <- conv1
I0730 10:17:47.912865 24894 net.cpp:386] relu1 -> conv1 (in-place)
I0730 10:17:47.913616 24881 net.cpp:141] Setting up embedding
I0730 10:17:47.913658 24881 net.cpp:148] Top shape: 1 1 500 (500)
I0730 10:17:47.913664 24881 net.cpp:156] Memory required for data: 22408
I0730 10:17:47.913682 24881 layer_factory.hpp:77] Creating layer lstm1
I0730 10:17:47.913698 24894 net.cpp:141] Setting up relu1
I0730 10:17:47.913702 24881 net.cpp:91] Creating Layer lstm1
I0730 10:17:47.913715 24894 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0730 10:17:47.913720 24894 net.cpp:156] Memory required for data: 29415480
I0730 10:17:47.913722 24881 net.cpp:425] lstm1 <- embedded_input_frames
I0730 10:17:47.913727 24894 layer_factory.hpp:77] Creating layer pool1
I0730 10:17:47.913733 24881 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0730 10:17:47.913743 24894 net.cpp:91] Creating Layer pool1
I0730 10:17:47.913746 24881 net.cpp:399] lstm1 -> lstm1
I0730 10:17:47.913748 24894 net.cpp:425] pool1 <- conv1
I0730 10:17:47.913766 24894 net.cpp:399] pool1 -> pool1
I0730 10:17:47.913787 24881 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0730 10:17:47.913846 24894 net.cpp:141] Setting up pool1
I0730 10:17:47.913856 24894 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0730 10:17:47.913862 24894 net.cpp:156] Memory required for data: 32214840
I0730 10:17:47.913867 24894 layer_factory.hpp:77] Creating layer norm1
I0730 10:17:47.913883 24894 net.cpp:91] Creating Layer norm1
I0730 10:17:47.913888 24894 net.cpp:425] norm1 <- pool1
I0730 10:17:47.913894 24894 net.cpp:399] norm1 -> norm1
I0730 10:17:47.914192 24881 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0730 10:17:47.914296 24881 layer_factory.hpp:77] Creating layer lstm1_
I0730 10:17:47.914309 24881 net.cpp:91] Creating Layer lstm1_
I0730 10:17:47.914316 24881 net.cpp:399] lstm1_ -> x
I0730 10:17:47.914330 24881 net.cpp:399] lstm1_ -> cont
I0730 10:17:47.914588 24881 net.cpp:141] Setting up lstm1_
I0730 10:17:47.914600 24881 net.cpp:148] Top shape: 1 1 500 (500)
I0730 10:17:47.914608 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.914611 24881 net.cpp:156] Memory required for data: 2004
I0730 10:17:47.914616 24881 layer_factory.hpp:77] Creating layer lstm1_
I0730 10:17:47.914626 24881 net.cpp:91] Creating Layer lstm1_
I0730 10:17:47.914640 24881 net.cpp:399] lstm1_ -> c_0
I0730 10:17:47.914651 24881 net.cpp:399] lstm1_ -> h_0
I0730 10:17:47.914757 24881 net.cpp:141] Setting up lstm1_
I0730 10:17:47.914778 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:47.914784 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:47.914788 24881 net.cpp:156] Memory required for data: 10004
I0730 10:17:47.914793 24881 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0730 10:17:47.914803 24881 net.cpp:91] Creating Layer lstm1_cont_slice
I0730 10:17:47.914808 24881 net.cpp:425] lstm1_cont_slice <- cont
I0730 10:17:47.914819 24881 net.cpp:399] lstm1_cont_slice -> cont_1
I0730 10:17:47.914834 24894 net.cpp:141] Setting up norm1
I0730 10:17:47.914850 24894 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0730 10:17:47.914855 24894 net.cpp:156] Memory required for data: 35014200
I0730 10:17:47.914860 24894 layer_factory.hpp:77] Creating layer conv2
I0730 10:17:47.914868 24881 net.cpp:141] Setting up lstm1_cont_slice
I0730 10:17:47.914873 24894 net.cpp:91] Creating Layer conv2
I0730 10:17:47.914878 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.914888 24881 net.cpp:156] Memory required for data: 10008
I0730 10:17:47.914880 24894 net.cpp:425] conv2 <- norm1
I0730 10:17:47.914896 24881 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0730 10:17:47.914912 24894 net.cpp:399] conv2 -> conv2
I0730 10:17:47.914919 24881 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0730 10:17:47.914927 24881 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0730 10:17:47.914933 24881 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0730 10:17:47.914942 24881 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0730 10:17:47.915153 24881 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0730 10:17:47.915163 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.915169 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:47.915174 24881 net.cpp:156] Memory required for data: 10016
I0730 10:17:47.915179 24881 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0730 10:17:47.915189 24881 net.cpp:91] Creating Layer lstm1_x_transform
I0730 10:17:47.915194 24881 net.cpp:425] lstm1_x_transform <- x
I0730 10:17:47.915202 24881 net.cpp:399] lstm1_x_transform -> W_xc_x
I0730 10:17:47.924201 24894 net.cpp:141] Setting up conv2
I0730 10:17:47.924223 24894 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0730 10:17:47.924229 24894 net.cpp:156] Memory required for data: 42479160
I0730 10:17:47.924242 24894 layer_factory.hpp:77] Creating layer relu2
I0730 10:17:47.924254 24894 net.cpp:91] Creating Layer relu2
I0730 10:17:47.924259 24894 net.cpp:425] relu2 <- conv2
I0730 10:17:47.924266 24894 net.cpp:386] relu2 -> conv2 (in-place)
I0730 10:17:47.924947 24894 net.cpp:141] Setting up relu2
I0730 10:17:47.924959 24894 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0730 10:17:47.924963 24894 net.cpp:156] Memory required for data: 49944120
I0730 10:17:47.924968 24894 layer_factory.hpp:77] Creating layer pool2
I0730 10:17:47.924978 24894 net.cpp:91] Creating Layer pool2
I0730 10:17:47.924981 24894 net.cpp:425] pool2 <- conv2
I0730 10:17:47.924990 24894 net.cpp:399] pool2 -> pool2
I0730 10:17:47.925046 24894 net.cpp:141] Setting up pool2
I0730 10:17:47.925065 24894 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 10:17:47.925072 24894 net.cpp:156] Memory required for data: 51674680
I0730 10:17:47.925077 24894 layer_factory.hpp:77] Creating layer norm2
I0730 10:17:47.925087 24894 net.cpp:91] Creating Layer norm2
I0730 10:17:47.925091 24894 net.cpp:425] norm2 <- pool2
I0730 10:17:47.925101 24894 net.cpp:399] norm2 -> norm2
I0730 10:17:47.925349 24894 net.cpp:141] Setting up norm2
I0730 10:17:47.925360 24894 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 10:17:47.925364 24894 net.cpp:156] Memory required for data: 53405240
I0730 10:17:47.925369 24894 layer_factory.hpp:77] Creating layer conv3
I0730 10:17:47.925381 24894 net.cpp:91] Creating Layer conv3
I0730 10:17:47.925386 24894 net.cpp:425] conv3 <- norm2
I0730 10:17:47.925395 24894 net.cpp:399] conv3 -> conv3
I0730 10:17:47.930078 24894 net.cpp:141] Setting up conv3
I0730 10:17:47.930097 24894 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 10:17:47.930102 24894 net.cpp:156] Memory required for data: 56001080
I0730 10:17:47.930115 24894 layer_factory.hpp:77] Creating layer relu3
I0730 10:17:47.930127 24894 net.cpp:91] Creating Layer relu3
I0730 10:17:47.930132 24894 net.cpp:425] relu3 <- conv3
I0730 10:17:47.930138 24894 net.cpp:386] relu3 -> conv3 (in-place)
I0730 10:17:47.930809 24894 net.cpp:141] Setting up relu3
I0730 10:17:47.930820 24894 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 10:17:47.930825 24894 net.cpp:156] Memory required for data: 58596920
I0730 10:17:47.930830 24894 layer_factory.hpp:77] Creating layer conv4
I0730 10:17:47.930843 24894 net.cpp:91] Creating Layer conv4
I0730 10:17:47.930850 24894 net.cpp:425] conv4 <- conv3
I0730 10:17:47.930857 24894 net.cpp:399] conv4 -> conv4
I0730 10:17:47.935721 24894 net.cpp:141] Setting up conv4
I0730 10:17:47.935737 24894 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 10:17:47.935742 24894 net.cpp:156] Memory required for data: 61192760
I0730 10:17:47.935751 24894 layer_factory.hpp:77] Creating layer relu4
I0730 10:17:47.935760 24894 net.cpp:91] Creating Layer relu4
I0730 10:17:47.935763 24894 net.cpp:425] relu4 <- conv4
I0730 10:17:47.935770 24894 net.cpp:386] relu4 -> conv4 (in-place)
I0730 10:17:47.936415 24894 net.cpp:141] Setting up relu4
I0730 10:17:47.936427 24894 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0730 10:17:47.936431 24894 net.cpp:156] Memory required for data: 63788600
I0730 10:17:47.936435 24894 layer_factory.hpp:77] Creating layer conv5
I0730 10:17:47.936449 24894 net.cpp:91] Creating Layer conv5
I0730 10:17:47.936453 24894 net.cpp:425] conv5 <- conv4
I0730 10:17:47.936460 24894 net.cpp:399] conv5 -> conv5
I0730 10:17:47.938519 24881 net.cpp:141] Setting up lstm1_x_transform
I0730 10:17:47.938552 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:47.938558 24881 net.cpp:156] Memory required for data: 26016
I0730 10:17:47.938577 24881 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0730 10:17:47.938593 24881 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0730 10:17:47.938599 24881 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0730 10:17:47.938609 24881 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0730 10:17:47.940065 24881 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0730 10:17:47.940078 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:47.940083 24881 net.cpp:156] Memory required for data: 42016
I0730 10:17:47.940088 24881 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0730 10:17:47.940104 24881 net.cpp:91] Creating Layer lstm1_h_conted_0
I0730 10:17:47.940109 24881 net.cpp:425] lstm1_h_conted_0 <- h_0
I0730 10:17:47.940115 24881 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0730 10:17:47.940124 24881 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0730 10:17:47.940389 24881 net.cpp:141] Setting up lstm1_h_conted_0
I0730 10:17:47.940402 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:47.940407 24881 net.cpp:156] Memory required for data: 46016
I0730 10:17:47.940412 24881 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0730 10:17:47.940426 24881 net.cpp:91] Creating Layer lstm1_transform_1
I0730 10:17:47.940433 24881 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0730 10:17:47.940440 24881 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0730 10:17:47.950628 24894 net.cpp:141] Setting up conv5
I0730 10:17:47.950647 24894 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 10:17:47.950652 24894 net.cpp:156] Memory required for data: 65519160
I0730 10:17:47.950664 24894 layer_factory.hpp:77] Creating layer relu5
I0730 10:17:47.950673 24894 net.cpp:91] Creating Layer relu5
I0730 10:17:47.950678 24894 net.cpp:425] relu5 <- conv5
I0730 10:17:47.950713 24894 net.cpp:386] relu5 -> conv5 (in-place)
I0730 10:17:47.951405 24894 net.cpp:141] Setting up relu5
I0730 10:17:47.951416 24894 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0730 10:17:47.951421 24894 net.cpp:156] Memory required for data: 67249720
I0730 10:17:47.951426 24894 layer_factory.hpp:77] Creating layer pool5
I0730 10:17:47.951437 24894 net.cpp:91] Creating Layer pool5
I0730 10:17:47.951442 24894 net.cpp:425] pool5 <- conv5
I0730 10:17:47.951449 24894 net.cpp:399] pool5 -> pool5
I0730 10:17:47.951508 24894 net.cpp:141] Setting up pool5
I0730 10:17:47.951516 24894 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0730 10:17:47.951520 24894 net.cpp:156] Memory required for data: 67618360
I0730 10:17:47.951525 24894 layer_factory.hpp:77] Creating layer fc6
I0730 10:17:47.951539 24894 net.cpp:91] Creating Layer fc6
I0730 10:17:47.951544 24894 net.cpp:425] fc6 <- pool5
I0730 10:17:47.951550 24894 net.cpp:399] fc6 -> fc6
I0730 10:17:48.013312 24881 net.cpp:141] Setting up lstm1_transform_1
I0730 10:17:48.013356 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.013361 24881 net.cpp:156] Memory required for data: 62016
I0730 10:17:48.013383 24881 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0730 10:17:48.013406 24881 net.cpp:91] Creating Layer lstm1_gate_input_1
I0730 10:17:48.013413 24881 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0730 10:17:48.013422 24881 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0730 10:17:48.013430 24881 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0730 10:17:48.013492 24881 net.cpp:141] Setting up lstm1_gate_input_1
I0730 10:17:48.013501 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.013505 24881 net.cpp:156] Memory required for data: 78016
I0730 10:17:48.013509 24881 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0730 10:17:48.013519 24881 net.cpp:91] Creating Layer lstm1_unit_1
I0730 10:17:48.013523 24881 net.cpp:425] lstm1_unit_1 <- c_0
I0730 10:17:48.013528 24881 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0730 10:17:48.013533 24881 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0730 10:17:48.013540 24881 net.cpp:399] lstm1_unit_1 -> c_1
I0730 10:17:48.013547 24881 net.cpp:399] lstm1_unit_1 -> h_1
I0730 10:17:48.013613 24881 net.cpp:141] Setting up lstm1_unit_1
I0730 10:17:48.013622 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.013628 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.013630 24881 net.cpp:156] Memory required for data: 86016
I0730 10:17:48.013636 24881 layer_factory.hpp:77] Creating layer lstm1_
I0730 10:17:48.013646 24881 net.cpp:91] Creating Layer lstm1_
I0730 10:17:48.013650 24881 net.cpp:425] lstm1_ <- c_1
I0730 10:17:48.013658 24881 net.cpp:399] lstm1_ -> c_T
I0730 10:17:48.013686 24881 net.cpp:141] Setting up lstm1_
I0730 10:17:48.013694 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.013697 24881 net.cpp:156] Memory required for data: 90016
I0730 10:17:48.013701 24881 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0730 10:17:48.013711 24881 net.cpp:91] Creating Layer lstm1_h_concat
I0730 10:17:48.013715 24881 net.cpp:425] lstm1_h_concat <- h_1
I0730 10:17:48.013725 24881 net.cpp:399] lstm1_h_concat -> h
I0730 10:17:48.013764 24881 net.cpp:141] Setting up lstm1_h_concat
I0730 10:17:48.013772 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.013777 24881 net.cpp:156] Memory required for data: 94016
I0730 10:17:48.013780 24881 layer_factory.hpp:77] Creating layer h_pseudoloss
I0730 10:17:48.013793 24881 net.cpp:91] Creating Layer h_pseudoloss
I0730 10:17:48.013797 24881 net.cpp:425] h_pseudoloss <- h
I0730 10:17:48.013804 24881 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0730 10:17:48.013890 24881 net.cpp:141] Setting up h_pseudoloss
I0730 10:17:48.013900 24881 net.cpp:148] Top shape: (1)
I0730 10:17:48.013903 24881 net.cpp:151]     with loss weight 1
I0730 10:17:48.013941 24881 net.cpp:156] Memory required for data: 94020
I0730 10:17:48.013945 24881 net.cpp:217] h_pseudoloss needs backward computation.
I0730 10:17:48.013949 24881 net.cpp:217] lstm1_h_concat needs backward computation.
I0730 10:17:48.013953 24881 net.cpp:219] lstm1_ does not need backward computation.
I0730 10:17:48.013957 24881 net.cpp:217] lstm1_unit_1 needs backward computation.
I0730 10:17:48.013962 24881 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0730 10:17:48.013967 24881 net.cpp:217] lstm1_transform_1 needs backward computation.
I0730 10:17:48.013970 24881 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0730 10:17:48.013975 24881 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0730 10:17:48.013980 24881 net.cpp:217] lstm1_x_transform needs backward computation.
I0730 10:17:48.013984 24881 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0730 10:17:48.013989 24881 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0730 10:17:48.013993 24881 net.cpp:219] lstm1_ does not need backward computation.
I0730 10:17:48.014000 24881 net.cpp:219] lstm1_ does not need backward computation.
I0730 10:17:48.014003 24881 net.cpp:261] This network produces output c_T
I0730 10:17:48.014008 24881 net.cpp:261] This network produces output h_pseudoloss
I0730 10:17:48.014021 24881 net.cpp:274] Network initialization done.
I0730 10:17:48.014083 24881 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0730 10:17:48.014089 24881 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0730 10:17:48.014093 24881 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0730 10:17:48.014199 24881 net.cpp:141] Setting up lstm1
I0730 10:17:48.014209 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.014214 24881 net.cpp:156] Memory required for data: 26408
I0730 10:17:48.014226 24881 layer_factory.hpp:77] Creating layer concat
I0730 10:17:48.014235 24881 net.cpp:91] Creating Layer concat
I0730 10:17:48.014241 24881 net.cpp:425] concat <- lstm1
I0730 10:17:48.014248 24881 net.cpp:425] concat <- embedded_input_sentence
I0730 10:17:48.014253 24881 net.cpp:425] concat <- reshaped_stage_indicator
I0730 10:17:48.014258 24881 net.cpp:399] concat -> lstm1_video_sequence
I0730 10:17:48.014288 24881 net.cpp:141] Setting up concat
I0730 10:17:48.014297 24881 net.cpp:148] Top shape: 1 1 1501 (1501)
I0730 10:17:48.014300 24881 net.cpp:156] Memory required for data: 32412
I0730 10:17:48.014304 24881 layer_factory.hpp:77] Creating layer lstm2
I0730 10:17:48.014317 24881 net.cpp:91] Creating Layer lstm2
I0730 10:17:48.014320 24881 net.cpp:425] lstm2 <- lstm1_video_sequence
I0730 10:17:48.014328 24881 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0730 10:17:48.014333 24881 net.cpp:399] lstm2 -> lstm2
I0730 10:17:48.014343 24881 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0730 10:17:48.014585 24881 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0730 10:17:48.014667 24881 layer_factory.hpp:77] Creating layer lstm2_
I0730 10:17:48.014678 24881 net.cpp:91] Creating Layer lstm2_
I0730 10:17:48.014683 24881 net.cpp:399] lstm2_ -> x
I0730 10:17:48.014711 24881 net.cpp:399] lstm2_ -> cont
I0730 10:17:48.014767 24881 net.cpp:141] Setting up lstm2_
I0730 10:17:48.014776 24881 net.cpp:148] Top shape: 1 1 1501 (1501)
I0730 10:17:48.014781 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:48.014786 24881 net.cpp:156] Memory required for data: 6008
I0730 10:17:48.014791 24881 layer_factory.hpp:77] Creating layer lstm2_
I0730 10:17:48.014798 24881 net.cpp:91] Creating Layer lstm2_
I0730 10:17:48.014806 24881 net.cpp:399] lstm2_ -> c_0
I0730 10:17:48.014816 24881 net.cpp:399] lstm2_ -> h_0
I0730 10:17:48.014863 24881 net.cpp:141] Setting up lstm2_
I0730 10:17:48.014871 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.014876 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.014880 24881 net.cpp:156] Memory required for data: 14008
I0730 10:17:48.014884 24881 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0730 10:17:48.014892 24881 net.cpp:91] Creating Layer lstm2_cont_slice
I0730 10:17:48.014896 24881 net.cpp:425] lstm2_cont_slice <- cont
I0730 10:17:48.014902 24881 net.cpp:399] lstm2_cont_slice -> cont_1
I0730 10:17:48.014935 24881 net.cpp:141] Setting up lstm2_cont_slice
I0730 10:17:48.014943 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:48.014947 24881 net.cpp:156] Memory required for data: 14012
I0730 10:17:48.014951 24881 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0730 10:17:48.014961 24881 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0730 10:17:48.014966 24881 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0730 10:17:48.014971 24881 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0730 10:17:48.014978 24881 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0730 10:17:48.015035 24881 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0730 10:17:48.015043 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:48.015048 24881 net.cpp:148] Top shape: 1 1 (1)
I0730 10:17:48.015051 24881 net.cpp:156] Memory required for data: 14020
I0730 10:17:48.015055 24881 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0730 10:17:48.015064 24881 net.cpp:91] Creating Layer lstm2_x_transform
I0730 10:17:48.015069 24881 net.cpp:425] lstm2_x_transform <- x
I0730 10:17:48.015079 24881 net.cpp:399] lstm2_x_transform -> W_xc_x
I0730 10:17:48.050505 24894 net.cpp:141] Setting up fc6
I0730 10:17:48.050546 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.050551 24894 net.cpp:156] Memory required for data: 67782200
I0730 10:17:48.050565 24894 layer_factory.hpp:77] Creating layer relu6
I0730 10:17:48.050580 24894 net.cpp:91] Creating Layer relu6
I0730 10:17:48.050586 24894 net.cpp:425] relu6 <- fc6
I0730 10:17:48.050595 24894 net.cpp:386] relu6 -> fc6 (in-place)
I0730 10:17:48.050926 24894 net.cpp:141] Setting up relu6
I0730 10:17:48.050937 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.050941 24894 net.cpp:156] Memory required for data: 67946040
I0730 10:17:48.050946 24894 layer_factory.hpp:77] Creating layer drop6
I0730 10:17:48.050956 24894 net.cpp:91] Creating Layer drop6
I0730 10:17:48.050959 24894 net.cpp:425] drop6 <- fc6
I0730 10:17:48.050969 24894 net.cpp:386] drop6 -> fc6 (in-place)
I0730 10:17:48.051017 24894 net.cpp:141] Setting up drop6
I0730 10:17:48.051026 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.051030 24894 net.cpp:156] Memory required for data: 68109880
I0730 10:17:48.051034 24894 layer_factory.hpp:77] Creating layer fc7
I0730 10:17:48.051044 24894 net.cpp:91] Creating Layer fc7
I0730 10:17:48.051048 24894 net.cpp:425] fc7 <- fc6
I0730 10:17:48.051054 24894 net.cpp:399] fc7 -> fc7
I0730 10:17:48.079105 24881 net.cpp:141] Setting up lstm2_x_transform
I0730 10:17:48.079150 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.079155 24881 net.cpp:156] Memory required for data: 30020
I0730 10:17:48.079174 24881 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0730 10:17:48.079190 24881 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0730 10:17:48.079196 24881 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0730 10:17:48.079205 24881 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0730 10:17:48.079252 24881 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0730 10:17:48.079260 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.079264 24881 net.cpp:156] Memory required for data: 46020
I0730 10:17:48.079268 24881 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0730 10:17:48.079278 24881 net.cpp:91] Creating Layer lstm2_h_conted_0
I0730 10:17:48.079283 24881 net.cpp:425] lstm2_h_conted_0 <- h_0
I0730 10:17:48.079288 24881 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0730 10:17:48.079295 24881 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0730 10:17:48.079382 24881 net.cpp:141] Setting up lstm2_h_conted_0
I0730 10:17:48.079391 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.079394 24881 net.cpp:156] Memory required for data: 50020
I0730 10:17:48.079398 24881 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0730 10:17:48.079411 24881 net.cpp:91] Creating Layer lstm2_transform_1
I0730 10:17:48.079416 24881 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0730 10:17:48.079423 24881 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0730 10:17:48.095854 24894 net.cpp:141] Setting up fc7
I0730 10:17:48.095892 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.095898 24894 net.cpp:156] Memory required for data: 68273720
I0730 10:17:48.095911 24894 layer_factory.hpp:77] Creating layer relu7
I0730 10:17:48.095926 24894 net.cpp:91] Creating Layer relu7
I0730 10:17:48.095932 24894 net.cpp:425] relu7 <- fc7
I0730 10:17:48.095939 24894 net.cpp:386] relu7 -> fc7 (in-place)
I0730 10:17:48.097342 24894 net.cpp:141] Setting up relu7
I0730 10:17:48.097354 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.097358 24894 net.cpp:156] Memory required for data: 68437560
I0730 10:17:48.097363 24894 layer_factory.hpp:77] Creating layer drop7
I0730 10:17:48.097376 24894 net.cpp:91] Creating Layer drop7
I0730 10:17:48.097381 24894 net.cpp:425] drop7 <- fc7
I0730 10:17:48.097388 24894 net.cpp:386] drop7 -> fc7 (in-place)
I0730 10:17:48.097427 24894 net.cpp:141] Setting up drop7
I0730 10:17:48.097435 24894 net.cpp:148] Top shape: 10 4096 (40960)
I0730 10:17:48.097440 24894 net.cpp:156] Memory required for data: 68601400
I0730 10:17:48.097443 24894 layer_factory.hpp:77] Creating layer fc8
I0730 10:17:48.097451 24894 net.cpp:91] Creating Layer fc8
I0730 10:17:48.097456 24894 net.cpp:425] fc8 <- fc7
I0730 10:17:48.097465 24894 net.cpp:399] fc8 -> fc8
I0730 10:17:48.109236 24894 net.cpp:141] Setting up fc8
I0730 10:17:48.109277 24894 net.cpp:148] Top shape: 10 1000 (10000)
I0730 10:17:48.109282 24894 net.cpp:156] Memory required for data: 68641400
I0730 10:17:48.109293 24894 layer_factory.hpp:77] Creating layer prob
I0730 10:17:48.109313 24894 net.cpp:91] Creating Layer prob
I0730 10:17:48.109318 24894 net.cpp:425] prob <- fc8
I0730 10:17:48.109328 24894 net.cpp:399] prob -> prob
I0730 10:17:48.109707 24894 net.cpp:141] Setting up prob
I0730 10:17:48.109720 24894 net.cpp:148] Top shape: 10 1000 (10000)
I0730 10:17:48.109724 24894 net.cpp:156] Memory required for data: 68681400
I0730 10:17:48.109730 24894 net.cpp:219] prob does not need backward computation.
I0730 10:17:48.109733 24894 net.cpp:219] fc8 does not need backward computation.
I0730 10:17:48.109737 24894 net.cpp:219] drop7 does not need backward computation.
I0730 10:17:48.109741 24894 net.cpp:219] relu7 does not need backward computation.
I0730 10:17:48.109745 24894 net.cpp:219] fc7 does not need backward computation.
I0730 10:17:48.109748 24894 net.cpp:219] drop6 does not need backward computation.
I0730 10:17:48.109752 24894 net.cpp:219] relu6 does not need backward computation.
I0730 10:17:48.109756 24894 net.cpp:219] fc6 does not need backward computation.
I0730 10:17:48.109760 24894 net.cpp:219] pool5 does not need backward computation.
I0730 10:17:48.109764 24894 net.cpp:219] relu5 does not need backward computation.
I0730 10:17:48.109768 24894 net.cpp:219] conv5 does not need backward computation.
I0730 10:17:48.109772 24894 net.cpp:219] relu4 does not need backward computation.
I0730 10:17:48.109776 24894 net.cpp:219] conv4 does not need backward computation.
I0730 10:17:48.109779 24894 net.cpp:219] relu3 does not need backward computation.
I0730 10:17:48.109783 24894 net.cpp:219] conv3 does not need backward computation.
I0730 10:17:48.109787 24894 net.cpp:219] norm2 does not need backward computation.
I0730 10:17:48.109791 24894 net.cpp:219] pool2 does not need backward computation.
I0730 10:17:48.109794 24894 net.cpp:219] relu2 does not need backward computation.
I0730 10:17:48.109798 24894 net.cpp:219] conv2 does not need backward computation.
I0730 10:17:48.109802 24894 net.cpp:219] norm1 does not need backward computation.
I0730 10:17:48.109805 24894 net.cpp:219] pool1 does not need backward computation.
I0730 10:17:48.109809 24894 net.cpp:219] relu1 does not need backward computation.
I0730 10:17:48.109812 24894 net.cpp:219] conv1 does not need backward computation.
I0730 10:17:48.109817 24894 net.cpp:219] data does not need backward computation.
I0730 10:17:48.109819 24894 net.cpp:261] This network produces output prob
I0730 10:17:48.109838 24894 net.cpp:274] Network initialization done.
I0730 10:17:48.117303 24881 net.cpp:141] Setting up lstm2_transform_1
I0730 10:17:48.117321 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.117324 24881 net.cpp:156] Memory required for data: 66020
I0730 10:17:48.117336 24881 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0730 10:17:48.117348 24881 net.cpp:91] Creating Layer lstm2_gate_input_1
I0730 10:17:48.117354 24881 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0730 10:17:48.117359 24881 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0730 10:17:48.117365 24881 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0730 10:17:48.117406 24881 net.cpp:141] Setting up lstm2_gate_input_1
I0730 10:17:48.117413 24881 net.cpp:148] Top shape: 1 1 4000 (4000)
I0730 10:17:48.117418 24881 net.cpp:156] Memory required for data: 82020
I0730 10:17:48.117421 24881 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0730 10:17:48.117431 24881 net.cpp:91] Creating Layer lstm2_unit_1
I0730 10:17:48.117435 24881 net.cpp:425] lstm2_unit_1 <- c_0
I0730 10:17:48.117440 24881 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0730 10:17:48.117444 24881 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0730 10:17:48.117450 24881 net.cpp:399] lstm2_unit_1 -> c_1
I0730 10:17:48.117458 24881 net.cpp:399] lstm2_unit_1 -> h_1
I0730 10:17:48.117514 24881 net.cpp:141] Setting up lstm2_unit_1
I0730 10:17:48.117522 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.117527 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.117530 24881 net.cpp:156] Memory required for data: 90020
I0730 10:17:48.117534 24881 layer_factory.hpp:77] Creating layer lstm2_
I0730 10:17:48.117542 24881 net.cpp:91] Creating Layer lstm2_
I0730 10:17:48.117545 24881 net.cpp:425] lstm2_ <- c_1
I0730 10:17:48.117552 24881 net.cpp:399] lstm2_ -> c_T
I0730 10:17:48.117578 24881 net.cpp:141] Setting up lstm2_
I0730 10:17:48.117585 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.117589 24881 net.cpp:156] Memory required for data: 94020
I0730 10:17:48.117593 24881 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0730 10:17:48.117604 24881 net.cpp:91] Creating Layer lstm2_h_concat
I0730 10:17:48.117607 24881 net.cpp:425] lstm2_h_concat <- h_1
I0730 10:17:48.117614 24881 net.cpp:399] lstm2_h_concat -> h
I0730 10:17:48.117646 24881 net.cpp:141] Setting up lstm2_h_concat
I0730 10:17:48.117653 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.117656 24881 net.cpp:156] Memory required for data: 98020
I0730 10:17:48.117660 24881 layer_factory.hpp:77] Creating layer h_pseudoloss
I0730 10:17:48.117667 24881 net.cpp:91] Creating Layer h_pseudoloss
I0730 10:17:48.117671 24881 net.cpp:425] h_pseudoloss <- h
I0730 10:17:48.117678 24881 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0730 10:17:48.117743 24881 net.cpp:141] Setting up h_pseudoloss
I0730 10:17:48.117753 24881 net.cpp:148] Top shape: (1)
I0730 10:17:48.117758 24881 net.cpp:151]     with loss weight 1
I0730 10:17:48.117774 24881 net.cpp:156] Memory required for data: 98024
I0730 10:17:48.117779 24881 net.cpp:217] h_pseudoloss needs backward computation.
I0730 10:17:48.117782 24881 net.cpp:217] lstm2_h_concat needs backward computation.
I0730 10:17:48.117786 24881 net.cpp:219] lstm2_ does not need backward computation.
I0730 10:17:48.117790 24881 net.cpp:217] lstm2_unit_1 needs backward computation.
I0730 10:17:48.117794 24881 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0730 10:17:48.117799 24881 net.cpp:217] lstm2_transform_1 needs backward computation.
I0730 10:17:48.117802 24881 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0730 10:17:48.117806 24881 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0730 10:17:48.117810 24881 net.cpp:217] lstm2_x_transform needs backward computation.
I0730 10:17:48.117815 24881 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0730 10:17:48.117818 24881 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0730 10:17:48.117823 24881 net.cpp:219] lstm2_ does not need backward computation.
I0730 10:17:48.117826 24881 net.cpp:219] lstm2_ does not need backward computation.
I0730 10:17:48.117830 24881 net.cpp:261] This network produces output c_T
I0730 10:17:48.117833 24881 net.cpp:261] This network produces output h_pseudoloss
I0730 10:17:48.117847 24881 net.cpp:274] Network initialization done.
I0730 10:17:48.117895 24881 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0730 10:17:48.117900 24881 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0730 10:17:48.117903 24881 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0730 10:17:48.118000 24881 net.cpp:141] Setting up lstm2
I0730 10:17:48.118010 24881 net.cpp:148] Top shape: 1 1 1000 (1000)
I0730 10:17:48.118015 24881 net.cpp:156] Memory required for data: 36412
I0730 10:17:48.118027 24881 layer_factory.hpp:77] Creating layer predict
I0730 10:17:48.118038 24881 net.cpp:91] Creating Layer predict
I0730 10:17:48.118044 24881 net.cpp:425] predict <- lstm2
I0730 10:17:48.118052 24881 net.cpp:399] predict -> predict
I0730 10:17:48.516520 24881 net.cpp:141] Setting up predict
I0730 10:17:48.516564 24881 net.cpp:148] Top shape: 1 1 46168 (46168)
I0730 10:17:48.516571 24881 net.cpp:156] Memory required for data: 221084
I0730 10:17:48.516582 24881 layer_factory.hpp:77] Creating layer probs
I0730 10:17:48.516597 24881 net.cpp:91] Creating Layer probs
I0730 10:17:48.516613 24881 net.cpp:425] probs <- predict
I0730 10:17:48.516623 24881 net.cpp:399] probs -> probs
I0730 10:17:48.518205 24881 net.cpp:141] Setting up probs
I0730 10:17:48.518220 24881 net.cpp:148] Top shape: 1 1 46168 (46168)
I0730 10:17:48.518224 24881 net.cpp:156] Memory required for data: 405756
I0730 10:17:48.518229 24881 net.cpp:219] probs does not need backward computation.
I0730 10:17:48.518234 24881 net.cpp:219] predict does not need backward computation.
I0730 10:17:48.518237 24881 net.cpp:219] lstm2 does not need backward computation.
I0730 10:17:48.518244 24881 net.cpp:219] concat does not need backward computation.
I0730 10:17:48.518249 24881 net.cpp:219] lstm1 does not need backward computation.
I0730 10:17:48.518256 24881 net.cpp:219] embedding does not need backward computation.
I0730 10:17:48.518270 24881 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0730 10:17:48.518273 24881 net.cpp:219] reshape_frames does not need backward computation.
I0730 10:17:48.518278 24881 net.cpp:219] embed_encoder does not need backward computation.
I0730 10:17:48.518283 24881 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0730 10:17:48.518288 24881 net.cpp:219] input does not need backward computation.
I0730 10:17:48.518291 24881 net.cpp:261] This network produces output probs
I0730 10:17:48.518303 24881 net.cpp:274] Network initialization done.
I0730 10:17:52.715593 24894 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld8902634416604720027/bvlc_reference_caffenet.caffemodel
I0730 10:17:52.715673 24894 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0730 10:17:52.715683 24894 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0730 10:17:52.715692 24894 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld8902634416604720027/bvlc_reference_caffenet.caffemodel
I0730 10:17:52.816608 24881 net.cpp:752] Ignoring source layer data
I0730 10:17:52.816654 24881 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0730 10:17:52.816659 24881 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0730 10:17:52.901554 24881 net.cpp:752] Ignoring source layer cross_entropy_loss
I0730 10:17:53.140202 24894 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0730 10:17:53.192028 24894 net.cpp:752] Ignoring source layer loss
