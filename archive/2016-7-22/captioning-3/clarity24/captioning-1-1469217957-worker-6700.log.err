SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/lib/log4j-slf4j-impl-2.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/peifeng/tools/storm/data/supervisor/stormdist/captioning-1-1469217957/stormjar.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2016-07-22 16:06:17,305 ERROR Logger contains an invalid element or attribute "appender"
2016-07-22 16:06:20,265 ERROR Logger contains an invalid element or attribute "appender"
Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /tmp/cvld6353972619595424022/libopencv_java310.xine1.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0722 16:06:26.633975 22448 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0722 16:06:26.634182 22448 layer_factory.hpp:77] Creating layer data
I0722 16:06:26.634209 22448 net.cpp:91] Creating Layer data
I0722 16:06:26.634219 22448 net.cpp:399] data -> data
I0722 16:06:26.642259 22442 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0722 16:06:26.642401 22442 layer_factory.hpp:77] Creating layer data
I0722 16:06:26.642419 22442 net.cpp:91] Creating Layer data
I0722 16:06:26.642427 22442 net.cpp:399] data -> data
I0722 16:06:26.819399 22430 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld6353972619595424022/s2vt.words_to_preds.prototxt
I0722 16:06:26.819444 22430 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0722 16:06:26.819453 22430 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0722 16:06:26.819697 22430 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0722 16:06:26.819815 22430 layer_factory.hpp:77] Creating layer input
I0722 16:06:26.819830 22430 net.cpp:91] Creating Layer input
I0722 16:06:26.819839 22430 net.cpp:399] input -> frames_fc7
I0722 16:06:26.819854 22430 net.cpp:399] input -> cont_sentence
I0722 16:06:26.819866 22430 net.cpp:399] input -> input_sentence
I0722 16:06:26.819876 22430 net.cpp:399] input -> stage_indicator
I0722 16:06:26.825040 22434 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /tmp/cvld6353972619595424022/s2vt.words_to_preds.prototxt
I0722 16:06:26.825060 22434 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0722 16:06:26.825065 22434 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0722 16:06:26.825261 22434 net.cpp:49] Initializing net from parameters: 
name: "s2vt:features_to_lstm"
state {
  phase: TEST
}
layer {
  name: "input"
  type: "Input"
  top: "frames_fc7"
  top: "cont_sentence"
  top: "input_sentence"
  top: "stage_indicator"
  input_param {
    shape {
      dim: 1
      dim: 4096
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embed_encoder"
  type: "InnerProduct"
  bottom: "frames_fc7"
  top: "embedded_in_frames"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reshape_frames"
  type: "Reshape"
  bottom: "embedded_in_frames"
  top: "embedded_input_frames"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
  }
}
layer {
  name: "reshape_stage_indicator"
  type: "Reshape"
  bottom: "stage_indicator"
  top: "reshaped_stage_indicator"
  reshape_param {
    shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "embedding"
  type: "Embed"
  bottom: "input_sentence"
  top: "embedded_input_sentence"
  param {
    lr_mult: 1
  }
  embed_param {
    num_output: 500
    input_dim: 46168
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
  }
}
layer {
  name: "lstm1"
  type: "LSTM"
  bottom: "embedded_input_frames"
  bottom: "cont_sentence"
  top: "lstm1"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "lstm1"
  bottom: "embedded_input_sentence"
  bottom: "reshaped_stage_indicator"
  top: "lstm1_video_sequence"
  concat_param {
    concat_dim: 2
  }
}
layer {
  name: "lstm2"
  type: "LSTM"
  bottom: "lstm1_video_sequence"
  bottom: "cont_sentence"
  top: "lstm2"
  recurrent_param {
    num_output: 1000
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "predict"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 46168
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "predict"
  top: "probs"
  softmax_param {
    axis: 2
  }
}
I0722 16:06:26.825340 22434 layer_factory.hpp:77] Creating layer input
I0722 16:06:26.825351 22434 net.cpp:91] Creating Layer input
I0722 16:06:26.825358 22434 net.cpp:399] input -> frames_fc7
I0722 16:06:26.825371 22434 net.cpp:399] input -> cont_sentence
I0722 16:06:26.825381 22434 net.cpp:399] input -> input_sentence
I0722 16:06:26.825392 22434 net.cpp:399] input -> stage_indicator
I0722 16:06:27.527405 22448 net.cpp:141] Setting up data
I0722 16:06:27.527505 22448 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0722 16:06:27.527513 22448 net.cpp:156] Memory required for data: 6183480
I0722 16:06:27.527536 22448 layer_factory.hpp:77] Creating layer conv1
I0722 16:06:27.527570 22448 net.cpp:91] Creating Layer conv1
I0722 16:06:27.527580 22448 net.cpp:425] conv1 <- data
I0722 16:06:27.527595 22448 net.cpp:399] conv1 -> conv1
I0722 16:06:27.527672 22430 net.cpp:141] Setting up input
I0722 16:06:27.527710 22430 net.cpp:148] Top shape: 1 4096 (4096)
I0722 16:06:27.527717 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.527722 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.527727 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.527731 22430 net.cpp:156] Memory required for data: 16396
I0722 16:06:27.527740 22430 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0722 16:06:27.527766 22430 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0722 16:06:27.527773 22430 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0722 16:06:27.527804 22430 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0722 16:06:27.527822 22430 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0722 16:06:27.527993 22430 net.cpp:141] Setting up cont_sentence_input_1_split
I0722 16:06:27.528005 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.528012 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.528015 22430 net.cpp:156] Memory required for data: 16404
I0722 16:06:27.528020 22430 layer_factory.hpp:77] Creating layer embed_encoder
I0722 16:06:27.528035 22430 net.cpp:91] Creating Layer embed_encoder
I0722 16:06:27.528040 22430 net.cpp:425] embed_encoder <- frames_fc7
I0722 16:06:27.528048 22430 net.cpp:399] embed_encoder -> embedded_in_frames
I0722 16:06:27.559509 22442 net.cpp:141] Setting up data
I0722 16:06:27.559547 22442 net.cpp:148] Top shape: 10 3 227 227 (1545870)
I0722 16:06:27.559553 22442 net.cpp:156] Memory required for data: 6183480
I0722 16:06:27.559562 22442 layer_factory.hpp:77] Creating layer conv1
I0722 16:06:27.559583 22442 net.cpp:91] Creating Layer conv1
I0722 16:06:27.559589 22442 net.cpp:425] conv1 <- data
I0722 16:06:27.559598 22442 net.cpp:399] conv1 -> conv1
I0722 16:06:27.564967 22434 net.cpp:141] Setting up input
I0722 16:06:27.565006 22434 net.cpp:148] Top shape: 1 4096 (4096)
I0722 16:06:27.565013 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.565018 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.565024 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.565027 22434 net.cpp:156] Memory required for data: 16396
I0722 16:06:27.565033 22434 layer_factory.hpp:77] Creating layer cont_sentence_input_1_split
I0722 16:06:27.565047 22434 net.cpp:91] Creating Layer cont_sentence_input_1_split
I0722 16:06:27.565052 22434 net.cpp:425] cont_sentence_input_1_split <- cont_sentence
I0722 16:06:27.565062 22434 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_0
I0722 16:06:27.565073 22434 net.cpp:399] cont_sentence_input_1_split -> cont_sentence_input_1_split_1
I0722 16:06:27.579360 22434 net.cpp:141] Setting up cont_sentence_input_1_split
I0722 16:06:27.579403 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.579411 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.579414 22434 net.cpp:156] Memory required for data: 16404
I0722 16:06:27.579422 22434 layer_factory.hpp:77] Creating layer embed_encoder
I0722 16:06:27.579447 22434 net.cpp:91] Creating Layer embed_encoder
I0722 16:06:27.579453 22434 net.cpp:425] embed_encoder <- frames_fc7
I0722 16:06:27.579462 22430 net.cpp:141] Setting up embed_encoder
I0722 16:06:27.579466 22434 net.cpp:399] embed_encoder -> embedded_in_frames
I0722 16:06:27.579483 22430 net.cpp:148] Top shape: 1 500 (500)
I0722 16:06:27.579488 22430 net.cpp:156] Memory required for data: 18404
I0722 16:06:27.579512 22430 layer_factory.hpp:77] Creating layer reshape_frames
I0722 16:06:27.579538 22430 net.cpp:91] Creating Layer reshape_frames
I0722 16:06:27.579546 22430 net.cpp:425] reshape_frames <- embedded_in_frames
I0722 16:06:27.579555 22430 net.cpp:399] reshape_frames -> embedded_input_frames
I0722 16:06:27.585108 22430 net.cpp:141] Setting up reshape_frames
I0722 16:06:27.585144 22430 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.585149 22430 net.cpp:156] Memory required for data: 20404
I0722 16:06:27.585156 22430 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0722 16:06:27.585175 22430 net.cpp:91] Creating Layer reshape_stage_indicator
I0722 16:06:27.585182 22430 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0722 16:06:27.585196 22430 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0722 16:06:27.587188 22430 net.cpp:141] Setting up reshape_stage_indicator
I0722 16:06:27.587209 22430 net.cpp:148] Top shape: 1 1 1 (1)
I0722 16:06:27.587215 22430 net.cpp:156] Memory required for data: 20408
I0722 16:06:27.587220 22430 layer_factory.hpp:77] Creating layer embedding
I0722 16:06:27.587237 22430 net.cpp:91] Creating Layer embedding
I0722 16:06:27.587242 22430 net.cpp:425] embedding <- input_sentence
I0722 16:06:27.587251 22430 net.cpp:399] embedding -> embedded_input_sentence
I0722 16:06:27.666842 22434 net.cpp:141] Setting up embed_encoder
I0722 16:06:27.666898 22434 net.cpp:148] Top shape: 1 500 (500)
I0722 16:06:27.666904 22434 net.cpp:156] Memory required for data: 18404
I0722 16:06:27.666929 22434 layer_factory.hpp:77] Creating layer reshape_frames
I0722 16:06:27.666952 22434 net.cpp:91] Creating Layer reshape_frames
I0722 16:06:27.666960 22434 net.cpp:425] reshape_frames <- embedded_in_frames
I0722 16:06:27.666972 22434 net.cpp:399] reshape_frames -> embedded_input_frames
I0722 16:06:27.674985 22434 net.cpp:141] Setting up reshape_frames
I0722 16:06:27.675040 22434 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.675053 22434 net.cpp:156] Memory required for data: 20404
I0722 16:06:27.675062 22434 layer_factory.hpp:77] Creating layer reshape_stage_indicator
I0722 16:06:27.675086 22434 net.cpp:91] Creating Layer reshape_stage_indicator
I0722 16:06:27.675094 22434 net.cpp:425] reshape_stage_indicator <- stage_indicator
I0722 16:06:27.675107 22434 net.cpp:399] reshape_stage_indicator -> reshaped_stage_indicator
I0722 16:06:27.676882 22434 net.cpp:141] Setting up reshape_stage_indicator
I0722 16:06:27.676900 22434 net.cpp:148] Top shape: 1 1 1 (1)
I0722 16:06:27.676905 22434 net.cpp:156] Memory required for data: 20408
I0722 16:06:27.676918 22434 layer_factory.hpp:77] Creating layer embedding
I0722 16:06:27.676941 22434 net.cpp:91] Creating Layer embedding
I0722 16:06:27.676949 22434 net.cpp:425] embedding <- input_sentence
I0722 16:06:27.676962 22434 net.cpp:399] embedding -> embedded_input_sentence
I0722 16:06:27.809742 22430 net.cpp:141] Setting up embedding
I0722 16:06:27.809783 22430 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.809789 22430 net.cpp:156] Memory required for data: 22408
I0722 16:06:27.809806 22430 layer_factory.hpp:77] Creating layer lstm1
I0722 16:06:27.809823 22430 net.cpp:91] Creating Layer lstm1
I0722 16:06:27.809830 22430 net.cpp:425] lstm1 <- embedded_input_frames
I0722 16:06:27.809837 22430 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0722 16:06:27.809849 22430 net.cpp:399] lstm1 -> lstm1
I0722 16:06:27.809880 22430 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0722 16:06:27.810219 22430 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0722 16:06:27.810312 22430 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:27.810323 22430 net.cpp:91] Creating Layer lstm1_
I0722 16:06:27.810329 22430 net.cpp:399] lstm1_ -> x
I0722 16:06:27.810340 22430 net.cpp:399] lstm1_ -> cont
I0722 16:06:27.819607 22430 net.cpp:141] Setting up lstm1_
I0722 16:06:27.819625 22430 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.819631 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.819635 22430 net.cpp:156] Memory required for data: 2004
I0722 16:06:27.819640 22430 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:27.819653 22430 net.cpp:91] Creating Layer lstm1_
I0722 16:06:27.819660 22430 net.cpp:399] lstm1_ -> c_0
I0722 16:06:27.819674 22430 net.cpp:399] lstm1_ -> h_0
I0722 16:06:27.827713 22430 net.cpp:141] Setting up lstm1_
I0722 16:06:27.827739 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.827744 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.827749 22430 net.cpp:156] Memory required for data: 10004
I0722 16:06:27.827754 22430 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0722 16:06:27.827769 22430 net.cpp:91] Creating Layer lstm1_cont_slice
I0722 16:06:27.827775 22430 net.cpp:425] lstm1_cont_slice <- cont
I0722 16:06:27.827782 22430 net.cpp:399] lstm1_cont_slice -> cont_1
I0722 16:06:27.829121 22430 net.cpp:141] Setting up lstm1_cont_slice
I0722 16:06:27.829140 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.829145 22430 net.cpp:156] Memory required for data: 10008
I0722 16:06:27.829150 22430 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.829165 22430 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.829171 22430 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0722 16:06:27.829179 22430 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0722 16:06:27.829187 22430 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0722 16:06:27.836207 22430 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.836230 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.836236 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.836239 22430 net.cpp:156] Memory required for data: 10016
I0722 16:06:27.836244 22430 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0722 16:06:27.836262 22430 net.cpp:91] Creating Layer lstm1_x_transform
I0722 16:06:27.836268 22430 net.cpp:425] lstm1_x_transform <- x
I0722 16:06:27.836277 22430 net.cpp:399] lstm1_x_transform -> W_xc_x
I0722 16:06:27.887935 22430 net.cpp:141] Setting up lstm1_x_transform
I0722 16:06:27.887977 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:27.887984 22430 net.cpp:156] Memory required for data: 26016
I0722 16:06:27.888002 22430 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0722 16:06:27.888016 22430 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0722 16:06:27.888022 22430 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0722 16:06:27.888031 22430 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0722 16:06:27.890455 22430 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0722 16:06:27.890475 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:27.890480 22430 net.cpp:156] Memory required for data: 42016
I0722 16:06:27.890486 22430 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0722 16:06:27.890499 22430 net.cpp:91] Creating Layer lstm1_h_conted_0
I0722 16:06:27.890504 22430 net.cpp:425] lstm1_h_conted_0 <- h_0
I0722 16:06:27.890511 22430 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0722 16:06:27.890517 22430 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0722 16:06:27.924017 22430 net.cpp:141] Setting up lstm1_h_conted_0
I0722 16:06:27.924060 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.924065 22430 net.cpp:156] Memory required for data: 46016
I0722 16:06:27.924072 22430 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0722 16:06:27.924090 22430 net.cpp:91] Creating Layer lstm1_transform_1
I0722 16:06:27.924096 22430 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0722 16:06:27.924110 22430 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0722 16:06:27.926151 22434 net.cpp:141] Setting up embedding
I0722 16:06:27.926172 22434 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.926177 22434 net.cpp:156] Memory required for data: 22408
I0722 16:06:27.926190 22434 layer_factory.hpp:77] Creating layer lstm1
I0722 16:06:27.926205 22434 net.cpp:91] Creating Layer lstm1
I0722 16:06:27.926211 22434 net.cpp:425] lstm1 <- embedded_input_frames
I0722 16:06:27.926218 22434 net.cpp:425] lstm1 <- cont_sentence_input_1_split_0
I0722 16:06:27.926228 22434 net.cpp:399] lstm1 -> lstm1
I0722 16:06:27.926240 22434 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0722 16:06:27.926527 22434 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm1_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 500
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm1_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm1_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm1_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm1_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0722 16:06:27.926631 22434 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:27.926643 22434 net.cpp:91] Creating Layer lstm1_
I0722 16:06:27.926650 22434 net.cpp:399] lstm1_ -> x
I0722 16:06:27.926661 22434 net.cpp:399] lstm1_ -> cont
I0722 16:06:27.953024 22434 net.cpp:141] Setting up lstm1_
I0722 16:06:27.953068 22434 net.cpp:148] Top shape: 1 1 500 (500)
I0722 16:06:27.953075 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.953079 22434 net.cpp:156] Memory required for data: 2004
I0722 16:06:27.953099 22434 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:27.953117 22434 net.cpp:91] Creating Layer lstm1_
I0722 16:06:27.953128 22434 net.cpp:399] lstm1_ -> c_0
I0722 16:06:27.953145 22434 net.cpp:399] lstm1_ -> h_0
I0722 16:06:27.962859 22434 net.cpp:141] Setting up lstm1_
I0722 16:06:27.962888 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.962894 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.962898 22434 net.cpp:156] Memory required for data: 10004
I0722 16:06:27.962904 22434 layer_factory.hpp:77] Creating layer lstm1_cont_slice
I0722 16:06:27.962919 22434 net.cpp:91] Creating Layer lstm1_cont_slice
I0722 16:06:27.962924 22434 net.cpp:425] lstm1_cont_slice <- cont
I0722 16:06:27.962936 22434 net.cpp:399] lstm1_cont_slice -> cont_1
I0722 16:06:27.964048 22434 net.cpp:141] Setting up lstm1_cont_slice
I0722 16:06:27.964071 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.964081 22434 net.cpp:156] Memory required for data: 10008
I0722 16:06:27.964090 22434 layer_factory.hpp:77] Creating layer cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.964104 22434 net.cpp:91] Creating Layer cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.964114 22434 net.cpp:425] cont_1_lstm1_cont_slice_0_split <- cont_1
I0722 16:06:27.964133 22434 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_0
I0722 16:06:27.964149 22434 net.cpp:399] cont_1_lstm1_cont_slice_0_split -> cont_1_lstm1_cont_slice_0_split_1
I0722 16:06:27.972774 22434 net.cpp:141] Setting up cont_1_lstm1_cont_slice_0_split
I0722 16:06:27.972798 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.972810 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:27.972817 22434 net.cpp:156] Memory required for data: 10016
I0722 16:06:27.972826 22434 layer_factory.hpp:77] Creating layer lstm1_x_transform
I0722 16:06:27.972868 22434 net.cpp:91] Creating Layer lstm1_x_transform
I0722 16:06:27.972880 22434 net.cpp:425] lstm1_x_transform <- x
I0722 16:06:27.972898 22434 net.cpp:399] lstm1_x_transform -> W_xc_x
I0722 16:06:27.978446 22430 net.cpp:141] Setting up lstm1_transform_1
I0722 16:06:27.978466 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:27.978471 22430 net.cpp:156] Memory required for data: 62016
I0722 16:06:27.978483 22430 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0722 16:06:27.978497 22430 net.cpp:91] Creating Layer lstm1_gate_input_1
I0722 16:06:27.978502 22430 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0722 16:06:27.978508 22430 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0722 16:06:27.978515 22430 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0722 16:06:27.988445 22430 net.cpp:141] Setting up lstm1_gate_input_1
I0722 16:06:27.988476 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:27.988481 22430 net.cpp:156] Memory required for data: 78016
I0722 16:06:27.988487 22430 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0722 16:06:27.988500 22430 net.cpp:91] Creating Layer lstm1_unit_1
I0722 16:06:27.988505 22430 net.cpp:425] lstm1_unit_1 <- c_0
I0722 16:06:27.988513 22430 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0722 16:06:27.988518 22430 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0722 16:06:27.988524 22430 net.cpp:399] lstm1_unit_1 -> c_1
I0722 16:06:27.988535 22430 net.cpp:399] lstm1_unit_1 -> h_1
I0722 16:06:27.994068 22430 net.cpp:141] Setting up lstm1_unit_1
I0722 16:06:27.994137 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.994155 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.994164 22430 net.cpp:156] Memory required for data: 86016
I0722 16:06:27.994175 22430 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:27.994192 22430 net.cpp:91] Creating Layer lstm1_
I0722 16:06:27.994204 22430 net.cpp:425] lstm1_ <- c_1
I0722 16:06:27.994218 22430 net.cpp:399] lstm1_ -> c_T
I0722 16:06:27.996889 22430 net.cpp:141] Setting up lstm1_
I0722 16:06:27.996915 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:27.996927 22430 net.cpp:156] Memory required for data: 90016
I0722 16:06:27.996935 22430 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0722 16:06:27.996959 22430 net.cpp:91] Creating Layer lstm1_h_concat
I0722 16:06:27.996970 22430 net.cpp:425] lstm1_h_concat <- h_1
I0722 16:06:27.996989 22430 net.cpp:399] lstm1_h_concat -> h
I0722 16:06:28.003945 22430 net.cpp:141] Setting up lstm1_h_concat
I0722 16:06:28.003978 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.003983 22430 net.cpp:156] Memory required for data: 94016
I0722 16:06:28.003989 22430 layer_factory.hpp:77] Creating layer h_pseudoloss
I0722 16:06:28.004009 22430 net.cpp:91] Creating Layer h_pseudoloss
I0722 16:06:28.004015 22430 net.cpp:425] h_pseudoloss <- h
I0722 16:06:28.004024 22430 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0722 16:06:28.026185 22430 net.cpp:141] Setting up h_pseudoloss
I0722 16:06:28.026227 22430 net.cpp:148] Top shape: (1)
I0722 16:06:28.026232 22430 net.cpp:151]     with loss weight 1
I0722 16:06:28.026269 22430 net.cpp:156] Memory required for data: 94020
I0722 16:06:28.026276 22430 net.cpp:217] h_pseudoloss needs backward computation.
I0722 16:06:28.026283 22430 net.cpp:217] lstm1_h_concat needs backward computation.
I0722 16:06:28.026288 22430 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.026291 22430 net.cpp:217] lstm1_unit_1 needs backward computation.
I0722 16:06:28.026301 22430 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0722 16:06:28.026307 22430 net.cpp:217] lstm1_transform_1 needs backward computation.
I0722 16:06:28.026312 22430 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0722 16:06:28.026317 22430 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0722 16:06:28.026322 22430 net.cpp:217] lstm1_x_transform needs backward computation.
I0722 16:06:28.026326 22430 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0722 16:06:28.026331 22430 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0722 16:06:28.026336 22430 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.026340 22430 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.026343 22430 net.cpp:261] This network produces output c_T
I0722 16:06:28.026348 22430 net.cpp:261] This network produces output h_pseudoloss
I0722 16:06:28.026367 22430 net.cpp:274] Network initialization done.
I0722 16:06:28.026427 22430 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0722 16:06:28.026432 22430 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0722 16:06:28.026437 22430 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0722 16:06:28.042321 22434 net.cpp:141] Setting up lstm1_x_transform
I0722 16:06:28.042352 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.042362 22434 net.cpp:156] Memory required for data: 26016
I0722 16:06:28.042385 22434 layer_factory.hpp:77] Creating layer lstm1_W_xc_x_slice
I0722 16:06:28.042412 22434 net.cpp:91] Creating Layer lstm1_W_xc_x_slice
I0722 16:06:28.042424 22434 net.cpp:425] lstm1_W_xc_x_slice <- W_xc_x
I0722 16:06:28.042439 22434 net.cpp:399] lstm1_W_xc_x_slice -> W_xc_x_1
I0722 16:06:28.044690 22430 net.cpp:141] Setting up lstm1
I0722 16:06:28.044710 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.044715 22430 net.cpp:156] Memory required for data: 26408
I0722 16:06:28.044730 22430 layer_factory.hpp:77] Creating layer concat
I0722 16:06:28.044741 22430 net.cpp:91] Creating Layer concat
I0722 16:06:28.044747 22430 net.cpp:425] concat <- lstm1
I0722 16:06:28.044754 22430 net.cpp:425] concat <- embedded_input_sentence
I0722 16:06:28.044759 22430 net.cpp:425] concat <- reshaped_stage_indicator
I0722 16:06:28.044765 22430 net.cpp:399] concat -> lstm1_video_sequence
I0722 16:06:28.045035 22434 net.cpp:141] Setting up lstm1_W_xc_x_slice
I0722 16:06:28.045058 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.045068 22434 net.cpp:156] Memory required for data: 42016
I0722 16:06:28.045076 22434 layer_factory.hpp:77] Creating layer lstm1_h_conted_0
I0722 16:06:28.045094 22434 net.cpp:91] Creating Layer lstm1_h_conted_0
I0722 16:06:28.045104 22434 net.cpp:425] lstm1_h_conted_0 <- h_0
I0722 16:06:28.045115 22434 net.cpp:425] lstm1_h_conted_0 <- cont_1_lstm1_cont_slice_0_split_0
I0722 16:06:28.045135 22434 net.cpp:399] lstm1_h_conted_0 -> h_conted_0
I0722 16:06:28.048712 22430 net.cpp:141] Setting up concat
I0722 16:06:28.048732 22430 net.cpp:148] Top shape: 1 1 1501 (1501)
I0722 16:06:28.048738 22430 net.cpp:156] Memory required for data: 32412
I0722 16:06:28.048743 22430 layer_factory.hpp:77] Creating layer lstm2
I0722 16:06:28.048755 22430 net.cpp:91] Creating Layer lstm2
I0722 16:06:28.048760 22430 net.cpp:425] lstm2 <- lstm1_video_sequence
I0722 16:06:28.048768 22430 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0722 16:06:28.048774 22430 net.cpp:399] lstm2 -> lstm2
I0722 16:06:28.048785 22430 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0722 16:06:28.049077 22430 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0722 16:06:28.049167 22430 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.049178 22430 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.049185 22430 net.cpp:399] lstm2_ -> x
I0722 16:06:28.049196 22430 net.cpp:399] lstm2_ -> cont
I0722 16:06:28.054858 22430 net.cpp:141] Setting up lstm2_
I0722 16:06:28.054878 22430 net.cpp:148] Top shape: 1 1 1501 (1501)
I0722 16:06:28.054884 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.054888 22430 net.cpp:156] Memory required for data: 6008
I0722 16:06:28.054894 22430 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.054908 22430 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.054916 22430 net.cpp:399] lstm2_ -> c_0
I0722 16:06:28.054929 22430 net.cpp:399] lstm2_ -> h_0
I0722 16:06:28.055135 22434 net.cpp:141] Setting up lstm1_h_conted_0
I0722 16:06:28.055157 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.055167 22434 net.cpp:156] Memory required for data: 46016
I0722 16:06:28.055176 22434 layer_factory.hpp:77] Creating layer lstm1_transform_1
I0722 16:06:28.055177 22430 net.cpp:141] Setting up lstm2_
I0722 16:06:28.055197 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.055202 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.055200 22434 net.cpp:91] Creating Layer lstm1_transform_1
I0722 16:06:28.055207 22430 net.cpp:156] Memory required for data: 14008
I0722 16:06:28.055212 22430 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0722 16:06:28.055213 22434 net.cpp:425] lstm1_transform_1 <- h_conted_0
I0722 16:06:28.055223 22430 net.cpp:91] Creating Layer lstm2_cont_slice
I0722 16:06:28.055228 22430 net.cpp:425] lstm2_cont_slice <- cont
I0722 16:06:28.055235 22434 net.cpp:399] lstm1_transform_1 -> W_hc_h_0
I0722 16:06:28.055235 22430 net.cpp:399] lstm2_cont_slice -> cont_1
I0722 16:06:28.066701 22430 net.cpp:141] Setting up lstm2_cont_slice
I0722 16:06:28.066745 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.066751 22430 net.cpp:156] Memory required for data: 14012
I0722 16:06:28.066759 22430 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.066781 22430 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.066788 22430 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0722 16:06:28.066798 22430 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0722 16:06:28.066810 22430 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0722 16:06:28.070343 22430 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.070390 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.070397 22430 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.070401 22430 net.cpp:156] Memory required for data: 14020
I0722 16:06:28.070410 22430 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0722 16:06:28.070436 22430 net.cpp:91] Creating Layer lstm2_x_transform
I0722 16:06:28.070441 22430 net.cpp:425] lstm2_x_transform <- x
I0722 16:06:28.070453 22430 net.cpp:399] lstm2_x_transform -> W_xc_x
I0722 16:06:28.086513 22442 net.cpp:141] Setting up conv1
I0722 16:06:28.086571 22442 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0722 16:06:28.086578 22442 net.cpp:156] Memory required for data: 17799480
I0722 16:06:28.086585 22448 net.cpp:141] Setting up conv1
I0722 16:06:28.086603 22442 layer_factory.hpp:77] Creating layer relu1
I0722 16:06:28.086614 22448 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0722 16:06:28.086621 22448 net.cpp:156] Memory required for data: 17799480
I0722 16:06:28.086624 22442 net.cpp:91] Creating Layer relu1
I0722 16:06:28.086632 22442 net.cpp:425] relu1 <- conv1
I0722 16:06:28.086635 22448 layer_factory.hpp:77] Creating layer relu1
I0722 16:06:28.086639 22442 net.cpp:386] relu1 -> conv1 (in-place)
I0722 16:06:28.086645 22448 net.cpp:91] Creating Layer relu1
I0722 16:06:28.086654 22448 net.cpp:425] relu1 <- conv1
I0722 16:06:28.086663 22448 net.cpp:386] relu1 -> conv1 (in-place)
I0722 16:06:28.087447 22442 net.cpp:141] Setting up relu1
I0722 16:06:28.087461 22442 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0722 16:06:28.087466 22442 net.cpp:156] Memory required for data: 29415480
I0722 16:06:28.087471 22442 layer_factory.hpp:77] Creating layer pool1
I0722 16:06:28.087483 22442 net.cpp:91] Creating Layer pool1
I0722 16:06:28.087488 22442 net.cpp:425] pool1 <- conv1
I0722 16:06:28.087497 22442 net.cpp:399] pool1 -> pool1
I0722 16:06:28.087832 22442 net.cpp:141] Setting up pool1
I0722 16:06:28.087844 22442 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0722 16:06:28.087848 22442 net.cpp:156] Memory required for data: 32214840
I0722 16:06:28.087853 22442 layer_factory.hpp:77] Creating layer norm1
I0722 16:06:28.087873 22442 net.cpp:91] Creating Layer norm1
I0722 16:06:28.087878 22442 net.cpp:425] norm1 <- pool1
I0722 16:06:28.087884 22442 net.cpp:399] norm1 -> norm1
I0722 16:06:28.087918 22448 net.cpp:141] Setting up relu1
I0722 16:06:28.087932 22448 net.cpp:148] Top shape: 10 96 55 55 (2904000)
I0722 16:06:28.087936 22448 net.cpp:156] Memory required for data: 29415480
I0722 16:06:28.087941 22448 layer_factory.hpp:77] Creating layer pool1
I0722 16:06:28.087952 22448 net.cpp:91] Creating Layer pool1
I0722 16:06:28.087957 22448 net.cpp:425] pool1 <- conv1
I0722 16:06:28.087965 22448 net.cpp:399] pool1 -> pool1
I0722 16:06:28.088627 22448 net.cpp:141] Setting up pool1
I0722 16:06:28.088639 22448 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0722 16:06:28.088644 22448 net.cpp:156] Memory required for data: 32214840
I0722 16:06:28.088649 22448 layer_factory.hpp:77] Creating layer norm1
I0722 16:06:28.088660 22448 net.cpp:91] Creating Layer norm1
I0722 16:06:28.088665 22448 net.cpp:425] norm1 <- pool1
I0722 16:06:28.088670 22448 net.cpp:399] norm1 -> norm1
I0722 16:06:28.089402 22442 net.cpp:141] Setting up norm1
I0722 16:06:28.089417 22442 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0722 16:06:28.089421 22442 net.cpp:156] Memory required for data: 35014200
I0722 16:06:28.089426 22442 layer_factory.hpp:77] Creating layer conv2
I0722 16:06:28.089448 22442 net.cpp:91] Creating Layer conv2
I0722 16:06:28.089453 22442 net.cpp:425] conv2 <- norm1
I0722 16:06:28.089460 22442 net.cpp:399] conv2 -> conv2
I0722 16:06:28.089623 22448 net.cpp:141] Setting up norm1
I0722 16:06:28.089637 22448 net.cpp:148] Top shape: 10 96 27 27 (699840)
I0722 16:06:28.089640 22448 net.cpp:156] Memory required for data: 35014200
I0722 16:06:28.089645 22448 layer_factory.hpp:77] Creating layer conv2
I0722 16:06:28.089660 22448 net.cpp:91] Creating Layer conv2
I0722 16:06:28.089665 22448 net.cpp:425] conv2 <- norm1
I0722 16:06:28.089673 22448 net.cpp:399] conv2 -> conv2
I0722 16:06:28.097132 22442 net.cpp:141] Setting up conv2
I0722 16:06:28.097153 22442 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0722 16:06:28.097158 22442 net.cpp:156] Memory required for data: 42479160
I0722 16:06:28.097172 22442 layer_factory.hpp:77] Creating layer relu2
I0722 16:06:28.097180 22442 net.cpp:91] Creating Layer relu2
I0722 16:06:28.097185 22442 net.cpp:425] relu2 <- conv2
I0722 16:06:28.097196 22442 net.cpp:386] relu2 -> conv2 (in-place)
I0722 16:06:28.098079 22448 net.cpp:141] Setting up conv2
I0722 16:06:28.098083 22442 net.cpp:141] Setting up relu2
I0722 16:06:28.098099 22448 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0722 16:06:28.098104 22442 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0722 16:06:28.098105 22448 net.cpp:156] Memory required for data: 42479160
I0722 16:06:28.098114 22442 net.cpp:156] Memory required for data: 49944120
I0722 16:06:28.098119 22442 layer_factory.hpp:77] Creating layer pool2
I0722 16:06:28.098125 22448 layer_factory.hpp:77] Creating layer relu2
I0722 16:06:28.098131 22442 net.cpp:91] Creating Layer pool2
I0722 16:06:28.098137 22442 net.cpp:425] pool2 <- conv2
I0722 16:06:28.098139 22448 net.cpp:91] Creating Layer relu2
I0722 16:06:28.098143 22448 net.cpp:425] relu2 <- conv2
I0722 16:06:28.098145 22442 net.cpp:399] pool2 -> pool2
I0722 16:06:28.098150 22448 net.cpp:386] relu2 -> conv2 (in-place)
I0722 16:06:28.099004 22434 net.cpp:141] Setting up lstm1_transform_1
I0722 16:06:28.099020 22442 net.cpp:141] Setting up pool2
I0722 16:06:28.099047 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.099050 22442 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.099053 22434 net.cpp:156] Memory required for data: 62016
I0722 16:06:28.099056 22442 net.cpp:156] Memory required for data: 51674680
I0722 16:06:28.099057 22448 net.cpp:141] Setting up relu2
I0722 16:06:28.099062 22442 layer_factory.hpp:77] Creating layer norm2
I0722 16:06:28.099074 22448 net.cpp:148] Top shape: 10 256 27 27 (1866240)
I0722 16:06:28.099083 22448 net.cpp:156] Memory required for data: 49944120
I0722 16:06:28.099083 22442 net.cpp:91] Creating Layer norm2
I0722 16:06:28.099088 22448 layer_factory.hpp:77] Creating layer pool2
I0722 16:06:28.099074 22434 layer_factory.hpp:77] Creating layer lstm1_gate_input_1
I0722 16:06:28.099092 22442 net.cpp:425] norm2 <- pool2
I0722 16:06:28.099102 22448 net.cpp:91] Creating Layer pool2
I0722 16:06:28.099107 22448 net.cpp:425] pool2 <- conv2
I0722 16:06:28.099109 22442 net.cpp:399] norm2 -> norm2
I0722 16:06:28.099114 22434 net.cpp:91] Creating Layer lstm1_gate_input_1
I0722 16:06:28.099115 22448 net.cpp:399] pool2 -> pool2
I0722 16:06:28.099124 22434 net.cpp:425] lstm1_gate_input_1 <- W_hc_h_0
I0722 16:06:28.099143 22434 net.cpp:425] lstm1_gate_input_1 <- W_xc_x_1
I0722 16:06:28.099151 22434 net.cpp:399] lstm1_gate_input_1 -> gate_input_1
I0722 16:06:28.099432 22434 net.cpp:141] Setting up lstm1_gate_input_1
I0722 16:06:28.099443 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.099447 22434 net.cpp:156] Memory required for data: 78016
I0722 16:06:28.099452 22434 layer_factory.hpp:77] Creating layer lstm1_unit_1
I0722 16:06:28.099462 22434 net.cpp:91] Creating Layer lstm1_unit_1
I0722 16:06:28.099469 22434 net.cpp:425] lstm1_unit_1 <- c_0
I0722 16:06:28.099459 22448 net.cpp:141] Setting up pool2
I0722 16:06:28.099478 22434 net.cpp:425] lstm1_unit_1 <- gate_input_1
I0722 16:06:28.099486 22434 net.cpp:425] lstm1_unit_1 <- cont_1_lstm1_cont_slice_0_split_1
I0722 16:06:28.099486 22448 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.099498 22434 net.cpp:399] lstm1_unit_1 -> c_1
I0722 16:06:28.099499 22448 net.cpp:156] Memory required for data: 51674680
I0722 16:06:28.099505 22448 layer_factory.hpp:77] Creating layer norm2
I0722 16:06:28.099508 22434 net.cpp:399] lstm1_unit_1 -> h_1
I0722 16:06:28.099519 22448 net.cpp:91] Creating Layer norm2
I0722 16:06:28.099524 22448 net.cpp:425] norm2 <- pool2
I0722 16:06:28.099532 22448 net.cpp:399] norm2 -> norm2
I0722 16:06:28.099828 22442 net.cpp:141] Setting up norm2
I0722 16:06:28.099839 22442 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.099843 22442 net.cpp:156] Memory required for data: 53405240
I0722 16:06:28.099848 22442 layer_factory.hpp:77] Creating layer conv3
I0722 16:06:28.099859 22442 net.cpp:91] Creating Layer conv3
I0722 16:06:28.099864 22442 net.cpp:425] conv3 <- norm2
I0722 16:06:28.099874 22442 net.cpp:399] conv3 -> conv3
I0722 16:06:28.099925 22434 net.cpp:141] Setting up lstm1_unit_1
I0722 16:06:28.099936 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.099942 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.099946 22434 net.cpp:156] Memory required for data: 86016
I0722 16:06:28.099951 22434 layer_factory.hpp:77] Creating layer lstm1_
I0722 16:06:28.099961 22434 net.cpp:91] Creating Layer lstm1_
I0722 16:06:28.099967 22434 net.cpp:425] lstm1_ <- c_1
I0722 16:06:28.099973 22434 net.cpp:399] lstm1_ -> c_T
I0722 16:06:28.100073 22434 net.cpp:141] Setting up lstm1_
I0722 16:06:28.100083 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.100087 22434 net.cpp:156] Memory required for data: 90016
I0722 16:06:28.100091 22434 layer_factory.hpp:77] Creating layer lstm1_h_concat
I0722 16:06:28.100105 22434 net.cpp:91] Creating Layer lstm1_h_concat
I0722 16:06:28.100109 22434 net.cpp:425] lstm1_h_concat <- h_1
I0722 16:06:28.100118 22434 net.cpp:399] lstm1_h_concat -> h
I0722 16:06:28.100234 22448 net.cpp:141] Setting up norm2
I0722 16:06:28.100247 22448 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.100251 22448 net.cpp:156] Memory required for data: 53405240
I0722 16:06:28.100256 22448 layer_factory.hpp:77] Creating layer conv3
I0722 16:06:28.100265 22448 net.cpp:91] Creating Layer conv3
I0722 16:06:28.100270 22448 net.cpp:425] conv3 <- norm2
I0722 16:06:28.100281 22448 net.cpp:399] conv3 -> conv3
I0722 16:06:28.100283 22434 net.cpp:141] Setting up lstm1_h_concat
I0722 16:06:28.100293 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.100297 22434 net.cpp:156] Memory required for data: 94016
I0722 16:06:28.100302 22434 layer_factory.hpp:77] Creating layer h_pseudoloss
I0722 16:06:28.100311 22434 net.cpp:91] Creating Layer h_pseudoloss
I0722 16:06:28.100316 22434 net.cpp:425] h_pseudoloss <- h
I0722 16:06:28.100322 22434 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0722 16:06:28.100814 22434 net.cpp:141] Setting up h_pseudoloss
I0722 16:06:28.100831 22434 net.cpp:148] Top shape: (1)
I0722 16:06:28.100836 22434 net.cpp:151]     with loss weight 1
I0722 16:06:28.100855 22434 net.cpp:156] Memory required for data: 94020
I0722 16:06:28.100862 22434 net.cpp:217] h_pseudoloss needs backward computation.
I0722 16:06:28.100867 22434 net.cpp:217] lstm1_h_concat needs backward computation.
I0722 16:06:28.100870 22434 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.100875 22434 net.cpp:217] lstm1_unit_1 needs backward computation.
I0722 16:06:28.100881 22434 net.cpp:217] lstm1_gate_input_1 needs backward computation.
I0722 16:06:28.100886 22434 net.cpp:217] lstm1_transform_1 needs backward computation.
I0722 16:06:28.100891 22434 net.cpp:219] lstm1_h_conted_0 does not need backward computation.
I0722 16:06:28.100896 22434 net.cpp:217] lstm1_W_xc_x_slice needs backward computation.
I0722 16:06:28.100901 22434 net.cpp:217] lstm1_x_transform needs backward computation.
I0722 16:06:28.100905 22434 net.cpp:219] cont_1_lstm1_cont_slice_0_split does not need backward computation.
I0722 16:06:28.100914 22434 net.cpp:219] lstm1_cont_slice does not need backward computation.
I0722 16:06:28.100919 22434 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.100924 22434 net.cpp:219] lstm1_ does not need backward computation.
I0722 16:06:28.100926 22434 net.cpp:261] This network produces output c_T
I0722 16:06:28.100931 22434 net.cpp:261] This network produces output h_pseudoloss
I0722 16:06:28.100950 22434 net.cpp:274] Network initialization done.
I0722 16:06:28.101009 22434 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0722 16:06:28.101016 22434 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0722 16:06:28.101021 22434 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0722 16:06:28.107565 22434 net.cpp:141] Setting up lstm1
I0722 16:06:28.107597 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.107602 22434 net.cpp:156] Memory required for data: 26408
I0722 16:06:28.107620 22434 layer_factory.hpp:77] Creating layer concat
I0722 16:06:28.107632 22434 net.cpp:91] Creating Layer concat
I0722 16:06:28.107640 22434 net.cpp:425] concat <- lstm1
I0722 16:06:28.107647 22434 net.cpp:425] concat <- embedded_input_sentence
I0722 16:06:28.107652 22434 net.cpp:425] concat <- reshaped_stage_indicator
I0722 16:06:28.107659 22434 net.cpp:399] concat -> lstm1_video_sequence
I0722 16:06:28.108516 22434 net.cpp:141] Setting up concat
I0722 16:06:28.108536 22434 net.cpp:148] Top shape: 1 1 1501 (1501)
I0722 16:06:28.108541 22434 net.cpp:156] Memory required for data: 32412
I0722 16:06:28.108546 22434 layer_factory.hpp:77] Creating layer lstm2
I0722 16:06:28.108561 22434 net.cpp:91] Creating Layer lstm2
I0722 16:06:28.108567 22434 net.cpp:425] lstm2 <- lstm1_video_sequence
I0722 16:06:28.108574 22434 net.cpp:425] lstm2 <- cont_sentence_input_1_split_1
I0722 16:06:28.108582 22434 net.cpp:399] lstm2 -> lstm2
I0722 16:06:28.108594 22434 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 1 timesteps of 1 independent streams.
I0722 16:06:28.108870 22434 net.cpp:49] Initializing net from parameters: 
layer {
  name: "lstm2_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1501
    }
    shape {
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "lstm2_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
    shape {
      dim: 1
      dim: 1
      dim: 1000
    }
  }
}
layer {
  name: "lstm2_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 4000
    bias_term: true
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 4000
    bias_term: false
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    axis: 2
  }
}
layer {
  name: "lstm2_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2_"
  type: "Split"
  bottom: "c_1"
  top: "c_T"
}
layer {
  name: "lstm2_h_concat"
  type: "Concat"
  bottom: "h_1"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0722 16:06:28.108961 22434 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.108974 22434 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.108980 22434 net.cpp:399] lstm2_ -> x
I0722 16:06:28.108990 22434 net.cpp:399] lstm2_ -> cont
I0722 16:06:28.110915 22434 net.cpp:141] Setting up lstm2_
I0722 16:06:28.110929 22434 net.cpp:148] Top shape: 1 1 1501 (1501)
I0722 16:06:28.110934 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.110939 22434 net.cpp:156] Memory required for data: 6008
I0722 16:06:28.110944 22434 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.110952 22434 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.110967 22434 net.cpp:399] lstm2_ -> c_0
I0722 16:06:28.110978 22434 net.cpp:399] lstm2_ -> h_0
I0722 16:06:28.111157 22434 net.cpp:141] Setting up lstm2_
I0722 16:06:28.111168 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.111174 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.111177 22434 net.cpp:156] Memory required for data: 14008
I0722 16:06:28.111182 22434 layer_factory.hpp:77] Creating layer lstm2_cont_slice
I0722 16:06:28.111191 22434 net.cpp:91] Creating Layer lstm2_cont_slice
I0722 16:06:28.111196 22434 net.cpp:425] lstm2_cont_slice <- cont
I0722 16:06:28.111207 22434 net.cpp:399] lstm2_cont_slice -> cont_1
I0722 16:06:28.111356 22434 net.cpp:141] Setting up lstm2_cont_slice
I0722 16:06:28.111366 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.111371 22434 net.cpp:156] Memory required for data: 14012
I0722 16:06:28.111376 22434 layer_factory.hpp:77] Creating layer cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.111382 22434 net.cpp:91] Creating Layer cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.111387 22434 net.cpp:425] cont_1_lstm2_cont_slice_0_split <- cont_1
I0722 16:06:28.111397 22434 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_0
I0722 16:06:28.111404 22434 net.cpp:399] cont_1_lstm2_cont_slice_0_split -> cont_1_lstm2_cont_slice_0_split_1
I0722 16:06:28.111510 22442 net.cpp:141] Setting up conv3
I0722 16:06:28.111527 22442 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.111532 22442 net.cpp:156] Memory required for data: 56001080
I0722 16:06:28.111546 22442 layer_factory.hpp:77] Creating layer relu3
I0722 16:06:28.111558 22442 net.cpp:91] Creating Layer relu3
I0722 16:06:28.111563 22442 net.cpp:425] relu3 <- conv3
I0722 16:06:28.111570 22442 net.cpp:386] relu3 -> conv3 (in-place)
I0722 16:06:28.111578 22434 net.cpp:141] Setting up cont_1_lstm2_cont_slice_0_split
I0722 16:06:28.111589 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.111595 22434 net.cpp:148] Top shape: 1 1 (1)
I0722 16:06:28.111598 22434 net.cpp:156] Memory required for data: 14020
I0722 16:06:28.111603 22434 layer_factory.hpp:77] Creating layer lstm2_x_transform
I0722 16:06:28.111615 22434 net.cpp:91] Creating Layer lstm2_x_transform
I0722 16:06:28.111620 22434 net.cpp:425] lstm2_x_transform <- x
I0722 16:06:28.111629 22434 net.cpp:399] lstm2_x_transform -> W_xc_x
I0722 16:06:28.112452 22448 net.cpp:141] Setting up conv3
I0722 16:06:28.112468 22448 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.112473 22448 net.cpp:156] Memory required for data: 56001080
I0722 16:06:28.112486 22448 layer_factory.hpp:77] Creating layer relu3
I0722 16:06:28.112495 22448 net.cpp:91] Creating Layer relu3
I0722 16:06:28.112500 22448 net.cpp:425] relu3 <- conv3
I0722 16:06:28.121512 22448 net.cpp:386] relu3 -> conv3 (in-place)
I0722 16:06:28.124019 22442 net.cpp:141] Setting up relu3
I0722 16:06:28.124047 22442 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.124053 22442 net.cpp:156] Memory required for data: 58596920
I0722 16:06:28.124061 22442 layer_factory.hpp:77] Creating layer conv4
I0722 16:06:28.124088 22442 net.cpp:91] Creating Layer conv4
I0722 16:06:28.124094 22442 net.cpp:425] conv4 <- conv3
I0722 16:06:28.124104 22442 net.cpp:399] conv4 -> conv4
I0722 16:06:28.124119 22448 net.cpp:141] Setting up relu3
I0722 16:06:28.124136 22448 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.124141 22448 net.cpp:156] Memory required for data: 58596920
I0722 16:06:28.124147 22448 layer_factory.hpp:77] Creating layer conv4
I0722 16:06:28.124161 22448 net.cpp:91] Creating Layer conv4
I0722 16:06:28.124166 22448 net.cpp:425] conv4 <- conv3
I0722 16:06:28.124177 22448 net.cpp:399] conv4 -> conv4
I0722 16:06:28.137053 22442 net.cpp:141] Setting up conv4
I0722 16:06:28.137106 22442 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.137114 22442 net.cpp:156] Memory required for data: 61192760
I0722 16:06:28.137127 22442 layer_factory.hpp:77] Creating layer relu4
I0722 16:06:28.137145 22442 net.cpp:91] Creating Layer relu4
I0722 16:06:28.137151 22442 net.cpp:425] relu4 <- conv4
I0722 16:06:28.137164 22442 net.cpp:386] relu4 -> conv4 (in-place)
I0722 16:06:28.138267 22442 net.cpp:141] Setting up relu4
I0722 16:06:28.138283 22442 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.138288 22442 net.cpp:156] Memory required for data: 63788600
I0722 16:06:28.138293 22442 layer_factory.hpp:77] Creating layer conv5
I0722 16:06:28.138316 22442 net.cpp:91] Creating Layer conv5
I0722 16:06:28.138324 22442 net.cpp:425] conv5 <- conv4
I0722 16:06:28.138331 22442 net.cpp:399] conv5 -> conv5
I0722 16:06:28.138370 22430 net.cpp:141] Setting up lstm2_x_transform
I0722 16:06:28.138411 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.138416 22430 net.cpp:156] Memory required for data: 30020
I0722 16:06:28.138434 22430 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0722 16:06:28.138432 22448 net.cpp:141] Setting up conv4
I0722 16:06:28.138453 22430 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0722 16:06:28.138460 22430 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0722 16:06:28.138460 22448 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.138466 22448 net.cpp:156] Memory required for data: 61192760
I0722 16:06:28.138469 22430 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0722 16:06:28.138478 22448 layer_factory.hpp:77] Creating layer relu4
I0722 16:06:28.138486 22448 net.cpp:91] Creating Layer relu4
I0722 16:06:28.138491 22448 net.cpp:425] relu4 <- conv4
I0722 16:06:28.138499 22448 net.cpp:386] relu4 -> conv4 (in-place)
I0722 16:06:28.138635 22430 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0722 16:06:28.138648 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.138653 22430 net.cpp:156] Memory required for data: 46020
I0722 16:06:28.138658 22430 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0722 16:06:28.138667 22430 net.cpp:91] Creating Layer lstm2_h_conted_0
I0722 16:06:28.138674 22430 net.cpp:425] lstm2_h_conted_0 <- h_0
I0722 16:06:28.138679 22430 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0722 16:06:28.138698 22430 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0722 16:06:28.139803 22448 net.cpp:141] Setting up relu4
I0722 16:06:28.139839 22448 net.cpp:148] Top shape: 10 384 13 13 (648960)
I0722 16:06:28.139845 22448 net.cpp:156] Memory required for data: 63788600
I0722 16:06:28.139850 22448 layer_factory.hpp:77] Creating layer conv5
I0722 16:06:28.139860 22448 net.cpp:91] Creating Layer conv5
I0722 16:06:28.139865 22448 net.cpp:425] conv5 <- conv4
I0722 16:06:28.140532 22448 net.cpp:399] conv5 -> conv5
I0722 16:06:28.141214 22430 net.cpp:141] Setting up lstm2_h_conted_0
I0722 16:06:28.141238 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.141243 22430 net.cpp:156] Memory required for data: 50020
I0722 16:06:28.141248 22430 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0722 16:06:28.141264 22430 net.cpp:91] Creating Layer lstm2_transform_1
I0722 16:06:28.141270 22430 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0722 16:06:28.141278 22430 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0722 16:06:28.158326 22442 net.cpp:141] Setting up conv5
I0722 16:06:28.158372 22442 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.158380 22442 net.cpp:156] Memory required for data: 65519160
I0722 16:06:28.158399 22442 layer_factory.hpp:77] Creating layer relu5
I0722 16:06:28.158414 22442 net.cpp:91] Creating Layer relu5
I0722 16:06:28.158421 22442 net.cpp:425] relu5 <- conv5
I0722 16:06:28.158428 22442 net.cpp:386] relu5 -> conv5 (in-place)
I0722 16:06:28.159315 22448 net.cpp:141] Setting up conv5
I0722 16:06:28.159337 22448 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.159337 22442 net.cpp:141] Setting up relu5
I0722 16:06:28.159344 22448 net.cpp:156] Memory required for data: 65519160
I0722 16:06:28.159351 22442 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.159356 22442 net.cpp:156] Memory required for data: 67249720
I0722 16:06:28.159358 22448 layer_factory.hpp:77] Creating layer relu5
I0722 16:06:28.159361 22442 layer_factory.hpp:77] Creating layer pool5
I0722 16:06:28.159369 22448 net.cpp:91] Creating Layer relu5
I0722 16:06:28.159373 22442 net.cpp:91] Creating Layer pool5
I0722 16:06:28.159375 22448 net.cpp:425] relu5 <- conv5
I0722 16:06:28.159378 22442 net.cpp:425] pool5 <- conv5
I0722 16:06:28.159381 22448 net.cpp:386] relu5 -> conv5 (in-place)
I0722 16:06:28.159389 22442 net.cpp:399] pool5 -> pool5
I0722 16:06:28.160152 22442 net.cpp:141] Setting up pool5
I0722 16:06:28.160163 22442 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0722 16:06:28.160167 22442 net.cpp:156] Memory required for data: 67618360
I0722 16:06:28.160172 22442 layer_factory.hpp:77] Creating layer fc6
I0722 16:06:28.160187 22442 net.cpp:91] Creating Layer fc6
I0722 16:06:28.160190 22442 net.cpp:425] fc6 <- pool5
I0722 16:06:28.160200 22442 net.cpp:399] fc6 -> fc6
I0722 16:06:28.160212 22448 net.cpp:141] Setting up relu5
I0722 16:06:28.160228 22448 net.cpp:148] Top shape: 10 256 13 13 (432640)
I0722 16:06:28.160233 22448 net.cpp:156] Memory required for data: 67249720
I0722 16:06:28.160238 22448 layer_factory.hpp:77] Creating layer pool5
I0722 16:06:28.160246 22448 net.cpp:91] Creating Layer pool5
I0722 16:06:28.160250 22448 net.cpp:425] pool5 <- conv5
I0722 16:06:28.160257 22448 net.cpp:399] pool5 -> pool5
I0722 16:06:28.222242 22430 net.cpp:141] Setting up lstm2_transform_1
I0722 16:06:28.222288 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.222293 22430 net.cpp:156] Memory required for data: 66020
I0722 16:06:28.222313 22430 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0722 16:06:28.222332 22430 net.cpp:91] Creating Layer lstm2_gate_input_1
I0722 16:06:28.222337 22430 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0722 16:06:28.222345 22430 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0722 16:06:28.222353 22430 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0722 16:06:28.225389 22448 net.cpp:141] Setting up pool5
I0722 16:06:28.225430 22448 net.cpp:148] Top shape: 10 256 6 6 (92160)
I0722 16:06:28.225436 22448 net.cpp:156] Memory required for data: 67618360
I0722 16:06:28.225445 22448 layer_factory.hpp:77] Creating layer fc6
I0722 16:06:28.225446 22430 net.cpp:141] Setting up lstm2_gate_input_1
I0722 16:06:28.225464 22430 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.225466 22448 net.cpp:91] Creating Layer fc6
I0722 16:06:28.225469 22430 net.cpp:156] Memory required for data: 82020
I0722 16:06:28.225474 22448 net.cpp:425] fc6 <- pool5
I0722 16:06:28.225476 22430 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0722 16:06:28.225484 22448 net.cpp:399] fc6 -> fc6
I0722 16:06:28.225486 22430 net.cpp:91] Creating Layer lstm2_unit_1
I0722 16:06:28.225492 22430 net.cpp:425] lstm2_unit_1 <- c_0
I0722 16:06:28.225498 22430 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0722 16:06:28.225504 22430 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0722 16:06:28.225512 22430 net.cpp:399] lstm2_unit_1 -> c_1
I0722 16:06:28.225522 22430 net.cpp:399] lstm2_unit_1 -> h_1
I0722 16:06:28.225672 22434 net.cpp:141] Setting up lstm2_x_transform
I0722 16:06:28.225689 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.225694 22434 net.cpp:156] Memory required for data: 30020
I0722 16:06:28.225709 22434 layer_factory.hpp:77] Creating layer lstm2_W_xc_x_slice
I0722 16:06:28.225725 22434 net.cpp:91] Creating Layer lstm2_W_xc_x_slice
I0722 16:06:28.225731 22434 net.cpp:425] lstm2_W_xc_x_slice <- W_xc_x
I0722 16:06:28.225739 22434 net.cpp:399] lstm2_W_xc_x_slice -> W_xc_x_1
I0722 16:06:28.291705 22434 net.cpp:141] Setting up lstm2_W_xc_x_slice
I0722 16:06:28.291761 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.291767 22434 net.cpp:156] Memory required for data: 46020
I0722 16:06:28.291777 22434 layer_factory.hpp:77] Creating layer lstm2_h_conted_0
I0722 16:06:28.291797 22434 net.cpp:91] Creating Layer lstm2_h_conted_0
I0722 16:06:28.291805 22434 net.cpp:425] lstm2_h_conted_0 <- h_0
I0722 16:06:28.291815 22434 net.cpp:425] lstm2_h_conted_0 <- cont_1_lstm2_cont_slice_0_split_0
I0722 16:06:28.291822 22434 net.cpp:399] lstm2_h_conted_0 -> h_conted_0
I0722 16:06:28.295191 22430 net.cpp:141] Setting up lstm2_unit_1
I0722 16:06:28.295234 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.295243 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.295248 22430 net.cpp:156] Memory required for data: 90020
I0722 16:06:28.295255 22430 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.295269 22430 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.295275 22430 net.cpp:425] lstm2_ <- c_1
I0722 16:06:28.295285 22430 net.cpp:399] lstm2_ -> c_T
I0722 16:06:28.295395 22442 net.cpp:141] Setting up fc6
I0722 16:06:28.295416 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.295421 22442 net.cpp:156] Memory required for data: 67782200
I0722 16:06:28.295428 22430 net.cpp:141] Setting up lstm2_
I0722 16:06:28.295438 22442 layer_factory.hpp:77] Creating layer relu6
I0722 16:06:28.295447 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.295454 22430 net.cpp:156] Memory required for data: 94020
I0722 16:06:28.295469 22430 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0722 16:06:28.295469 22434 net.cpp:141] Setting up lstm2_h_conted_0
I0722 16:06:28.295491 22430 net.cpp:91] Creating Layer lstm2_h_concat
I0722 16:06:28.295498 22430 net.cpp:425] lstm2_h_concat <- h_1
I0722 16:06:28.295496 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.295516 22430 net.cpp:399] lstm2_h_concat -> h
I0722 16:06:28.295517 22434 net.cpp:156] Memory required for data: 50020
I0722 16:06:28.295524 22434 layer_factory.hpp:77] Creating layer lstm2_transform_1
I0722 16:06:28.295538 22434 net.cpp:91] Creating Layer lstm2_transform_1
I0722 16:06:28.295544 22434 net.cpp:425] lstm2_transform_1 <- h_conted_0
I0722 16:06:28.295553 22434 net.cpp:399] lstm2_transform_1 -> W_hc_h_0
I0722 16:06:28.295593 22430 net.cpp:141] Setting up lstm2_h_concat
I0722 16:06:28.295603 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.295608 22430 net.cpp:156] Memory required for data: 98020
I0722 16:06:28.295611 22430 layer_factory.hpp:77] Creating layer h_pseudoloss
I0722 16:06:28.295624 22430 net.cpp:91] Creating Layer h_pseudoloss
I0722 16:06:28.295629 22430 net.cpp:425] h_pseudoloss <- h
I0722 16:06:28.295636 22430 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0722 16:06:28.295455 22442 net.cpp:91] Creating Layer relu6
I0722 16:06:28.295691 22442 net.cpp:425] relu6 <- fc6
I0722 16:06:28.295702 22442 net.cpp:386] relu6 -> fc6 (in-place)
I0722 16:06:28.305414 22430 net.cpp:141] Setting up h_pseudoloss
I0722 16:06:28.305469 22430 net.cpp:148] Top shape: (1)
I0722 16:06:28.305476 22430 net.cpp:151]     with loss weight 1
I0722 16:06:28.305480 22442 net.cpp:141] Setting up relu6
I0722 16:06:28.305497 22430 net.cpp:156] Memory required for data: 98024
I0722 16:06:28.305526 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.305528 22430 net.cpp:217] h_pseudoloss needs backward computation.
I0722 16:06:28.305532 22442 net.cpp:156] Memory required for data: 67946040
I0722 16:06:28.305537 22430 net.cpp:217] lstm2_h_concat needs backward computation.
I0722 16:06:28.305543 22442 layer_factory.hpp:77] Creating layer drop6
I0722 16:06:28.305543 22430 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.305557 22430 net.cpp:217] lstm2_unit_1 needs backward computation.
I0722 16:06:28.305565 22430 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0722 16:06:28.305567 22442 net.cpp:91] Creating Layer drop6
I0722 16:06:28.305570 22430 net.cpp:217] lstm2_transform_1 needs backward computation.
I0722 16:06:28.305575 22442 net.cpp:425] drop6 <- fc6
I0722 16:06:28.305577 22430 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0722 16:06:28.305589 22430 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0722 16:06:28.305594 22430 net.cpp:217] lstm2_x_transform needs backward computation.
I0722 16:06:28.305598 22442 net.cpp:386] drop6 -> fc6 (in-place)
I0722 16:06:28.305599 22430 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0722 16:06:28.305613 22430 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0722 16:06:28.305619 22430 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.305622 22430 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.305625 22430 net.cpp:261] This network produces output c_T
I0722 16:06:28.305631 22430 net.cpp:261] This network produces output h_pseudoloss
I0722 16:06:28.305650 22430 net.cpp:274] Network initialization done.
I0722 16:06:28.305707 22430 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0722 16:06:28.305713 22430 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0722 16:06:28.305717 22430 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0722 16:06:28.305747 22442 net.cpp:141] Setting up drop6
I0722 16:06:28.305757 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.305760 22442 net.cpp:156] Memory required for data: 68109880
I0722 16:06:28.305765 22442 layer_factory.hpp:77] Creating layer fc7
I0722 16:06:28.305778 22442 net.cpp:91] Creating Layer fc7
I0722 16:06:28.305781 22442 net.cpp:425] fc7 <- fc6
I0722 16:06:28.305793 22442 net.cpp:399] fc7 -> fc7
I0722 16:06:28.335623 22430 net.cpp:141] Setting up lstm2
I0722 16:06:28.335669 22430 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.335675 22430 net.cpp:156] Memory required for data: 36412
I0722 16:06:28.335696 22430 layer_factory.hpp:77] Creating layer predict
I0722 16:06:28.335716 22430 net.cpp:91] Creating Layer predict
I0722 16:06:28.335721 22430 net.cpp:425] predict <- lstm2
I0722 16:06:28.335731 22430 net.cpp:399] predict -> predict
I0722 16:06:28.337404 22434 net.cpp:141] Setting up lstm2_transform_1
I0722 16:06:28.337456 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.337461 22434 net.cpp:156] Memory required for data: 66020
I0722 16:06:28.337483 22434 layer_factory.hpp:77] Creating layer lstm2_gate_input_1
I0722 16:06:28.337504 22434 net.cpp:91] Creating Layer lstm2_gate_input_1
I0722 16:06:28.337512 22434 net.cpp:425] lstm2_gate_input_1 <- W_hc_h_0
I0722 16:06:28.337520 22434 net.cpp:425] lstm2_gate_input_1 <- W_xc_x_1
I0722 16:06:28.337535 22434 net.cpp:399] lstm2_gate_input_1 -> gate_input_1
I0722 16:06:28.414099 22434 net.cpp:141] Setting up lstm2_gate_input_1
I0722 16:06:28.414151 22434 net.cpp:148] Top shape: 1 1 4000 (4000)
I0722 16:06:28.414157 22434 net.cpp:156] Memory required for data: 82020
I0722 16:06:28.414167 22434 layer_factory.hpp:77] Creating layer lstm2_unit_1
I0722 16:06:28.414186 22434 net.cpp:91] Creating Layer lstm2_unit_1
I0722 16:06:28.414193 22434 net.cpp:425] lstm2_unit_1 <- c_0
I0722 16:06:28.414211 22434 net.cpp:425] lstm2_unit_1 <- gate_input_1
I0722 16:06:28.414216 22434 net.cpp:425] lstm2_unit_1 <- cont_1_lstm2_cont_slice_0_split_1
I0722 16:06:28.414224 22434 net.cpp:399] lstm2_unit_1 -> c_1
I0722 16:06:28.414238 22434 net.cpp:399] lstm2_unit_1 -> h_1
I0722 16:06:28.419239 22434 net.cpp:141] Setting up lstm2_unit_1
I0722 16:06:28.419260 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.419267 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.419271 22434 net.cpp:156] Memory required for data: 90020
I0722 16:06:28.419276 22434 layer_factory.hpp:77] Creating layer lstm2_
I0722 16:06:28.419287 22434 net.cpp:91] Creating Layer lstm2_
I0722 16:06:28.419293 22434 net.cpp:425] lstm2_ <- c_1
I0722 16:06:28.419301 22434 net.cpp:399] lstm2_ -> c_T
I0722 16:06:28.419387 22442 net.cpp:141] Setting up fc7
I0722 16:06:28.419407 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.419411 22442 net.cpp:156] Memory required for data: 68273720
I0722 16:06:28.419410 22434 net.cpp:141] Setting up lstm2_
I0722 16:06:28.419425 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.419425 22442 layer_factory.hpp:77] Creating layer relu7
I0722 16:06:28.419428 22434 net.cpp:156] Memory required for data: 94020
I0722 16:06:28.419433 22434 layer_factory.hpp:77] Creating layer lstm2_h_concat
I0722 16:06:28.419435 22442 net.cpp:91] Creating Layer relu7
I0722 16:06:28.419441 22442 net.cpp:425] relu7 <- fc7
I0722 16:06:28.419445 22434 net.cpp:91] Creating Layer lstm2_h_concat
I0722 16:06:28.419450 22434 net.cpp:425] lstm2_h_concat <- h_1
I0722 16:06:28.419452 22442 net.cpp:386] relu7 -> fc7 (in-place)
I0722 16:06:28.419459 22434 net.cpp:399] lstm2_h_concat -> h
I0722 16:06:28.419505 22448 net.cpp:141] Setting up fc6
I0722 16:06:28.419549 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.419554 22448 net.cpp:156] Memory required for data: 67782200
I0722 16:06:28.419569 22448 layer_factory.hpp:77] Creating layer relu6
I0722 16:06:28.419585 22448 net.cpp:91] Creating Layer relu6
I0722 16:06:28.419594 22448 net.cpp:425] relu6 <- fc6
I0722 16:06:28.419603 22448 net.cpp:386] relu6 -> fc6 (in-place)
I0722 16:06:28.420198 22448 net.cpp:141] Setting up relu6
I0722 16:06:28.420218 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.420228 22448 net.cpp:156] Memory required for data: 67946040
I0722 16:06:28.420235 22448 layer_factory.hpp:77] Creating layer drop6
I0722 16:06:28.420250 22448 net.cpp:91] Creating Layer drop6
I0722 16:06:28.420259 22448 net.cpp:425] drop6 <- fc6
I0722 16:06:28.420295 22448 net.cpp:386] drop6 -> fc6 (in-place)
I0722 16:06:28.421169 22448 net.cpp:141] Setting up drop6
I0722 16:06:28.421191 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.421200 22448 net.cpp:156] Memory required for data: 68109880
I0722 16:06:28.421205 22434 net.cpp:141] Setting up lstm2_h_concat
I0722 16:06:28.421210 22448 layer_factory.hpp:77] Creating layer fc7
I0722 16:06:28.421236 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.421259 22434 net.cpp:156] Memory required for data: 98020
I0722 16:06:28.421267 22434 layer_factory.hpp:77] Creating layer h_pseudoloss
I0722 16:06:28.421278 22434 net.cpp:91] Creating Layer h_pseudoloss
I0722 16:06:28.421283 22434 net.cpp:425] h_pseudoloss <- h
I0722 16:06:28.421283 22448 net.cpp:91] Creating Layer fc7
I0722 16:06:28.421293 22434 net.cpp:399] h_pseudoloss -> h_pseudoloss
I0722 16:06:28.421298 22448 net.cpp:425] fc7 <- fc6
I0722 16:06:28.421314 22448 net.cpp:399] fc7 -> fc7
I0722 16:06:28.421581 22442 net.cpp:141] Setting up relu7
I0722 16:06:28.421597 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.421602 22442 net.cpp:156] Memory required for data: 68437560
I0722 16:06:28.421607 22442 layer_factory.hpp:77] Creating layer drop7
I0722 16:06:28.421680 22442 net.cpp:91] Creating Layer drop7
I0722 16:06:28.421687 22442 net.cpp:425] drop7 <- fc7
I0722 16:06:28.421695 22442 net.cpp:386] drop7 -> fc7 (in-place)
I0722 16:06:28.454991 22442 net.cpp:141] Setting up drop7
I0722 16:06:28.455018 22442 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.455029 22442 net.cpp:156] Memory required for data: 68601400
I0722 16:06:28.455037 22442 layer_factory.hpp:77] Creating layer fc8
I0722 16:06:28.455071 22442 net.cpp:91] Creating Layer fc8
I0722 16:06:28.455082 22442 net.cpp:425] fc8 <- fc7
I0722 16:06:28.455098 22442 net.cpp:399] fc8 -> fc8
I0722 16:06:28.457368 22434 net.cpp:141] Setting up h_pseudoloss
I0722 16:06:28.457396 22434 net.cpp:148] Top shape: (1)
I0722 16:06:28.457401 22434 net.cpp:151]     with loss weight 1
I0722 16:06:28.457417 22434 net.cpp:156] Memory required for data: 98024
I0722 16:06:28.457424 22434 net.cpp:217] h_pseudoloss needs backward computation.
I0722 16:06:28.457429 22434 net.cpp:217] lstm2_h_concat needs backward computation.
I0722 16:06:28.457434 22434 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.457439 22434 net.cpp:217] lstm2_unit_1 needs backward computation.
I0722 16:06:28.457445 22434 net.cpp:217] lstm2_gate_input_1 needs backward computation.
I0722 16:06:28.457451 22434 net.cpp:217] lstm2_transform_1 needs backward computation.
I0722 16:06:28.457456 22434 net.cpp:219] lstm2_h_conted_0 does not need backward computation.
I0722 16:06:28.457461 22434 net.cpp:217] lstm2_W_xc_x_slice needs backward computation.
I0722 16:06:28.457466 22434 net.cpp:217] lstm2_x_transform needs backward computation.
I0722 16:06:28.457471 22434 net.cpp:219] cont_1_lstm2_cont_slice_0_split does not need backward computation.
I0722 16:06:28.457476 22434 net.cpp:219] lstm2_cont_slice does not need backward computation.
I0722 16:06:28.457480 22434 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.457484 22434 net.cpp:219] lstm2_ does not need backward computation.
I0722 16:06:28.457487 22434 net.cpp:261] This network produces output c_T
I0722 16:06:28.457492 22434 net.cpp:261] This network produces output h_pseudoloss
I0722 16:06:28.457511 22434 net.cpp:274] Network initialization done.
I0722 16:06:28.457573 22434 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0722 16:06:28.457579 22434 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0722 16:06:28.457583 22434 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0722 16:06:28.470016 22434 net.cpp:141] Setting up lstm2
I0722 16:06:28.470080 22434 net.cpp:148] Top shape: 1 1 1000 (1000)
I0722 16:06:28.470087 22434 net.cpp:156] Memory required for data: 36412
I0722 16:06:28.470111 22434 layer_factory.hpp:77] Creating layer predict
I0722 16:06:28.470137 22434 net.cpp:91] Creating Layer predict
I0722 16:06:28.470144 22434 net.cpp:425] predict <- lstm2
I0722 16:06:28.470155 22434 net.cpp:399] predict -> predict
I0722 16:06:28.549814 22448 net.cpp:141] Setting up fc7
I0722 16:06:28.549845 22442 net.cpp:141] Setting up fc8
I0722 16:06:28.549872 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.549872 22442 net.cpp:148] Top shape: 10 1000 (10000)
I0722 16:06:28.549880 22448 net.cpp:156] Memory required for data: 68273720
I0722 16:06:28.549883 22442 net.cpp:156] Memory required for data: 68641400
I0722 16:06:28.549898 22442 layer_factory.hpp:77] Creating layer prob
I0722 16:06:28.549898 22448 layer_factory.hpp:77] Creating layer relu7
I0722 16:06:28.549919 22448 net.cpp:91] Creating Layer relu7
I0722 16:06:28.549924 22442 net.cpp:91] Creating Layer prob
I0722 16:06:28.549927 22448 net.cpp:425] relu7 <- fc7
I0722 16:06:28.549931 22442 net.cpp:425] prob <- fc8
I0722 16:06:28.549938 22448 net.cpp:386] relu7 -> fc7 (in-place)
I0722 16:06:28.549944 22442 net.cpp:399] prob -> prob
I0722 16:06:28.551564 22442 net.cpp:141] Setting up prob
I0722 16:06:28.551565 22448 net.cpp:141] Setting up relu7
I0722 16:06:28.551604 22442 net.cpp:148] Top shape: 10 1000 (10000)
I0722 16:06:28.551606 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.551610 22442 net.cpp:156] Memory required for data: 68681400
I0722 16:06:28.551611 22448 net.cpp:156] Memory required for data: 68437560
I0722 16:06:28.551617 22442 net.cpp:219] prob does not need backward computation.
I0722 16:06:28.551617 22448 layer_factory.hpp:77] Creating layer drop7
I0722 16:06:28.551627 22442 net.cpp:219] fc8 does not need backward computation.
I0722 16:06:28.551632 22442 net.cpp:219] drop7 does not need backward computation.
I0722 16:06:28.551635 22442 net.cpp:219] relu7 does not need backward computation.
I0722 16:06:28.551640 22442 net.cpp:219] fc7 does not need backward computation.
I0722 16:06:28.551642 22448 net.cpp:91] Creating Layer drop7
I0722 16:06:28.551643 22442 net.cpp:219] drop6 does not need backward computation.
I0722 16:06:28.551652 22448 net.cpp:425] drop7 <- fc7
I0722 16:06:28.551653 22442 net.cpp:219] relu6 does not need backward computation.
I0722 16:06:28.551658 22442 net.cpp:219] fc6 does not need backward computation.
I0722 16:06:28.551663 22448 net.cpp:386] drop7 -> fc7 (in-place)
I0722 16:06:28.551663 22442 net.cpp:219] pool5 does not need backward computation.
I0722 16:06:28.551674 22442 net.cpp:219] relu5 does not need backward computation.
I0722 16:06:28.551678 22442 net.cpp:219] conv5 does not need backward computation.
I0722 16:06:28.551683 22442 net.cpp:219] relu4 does not need backward computation.
I0722 16:06:28.551687 22442 net.cpp:219] conv4 does not need backward computation.
I0722 16:06:28.551690 22442 net.cpp:219] relu3 does not need backward computation.
I0722 16:06:28.551694 22442 net.cpp:219] conv3 does not need backward computation.
I0722 16:06:28.551699 22442 net.cpp:219] norm2 does not need backward computation.
I0722 16:06:28.551703 22442 net.cpp:219] pool2 does not need backward computation.
I0722 16:06:28.551707 22442 net.cpp:219] relu2 does not need backward computation.
I0722 16:06:28.551710 22442 net.cpp:219] conv2 does not need backward computation.
I0722 16:06:28.551714 22442 net.cpp:219] norm1 does not need backward computation.
I0722 16:06:28.551718 22442 net.cpp:219] pool1 does not need backward computation.
I0722 16:06:28.551723 22442 net.cpp:219] relu1 does not need backward computation.
I0722 16:06:28.551726 22442 net.cpp:219] conv1 does not need backward computation.
I0722 16:06:28.551730 22442 net.cpp:219] data does not need backward computation.
I0722 16:06:28.551734 22442 net.cpp:261] This network produces output prob
I0722 16:06:28.551744 22448 net.cpp:141] Setting up drop7
I0722 16:06:28.551762 22442 net.cpp:274] Network initialization done.
I0722 16:06:28.551764 22448 net.cpp:148] Top shape: 10 4096 (40960)
I0722 16:06:28.551774 22448 net.cpp:156] Memory required for data: 68601400
I0722 16:06:28.551779 22448 layer_factory.hpp:77] Creating layer fc8
I0722 16:06:28.551789 22448 net.cpp:91] Creating Layer fc8
I0722 16:06:28.551794 22448 net.cpp:425] fc8 <- fc7
I0722 16:06:28.551800 22448 net.cpp:399] fc8 -> fc8
I0722 16:06:28.567152 22448 net.cpp:141] Setting up fc8
I0722 16:06:28.567198 22448 net.cpp:148] Top shape: 10 1000 (10000)
I0722 16:06:28.567204 22448 net.cpp:156] Memory required for data: 68641400
I0722 16:06:28.567219 22448 layer_factory.hpp:77] Creating layer prob
I0722 16:06:28.567234 22448 net.cpp:91] Creating Layer prob
I0722 16:06:28.567240 22448 net.cpp:425] prob <- fc8
I0722 16:06:28.567255 22448 net.cpp:399] prob -> prob
I0722 16:06:28.568312 22448 net.cpp:141] Setting up prob
I0722 16:06:28.568327 22448 net.cpp:148] Top shape: 10 1000 (10000)
I0722 16:06:28.568332 22448 net.cpp:156] Memory required for data: 68681400
I0722 16:06:28.568337 22448 net.cpp:219] prob does not need backward computation.
I0722 16:06:28.568342 22448 net.cpp:219] fc8 does not need backward computation.
I0722 16:06:28.568346 22448 net.cpp:219] drop7 does not need backward computation.
I0722 16:06:28.568351 22448 net.cpp:219] relu7 does not need backward computation.
I0722 16:06:28.568356 22448 net.cpp:219] fc7 does not need backward computation.
I0722 16:06:28.568359 22448 net.cpp:219] drop6 does not need backward computation.
I0722 16:06:28.568363 22448 net.cpp:219] relu6 does not need backward computation.
I0722 16:06:28.568367 22448 net.cpp:219] fc6 does not need backward computation.
I0722 16:06:28.568372 22448 net.cpp:219] pool5 does not need backward computation.
I0722 16:06:28.568375 22448 net.cpp:219] relu5 does not need backward computation.
I0722 16:06:28.568380 22448 net.cpp:219] conv5 does not need backward computation.
I0722 16:06:28.568384 22448 net.cpp:219] relu4 does not need backward computation.
I0722 16:06:28.568388 22448 net.cpp:219] conv4 does not need backward computation.
I0722 16:06:28.568393 22448 net.cpp:219] relu3 does not need backward computation.
I0722 16:06:28.568397 22448 net.cpp:219] conv3 does not need backward computation.
I0722 16:06:28.568403 22448 net.cpp:219] norm2 does not need backward computation.
I0722 16:06:28.568406 22448 net.cpp:219] pool2 does not need backward computation.
I0722 16:06:28.568410 22448 net.cpp:219] relu2 does not need backward computation.
I0722 16:06:28.568414 22448 net.cpp:219] conv2 does not need backward computation.
I0722 16:06:28.568418 22448 net.cpp:219] norm1 does not need backward computation.
I0722 16:06:28.568423 22448 net.cpp:219] pool1 does not need backward computation.
I0722 16:06:28.568428 22448 net.cpp:219] relu1 does not need backward computation.
I0722 16:06:28.568431 22448 net.cpp:219] conv1 does not need backward computation.
I0722 16:06:28.568435 22448 net.cpp:219] data does not need backward computation.
I0722 16:06:28.568439 22448 net.cpp:261] This network produces output prob
I0722 16:06:28.568457 22448 net.cpp:274] Network initialization done.
I0722 16:06:28.774655 22430 net.cpp:141] Setting up predict
I0722 16:06:28.774713 22430 net.cpp:148] Top shape: 1 1 46168 (46168)
I0722 16:06:28.774718 22430 net.cpp:156] Memory required for data: 221084
I0722 16:06:28.774731 22430 layer_factory.hpp:77] Creating layer probs
I0722 16:06:28.774745 22430 net.cpp:91] Creating Layer probs
I0722 16:06:28.774751 22430 net.cpp:425] probs <- predict
I0722 16:06:28.774761 22430 net.cpp:399] probs -> probs
I0722 16:06:28.776540 22430 net.cpp:141] Setting up probs
I0722 16:06:28.776559 22430 net.cpp:148] Top shape: 1 1 46168 (46168)
I0722 16:06:28.776564 22430 net.cpp:156] Memory required for data: 405756
I0722 16:06:28.776569 22430 net.cpp:219] probs does not need backward computation.
I0722 16:06:28.776574 22430 net.cpp:219] predict does not need backward computation.
I0722 16:06:28.776579 22430 net.cpp:219] lstm2 does not need backward computation.
I0722 16:06:28.776584 22430 net.cpp:219] concat does not need backward computation.
I0722 16:06:28.776589 22430 net.cpp:219] lstm1 does not need backward computation.
I0722 16:06:28.776595 22430 net.cpp:219] embedding does not need backward computation.
I0722 16:06:28.776599 22430 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0722 16:06:28.776604 22430 net.cpp:219] reshape_frames does not need backward computation.
I0722 16:06:28.776608 22430 net.cpp:219] embed_encoder does not need backward computation.
I0722 16:06:28.776613 22430 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0722 16:06:28.776618 22430 net.cpp:219] input does not need backward computation.
I0722 16:06:28.776624 22430 net.cpp:261] This network produces output probs
I0722 16:06:28.776638 22430 net.cpp:274] Network initialization done.
I0722 16:06:28.791182 22442 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld6353972619595424022/bvlc_reference_caffenet.caffemodel
I0722 16:06:28.791231 22442 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0722 16:06:28.791237 22442 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0722 16:06:28.791241 22442 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld6353972619595424022/bvlc_reference_caffenet.caffemodel
I0722 16:06:28.846011 22448 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /tmp/cvld6353972619595424022/bvlc_reference_caffenet.caffemodel
I0722 16:06:28.846051 22448 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0722 16:06:28.846057 22448 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0722 16:06:28.846061 22448 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /tmp/cvld6353972619595424022/bvlc_reference_caffenet.caffemodel
I0722 16:06:28.912765 22434 net.cpp:141] Setting up predict
I0722 16:06:28.912828 22434 net.cpp:148] Top shape: 1 1 46168 (46168)
I0722 16:06:28.912834 22434 net.cpp:156] Memory required for data: 221084
I0722 16:06:28.912852 22434 layer_factory.hpp:77] Creating layer probs
I0722 16:06:28.912870 22434 net.cpp:91] Creating Layer probs
I0722 16:06:28.912880 22434 net.cpp:425] probs <- predict
I0722 16:06:28.912899 22434 net.cpp:399] probs -> probs
I0722 16:06:28.915073 22434 net.cpp:141] Setting up probs
I0722 16:06:28.915122 22434 net.cpp:148] Top shape: 1 1 46168 (46168)
I0722 16:06:28.915128 22434 net.cpp:156] Memory required for data: 405756
I0722 16:06:28.915137 22434 net.cpp:219] probs does not need backward computation.
I0722 16:06:28.915143 22434 net.cpp:219] predict does not need backward computation.
I0722 16:06:28.915148 22434 net.cpp:219] lstm2 does not need backward computation.
I0722 16:06:28.915153 22434 net.cpp:219] concat does not need backward computation.
I0722 16:06:28.915159 22434 net.cpp:219] lstm1 does not need backward computation.
I0722 16:06:28.915164 22434 net.cpp:219] embedding does not need backward computation.
I0722 16:06:28.915169 22434 net.cpp:219] reshape_stage_indicator does not need backward computation.
I0722 16:06:28.915174 22434 net.cpp:219] reshape_frames does not need backward computation.
I0722 16:06:28.915179 22434 net.cpp:219] embed_encoder does not need backward computation.
I0722 16:06:28.915182 22434 net.cpp:219] cont_sentence_input_1_split does not need backward computation.
I0722 16:06:28.915187 22434 net.cpp:219] input does not need backward computation.
I0722 16:06:28.915190 22434 net.cpp:261] This network produces output probs
I0722 16:06:28.915210 22434 net.cpp:274] Network initialization done.
I0722 16:06:29.183305 22430 net.cpp:752] Ignoring source layer data
I0722 16:06:29.183341 22430 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0722 16:06:29.183346 22430 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0722 16:06:29.183816 22442 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0722 16:06:29.241456 22442 net.cpp:752] Ignoring source layer loss
I0722 16:06:29.263977 22430 net.cpp:752] Ignoring source layer cross_entropy_loss
I0722 16:06:29.280455 22434 net.cpp:752] Ignoring source layer data
I0722 16:06:29.280493 22434 net.cpp:752] Ignoring source layer cont_sentence_data_0_split
I0722 16:06:29.280499 22434 net.cpp:752] Ignoring source layer reshape_stg_indicator
I0722 16:06:29.332435 22448 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0722 16:06:29.356176 22434 net.cpp:752] Ignoring source layer cross_entropy_loss
I0722 16:06:29.413923 22448 net.cpp:752] Ignoring source layer loss
